{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 16\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 16\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "\n",
    "#Power splitting ratio\n",
    "rho = 0\n",
    "eps=1\n",
    "eta=1\n",
    "print('number of symbols:',M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_nn(P,EsNodB):\n",
    "    label = np.random.randint(M,size=N)\n",
    "\n",
    "    # creating one hot encoded vectors\n",
    "    data = []\n",
    "    for i in label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        data.append(temp)\n",
    "\n",
    "    # checking data shape\n",
    "    data = np.array(data)\n",
    "    print (data.shape)\n",
    "\n",
    "\n",
    "    # Defined Autoencoder\n",
    "    batch_size = 4096\n",
    "    \n",
    "    # Transmitter Layers\n",
    "    input_signal = Input(shape=(M,))\n",
    "    encoded = Dense(M, activation='relu')(input_signal)\n",
    "    encoded2 = Dense(8, activation='relu')(encoded)\n",
    "    encoded2 = Dense(4, activation='relu')(encoded)\n",
    "    encoded2 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "\n",
    "    # Normalize Power\n",
    "    encoded3 = BatchNormalization(momentum=0,epsilon=1e-6,center=False,scale=False,axis=1)(encoded2)\n",
    "    encoded3 = Lambda(lambda x: x*np.sqrt(P/2))(encoded3)\n",
    "\n",
    "    # Slicing into CD and PD data, and applying noise\n",
    "\n",
    "    cd_data = Lambda(lambda x: np.sqrt(rho)*np.sqrt(eps)*x)(encoded3)\n",
    "    cd_data = Lambda(lambda x: x+K.random_normal_variable((32768*2,2), 0,np.sqrt(0.5))[0:tf.shape(x)[0],:])(cd_data)\n",
    "\n",
    "    \n",
    "    pd_data = Lambda(lambda x: K.expand_dims((1-rho)*eta*eps*K.sum(K.square(x),axis=1),axis=1))(encoded3)\n",
    "    pd_data = Lambda(lambda x: x+K.random_normal_variable((32768*2,1), 0,np.sqrt(0))[0:tf.shape(x)[0]])(pd_data)\n",
    "\n",
    "    #combining the split data to feed the decoder\n",
    "    data_split=[]\n",
    "    data_split.append(cd_data)\n",
    "    data_split.append(pd_data)\n",
    "\n",
    "    data_split =  Concatenate(axis=1)(data_split)\n",
    "\n",
    "\n",
    "    # Reciever Layer\n",
    "    decoded = Dense(2, activation='linear')(data_split)\n",
    "    decoded = Dense(4, activation='relu')(decoded)\n",
    "    decoded = Dense(8, activation='relu')(decoded)\n",
    "    decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "    autoencoder = Model(input_signal, decoded1)\n",
    "\n",
    "    adam = Adam(lr=0.075)\n",
    "    sgd = SGD(lr=0.5)\n",
    "    autoencoder.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy','mse'])\n",
    "\n",
    "    # printing summary of layers and it's trainable parameters \n",
    "    print (autoencoder.summary())\n",
    "\n",
    "    # traning auto encoder\n",
    "    autoencoder.fit(data, data,\n",
    "                    epochs=150,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "    # making encoder from full autoencoder\n",
    "    encoder = Model(input_signal, encoded3)\n",
    "\n",
    "    # for plotting learned consteallation diagram\n",
    "\n",
    "    scatter_plot = []\n",
    "    for i in range(0,M):\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "    scatter_plot = np.array(scatter_plot)\n",
    "    print (scatter_plot.shape)\n",
    "\n",
    "    # ploting constellation diagram\n",
    "    import matplotlib.pyplot as plt\n",
    "    scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "\n",
    "    plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "    #plt.axis((-2,2,-2,2))\n",
    "    plt.grid()\n",
    "    #plt.title('Splitting Receiver: rho = '+str(rho)+' eps = '+str(eps))\n",
    "    plt.xlabel('I Axis')\n",
    "    plt.ylabel('Q Axis')\n",
    "    plt.show()\n",
    "    p_av = np.sum(np.square(scatter_plot),axis=1)\n",
    "    print(sum(p_av)/16)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           272         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            34          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2)            4           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            8           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            12          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            40          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           144         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 514\n",
      "Trainable params: 510\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "10000/10000 [==============================] - 4s 353us/step - loss: 3.0099 - acc: 0.0707 - mean_squared_error: 0.0598\n",
      "Epoch 2/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 2.5886 - acc: 0.1314 - mean_squared_error: 0.0558\n",
      "Epoch 3/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 2.4196 - acc: 0.1489 - mean_squared_error: 0.0547\n",
      "Epoch 4/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 2.2769 - acc: 0.2988 - mean_squared_error: 0.0532\n",
      "Epoch 5/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 2.0865 - acc: 0.2491 - mean_squared_error: 0.0516\n",
      "Epoch 6/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.9136 - acc: 0.2896 - mean_squared_error: 0.0496\n",
      "Epoch 7/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.7262 - acc: 0.3254 - mean_squared_error: 0.0472\n",
      "Epoch 8/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.5639 - acc: 0.3849 - mean_squared_error: 0.0449\n",
      "Epoch 9/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.4618 - acc: 0.4099 - mean_squared_error: 0.0446\n",
      "Epoch 10/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.4260 - acc: 0.4718 - mean_squared_error: 0.0436\n",
      "Epoch 11/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.3081 - acc: 0.4198 - mean_squared_error: 0.0414\n",
      "Epoch 12/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 1.2682 - acc: 0.4109 - mean_squared_error: 0.0407\n",
      "Epoch 13/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 1.1652 - acc: 0.5403 - mean_squared_error: 0.0382\n",
      "Epoch 14/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.1363 - acc: 0.5343 - mean_squared_error: 0.0379\n",
      "Epoch 15/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.1702 - acc: 0.4696 - mean_squared_error: 0.0386\n",
      "Epoch 16/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.0978 - acc: 0.5187 - mean_squared_error: 0.0364\n",
      "Epoch 17/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.1787 - acc: 0.5140 - mean_squared_error: 0.0391\n",
      "Epoch 18/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.2187 - acc: 0.3898 - mean_squared_error: 0.0407\n",
      "Epoch 19/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.1165 - acc: 0.5031 - mean_squared_error: 0.0363\n",
      "Epoch 20/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.9993 - acc: 0.5311 - mean_squared_error: 0.0333\n",
      "Epoch 21/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.0615 - acc: 0.6601 - mean_squared_error: 0.0336\n",
      "Epoch 22/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.9734 - acc: 0.5417 - mean_squared_error: 0.0320\n",
      "Epoch 23/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.0301 - acc: 0.5641 - mean_squared_error: 0.0346\n",
      "Epoch 24/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.9906 - acc: 0.5491 - mean_squared_error: 0.0317\n",
      "Epoch 25/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 0.9832 - acc: 0.5387 - mean_squared_error: 0.0346\n",
      "Epoch 26/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 1.0877 - acc: 0.4974 - mean_squared_error: 0.0377\n",
      "Epoch 27/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 1.0002 - acc: 0.5664 - mean_squared_error: 0.0344\n",
      "Epoch 28/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.0679 - acc: 0.5151 - mean_squared_error: 0.0359\n",
      "Epoch 29/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.1675 - acc: 0.4674 - mean_squared_error: 0.0388\n",
      "Epoch 30/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.0713 - acc: 0.4393 - mean_squared_error: 0.0372\n",
      "Epoch 31/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.0553 - acc: 0.5361 - mean_squared_error: 0.0366\n",
      "Epoch 32/150\n",
      "10000/10000 [==============================] - 0s 19us/step - loss: 0.9375 - acc: 0.5612 - mean_squared_error: 0.0327\n",
      "Epoch 33/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.8924 - acc: 0.6789 - mean_squared_error: 0.0297\n",
      "Epoch 34/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.8481 - acc: 0.6774 - mean_squared_error: 0.0286\n",
      "Epoch 35/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.7816 - acc: 0.7366 - mean_squared_error: 0.0262\n",
      "Epoch 36/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.7470 - acc: 0.6865 - mean_squared_error: 0.0253\n",
      "Epoch 37/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.7097 - acc: 0.7689 - mean_squared_error: 0.0238\n",
      "Epoch 38/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6887 - acc: 0.7244 - mean_squared_error: 0.0230\n",
      "Epoch 39/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6567 - acc: 0.7652 - mean_squared_error: 0.0221\n",
      "Epoch 40/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.6944 - acc: 0.7244 - mean_squared_error: 0.0238\n",
      "Epoch 41/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.6915 - acc: 0.7665 - mean_squared_error: 0.0234\n",
      "Epoch 42/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6322 - acc: 0.7651 - mean_squared_error: 0.0212\n",
      "Epoch 43/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.2540 - acc: 0.7123 - mean_squared_error: 0.0304\n",
      "Epoch 44/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 1.0260 - acc: 0.5608 - mean_squared_error: 0.0345\n",
      "Epoch 45/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.9941 - acc: 0.5833 - mean_squared_error: 0.0305\n",
      "Epoch 46/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.8628 - acc: 0.6695 - mean_squared_error: 0.0288\n",
      "Epoch 47/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 1.2517 - acc: 0.5818 - mean_squared_error: 0.0357\n",
      "Epoch 48/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 1.1740 - acc: 0.4494 - mean_squared_error: 0.0408\n",
      "Epoch 49/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.7411 - acc: 0.6269 - mean_squared_error: 0.0260\n",
      "Epoch 50/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.9988 - acc: 0.5652 - mean_squared_error: 0.0357\n",
      "Epoch 51/150\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.8628 - acc: 0.6294 - mean_squared_error: 0.0304\n",
      "Epoch 52/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.8281 - acc: 0.6539 - mean_squared_error: 0.0301\n",
      "Epoch 53/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.6728 - acc: 0.7392 - mean_squared_error: 0.0247\n",
      "Epoch 54/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6604 - acc: 0.6653 - mean_squared_error: 0.0238\n",
      "Epoch 55/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.6586 - acc: 0.7176 - mean_squared_error: 0.0231\n",
      "Epoch 56/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.5352 - acc: 0.8575 - mean_squared_error: 0.0186\n",
      "Epoch 57/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.5057 - acc: 0.8357 - mean_squared_error: 0.0170\n",
      "Epoch 58/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.4944 - acc: 0.8111 - mean_squared_error: 0.0172\n",
      "Epoch 59/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4757 - acc: 0.8579 - mean_squared_error: 0.0169\n",
      "Epoch 60/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4366 - acc: 0.8586 - mean_squared_error: 0.0150\n",
      "Epoch 61/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.3807 - acc: 0.8810 - mean_squared_error: 0.0127\n",
      "Epoch 62/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3483 - acc: 0.8833 - mean_squared_error: 0.0111\n",
      "Epoch 63/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3598 - acc: 0.8630 - mean_squared_error: 0.0120\n",
      "Epoch 64/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.5452 - acc: 0.7850 - mean_squared_error: 0.0187\n",
      "Epoch 65/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5083 - acc: 0.8267 - mean_squared_error: 0.0187\n",
      "Epoch 66/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6669 - acc: 0.7867 - mean_squared_error: 0.0203\n",
      "Epoch 67/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 1.2312 - acc: 0.6959 - mean_squared_error: 0.0290\n",
      "Epoch 68/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 1.4220 - acc: 0.5744 - mean_squared_error: 0.0373\n",
      "Epoch 69/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.9090 - acc: 0.6259 - mean_squared_error: 0.0283\n",
      "Epoch 70/150\n",
      "10000/10000 [==============================] - 0s 6us/step - loss: 0.7041 - acc: 0.6445 - mean_squared_error: 0.0265\n",
      "Epoch 71/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.7519 - acc: 0.6432 - mean_squared_error: 0.0261\n",
      "Epoch 72/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.6143 - acc: 0.7632 - mean_squared_error: 0.0232\n",
      "Epoch 73/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4879 - acc: 0.7716 - mean_squared_error: 0.0178\n",
      "Epoch 74/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.5137 - acc: 0.7820 - mean_squared_error: 0.0192\n",
      "Epoch 75/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.4969 - acc: 0.7796 - mean_squared_error: 0.0191\n",
      "Epoch 76/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.5740 - acc: 0.6664 - mean_squared_error: 0.0234\n",
      "Epoch 77/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5548 - acc: 0.7738 - mean_squared_error: 0.0211\n",
      "Epoch 78/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5047 - acc: 0.7016 - mean_squared_error: 0.0197\n",
      "Epoch 79/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5187 - acc: 0.7060 - mean_squared_error: 0.0207\n",
      "Epoch 80/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4319 - acc: 0.8469 - mean_squared_error: 0.0155\n",
      "Epoch 81/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4033 - acc: 0.8464 - mean_squared_error: 0.0143\n",
      "Epoch 82/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3652 - acc: 0.8553 - mean_squared_error: 0.0124\n",
      "Epoch 83/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3260 - acc: 0.8972 - mean_squared_error: 0.0107\n",
      "Epoch 84/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4346 - acc: 0.8529 - mean_squared_error: 0.0129\n",
      "Epoch 85/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.5473 - acc: 0.8209 - mean_squared_error: 0.0179\n",
      "Epoch 86/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.8291 - acc: 0.6560 - mean_squared_error: 0.0284\n",
      "Epoch 87/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.5301 - acc: 0.7133 - mean_squared_error: 0.0213\n",
      "Epoch 88/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.5975 - acc: 0.7007 - mean_squared_error: 0.0207\n",
      "Epoch 89/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.4579 - acc: 0.7868 - mean_squared_error: 0.0166\n",
      "Epoch 90/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.8712 - acc: 0.6800 - mean_squared_error: 0.0311\n",
      "Epoch 91/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.7070 - acc: 0.6826 - mean_squared_error: 0.0270\n",
      "Epoch 92/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.6782 - acc: 0.7201 - mean_squared_error: 0.0262\n",
      "Epoch 93/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.5609 - acc: 0.6989 - mean_squared_error: 0.0226\n",
      "Epoch 94/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4906 - acc: 0.7685 - mean_squared_error: 0.0194\n",
      "Epoch 95/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.4827 - acc: 0.7851 - mean_squared_error: 0.0190\n",
      "Epoch 96/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.4603 - acc: 0.7780 - mean_squared_error: 0.0178\n",
      "Epoch 97/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.4009 - acc: 0.8089 - mean_squared_error: 0.0152\n",
      "Epoch 98/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.3331 - acc: 0.8485 - mean_squared_error: 0.0118\n",
      "Epoch 99/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4546 - acc: 0.8477 - mean_squared_error: 0.0151\n",
      "Epoch 100/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3251 - acc: 0.9119 - mean_squared_error: 0.0114\n",
      "Epoch 101/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3420 - acc: 0.8543 - mean_squared_error: 0.0123\n",
      "Epoch 102/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.2627 - acc: 0.9431 - mean_squared_error: 0.0077\n",
      "Epoch 103/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2761 - acc: 0.9206 - mean_squared_error: 0.0082\n",
      "Epoch 104/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2823 - acc: 0.9189 - mean_squared_error: 0.0092\n",
      "Epoch 105/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.2562 - acc: 0.9025 - mean_squared_error: 0.0083\n",
      "Epoch 106/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.2103 - acc: 0.9431 - mean_squared_error: 0.0067\n",
      "Epoch 107/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.2232 - acc: 0.9165 - mean_squared_error: 0.0074\n",
      "Epoch 108/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2007 - acc: 0.9431 - mean_squared_error: 0.0062\n",
      "Epoch 109/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.2049 - acc: 0.9399 - mean_squared_error: 0.0065\n",
      "Epoch 110/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.1920 - acc: 0.9431 - mean_squared_error: 0.0059\n",
      "Epoch 111/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.1728 - acc: 0.9431 - mean_squared_error: 0.0053\n",
      "Epoch 112/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.1696 - acc: 0.9255 - mean_squared_error: 0.0054\n",
      "Epoch 113/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.2487 - acc: 0.8793 - mean_squared_error: 0.0093\n",
      "Epoch 114/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2682 - acc: 0.8954 - mean_squared_error: 0.0087\n",
      "Epoch 115/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.2742 - acc: 0.8971 - mean_squared_error: 0.0092\n",
      "Epoch 116/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5357 - acc: 0.8405 - mean_squared_error: 0.0130\n",
      "Epoch 117/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.6972 - acc: 0.7256 - mean_squared_error: 0.0225\n",
      "Epoch 118/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 1.4490 - acc: 0.5343 - mean_squared_error: 0.0407\n",
      "Epoch 119/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.8061 - acc: 0.6494 - mean_squared_error: 0.0281\n",
      "Epoch 120/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.6841 - acc: 0.6883 - mean_squared_error: 0.0242\n",
      "Epoch 121/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.5770 - acc: 0.7653 - mean_squared_error: 0.0210\n",
      "Epoch 122/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5533 - acc: 0.7831 - mean_squared_error: 0.0199\n",
      "Epoch 123/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5842 - acc: 0.7328 - mean_squared_error: 0.0212\n",
      "Epoch 124/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.5563 - acc: 0.7712 - mean_squared_error: 0.0191\n",
      "Epoch 125/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.3597 - acc: 0.8593 - mean_squared_error: 0.0130\n",
      "Epoch 126/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6316 - acc: 0.7580 - mean_squared_error: 0.0193\n",
      "Epoch 127/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6796 - acc: 0.7509 - mean_squared_error: 0.0207\n",
      "Epoch 128/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.5530 - acc: 0.7647 - mean_squared_error: 0.0183\n",
      "Epoch 129/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4405 - acc: 0.8516 - mean_squared_error: 0.0136\n",
      "Epoch 130/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.6709 - acc: 0.7943 - mean_squared_error: 0.0189\n",
      "Epoch 131/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4523 - acc: 0.8206 - mean_squared_error: 0.0167\n",
      "Epoch 132/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3404 - acc: 0.8955 - mean_squared_error: 0.0114\n",
      "Epoch 133/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3514 - acc: 0.9063 - mean_squared_error: 0.0117\n",
      "Epoch 134/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3464 - acc: 0.8688 - mean_squared_error: 0.0123\n",
      "Epoch 135/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.6780 - acc: 0.8716 - mean_squared_error: 0.0126\n",
      "Epoch 136/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.3549 - acc: 0.8271 - mean_squared_error: 0.0133\n",
      "Epoch 137/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4368 - acc: 0.8139 - mean_squared_error: 0.0165\n",
      "Epoch 138/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4674 - acc: 0.7976 - mean_squared_error: 0.0178\n",
      "Epoch 139/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.2926 - acc: 0.8705 - mean_squared_error: 0.0109\n",
      "Epoch 140/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.2627 - acc: 0.9448 - mean_squared_error: 0.0083\n",
      "Epoch 141/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.3022 - acc: 0.9178 - mean_squared_error: 0.0092\n",
      "Epoch 142/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.3543 - acc: 0.8864 - mean_squared_error: 0.0120\n",
      "Epoch 143/150\n",
      "10000/10000 [==============================] - 0s 8us/step - loss: 0.4478 - acc: 0.8323 - mean_squared_error: 0.0167\n",
      "Epoch 144/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.3921 - acc: 0.8234 - mean_squared_error: 0.0158\n",
      "Epoch 145/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.3681 - acc: 0.8247 - mean_squared_error: 0.0143\n",
      "Epoch 146/150\n",
      "10000/10000 [==============================] - 0s 14us/step - loss: 0.2821 - acc: 0.9191 - mean_squared_error: 0.0096\n",
      "Epoch 147/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.2666 - acc: 0.9136 - mean_squared_error: 0.0090\n",
      "Epoch 148/150\n",
      "10000/10000 [==============================] - 0s 9us/step - loss: 0.3160 - acc: 0.9375 - mean_squared_error: 0.0109\n",
      "Epoch 149/150\n",
      "10000/10000 [==============================] - 0s 11us/step - loss: 0.2795 - acc: 0.8678 - mean_squared_error: 0.0101\n",
      "Epoch 150/150\n",
      "10000/10000 [==============================] - 0s 12us/step - loss: 0.2981 - acc: 0.8558 - mean_squared_error: 0.0116\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.596268]\n",
      "Es/No: 12 SER: 0.0938 Theor_SER_PAM: 0.5075803579279314\n",
      "(64000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           272         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            34          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2)            4           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2)            0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2)            0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3)            0           lambda_8[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            8           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            12          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8)            40          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           144         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 514\n",
      "Trainable params: 510\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "64000/64000 [==============================] - 3s 50us/step - loss: 3.0440 - acc: 0.0902 - mean_squared_error: 0.0596\n",
      "Epoch 2/150\n",
      "64000/64000 [==============================] - 0s 7us/step - loss: 2.3654 - acc: 0.1595 - mean_squared_error: 0.0547\n",
      "Epoch 3/150\n",
      "64000/64000 [==============================] - 0s 7us/step - loss: 2.1182 - acc: 0.2084 - mean_squared_error: 0.0503\n",
      "Epoch 4/150\n",
      "64000/64000 [==============================] - 0s 7us/step - loss: 2.0731 - acc: 0.2233 - mean_squared_error: 0.0498\n",
      "Epoch 5/150\n",
      "64000/64000 [==============================] - 0s 7us/step - loss: 1.9267 - acc: 0.2803 - mean_squared_error: 0.0466\n",
      "Epoch 6/150\n",
      "64000/64000 [==============================] - 0s 7us/step - loss: 1.8376 - acc: 0.3117 - mean_squared_error: 0.0446\n",
      "Epoch 7/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.8051 - acc: 0.3189 - mean_squared_error: 0.0442\n",
      "Epoch 8/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.7593 - acc: 0.3479 - mean_squared_error: 0.0424\n",
      "Epoch 9/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.8705 - acc: 0.3079 - mean_squared_error: 0.0456\n",
      "Epoch 10/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.7776 - acc: 0.3382 - mean_squared_error: 0.0434\n",
      "Epoch 11/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7205 - acc: 0.3691 - mean_squared_error: 0.0409\n",
      "Epoch 12/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7784 - acc: 0.3354 - mean_squared_error: 0.0433\n",
      "Epoch 13/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.8411 - acc: 0.2941 - mean_squared_error: 0.0459\n",
      "Epoch 14/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7176 - acc: 0.3508 - mean_squared_error: 0.0413\n",
      "Epoch 15/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6907 - acc: 0.3726 - mean_squared_error: 0.0399\n",
      "Epoch 16/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7080 - acc: 0.3560 - mean_squared_error: 0.0408\n",
      "Epoch 17/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6968 - acc: 0.3655 - mean_squared_error: 0.0401\n",
      "Epoch 18/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6806 - acc: 0.3701 - mean_squared_error: 0.0397\n",
      "Epoch 19/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7221 - acc: 0.3397 - mean_squared_error: 0.0417\n",
      "Epoch 20/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7109 - acc: 0.3575 - mean_squared_error: 0.0406\n",
      "Epoch 21/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.9043 - acc: 0.3224 - mean_squared_error: 0.0458\n",
      "Epoch 22/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7384 - acc: 0.3561 - mean_squared_error: 0.0420\n",
      "Epoch 23/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6635 - acc: 0.3926 - mean_squared_error: 0.0395\n",
      "Epoch 24/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6559 - acc: 0.3643 - mean_squared_error: 0.0392\n",
      "Epoch 25/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6654 - acc: 0.3732 - mean_squared_error: 0.0393\n",
      "Epoch 26/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.8904 - acc: 0.3112 - mean_squared_error: 0.0455\n",
      "Epoch 27/150\n",
      "64000/64000 [==============================] - 1s 8us/step - loss: 1.9420 - acc: 0.2988 - mean_squared_error: 0.0466\n",
      "Epoch 28/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.7102 - acc: 0.3633 - mean_squared_error: 0.0408\n",
      "Epoch 29/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6924 - acc: 0.3660 - mean_squared_error: 0.0403\n",
      "Epoch 30/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6747 - acc: 0.3701 - mean_squared_error: 0.0396\n",
      "Epoch 31/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6602 - acc: 0.3738 - mean_squared_error: 0.0391\n",
      "Epoch 32/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.6592 - acc: 0.3753 - mean_squared_error: 0.0391\n",
      "Epoch 33/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 1.6580 - acc: 0.3762 - mean_squared_error: 0.0391\n",
      "Epoch 34/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6575 - acc: 0.3760 - mean_squared_error: 0.0391\n",
      "Epoch 35/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6579 - acc: 0.3748 - mean_squared_error: 0.0391\n",
      "Epoch 36/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6566 - acc: 0.3751 - mean_squared_error: 0.0391\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6557 - acc: 0.3746 - mean_squared_error: 0.0391\n",
      "Epoch 38/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6552 - acc: 0.3755 - mean_squared_error: 0.0391\n",
      "Epoch 39/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6552 - acc: 0.3742 - mean_squared_error: 0.0391\n",
      "Epoch 40/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6547 - acc: 0.3744 - mean_squared_error: 0.0391\n",
      "Epoch 41/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6545 - acc: 0.3746 - mean_squared_error: 0.0391\n",
      "Epoch 42/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6566 - acc: 0.3740 - mean_squared_error: 0.0392\n",
      "Epoch 43/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.8310 - acc: 0.3455 - mean_squared_error: 0.0431\n",
      "Epoch 44/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.8265 - acc: 0.3193 - mean_squared_error: 0.0448\n",
      "Epoch 45/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.8394 - acc: 0.2986 - mean_squared_error: 0.0461\n",
      "Epoch 46/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7446 - acc: 0.3490 - mean_squared_error: 0.0424\n",
      "Epoch 47/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7942 - acc: 0.2962 - mean_squared_error: 0.0452\n",
      "Epoch 48/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7226 - acc: 0.3561 - mean_squared_error: 0.0411\n",
      "Epoch 49/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7217 - acc: 0.3523 - mean_squared_error: 0.0414\n",
      "Epoch 50/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6989 - acc: 0.3548 - mean_squared_error: 0.0408\n",
      "Epoch 51/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6664 - acc: 0.3740 - mean_squared_error: 0.0394\n",
      "Epoch 52/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.7348 - acc: 0.3466 - mean_squared_error: 0.0419\n",
      "Epoch 53/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6741 - acc: 0.3724 - mean_squared_error: 0.0395\n",
      "Epoch 54/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6608 - acc: 0.3694 - mean_squared_error: 0.0392\n",
      "Epoch 55/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6587 - acc: 0.3766 - mean_squared_error: 0.0391\n",
      "Epoch 56/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6555 - acc: 0.3735 - mean_squared_error: 0.0391\n",
      "Epoch 57/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6535 - acc: 0.3744 - mean_squared_error: 0.0391\n",
      "Epoch 58/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6527 - acc: 0.3760 - mean_squared_error: 0.0391\n",
      "Epoch 59/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6526 - acc: 0.3760 - mean_squared_error: 0.0391\n",
      "Epoch 60/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6523 - acc: 0.3741 - mean_squared_error: 0.0391\n",
      "Epoch 61/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6519 - acc: 0.3735 - mean_squared_error: 0.0391\n",
      "Epoch 62/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6519 - acc: 0.3752 - mean_squared_error: 0.0391\n",
      "Epoch 63/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6522 - acc: 0.3759 - mean_squared_error: 0.0391\n",
      "Epoch 64/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6523 - acc: 0.3762 - mean_squared_error: 0.0391\n",
      "Epoch 65/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6521 - acc: 0.3757 - mean_squared_error: 0.0391\n",
      "Epoch 66/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6520 - acc: 0.3746 - mean_squared_error: 0.0391\n",
      "Epoch 67/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6526 - acc: 0.3744 - mean_squared_error: 0.0391\n",
      "Epoch 68/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6523 - acc: 0.3746 - mean_squared_error: 0.0391\n",
      "Epoch 69/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6532 - acc: 0.3762 - mean_squared_error: 0.0391\n",
      "Epoch 70/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6518 - acc: 0.3751 - mean_squared_error: 0.0391\n",
      "Epoch 71/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6513 - acc: 0.3761 - mean_squared_error: 0.0391\n",
      "Epoch 72/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6515 - acc: 0.3739 - mean_squared_error: 0.0391\n",
      "Epoch 73/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6510 - acc: 0.3750 - mean_squared_error: 0.0391\n",
      "Epoch 74/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6510 - acc: 0.3758 - mean_squared_error: 0.0391\n",
      "Epoch 75/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6509 - acc: 0.3740 - mean_squared_error: 0.0391\n",
      "Epoch 76/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6513 - acc: 0.3751 - mean_squared_error: 0.0391\n",
      "Epoch 77/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6513 - acc: 0.3759 - mean_squared_error: 0.0391\n",
      "Epoch 78/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6525 - acc: 0.3766 - mean_squared_error: 0.0391\n",
      "Epoch 79/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6520 - acc: 0.3754 - mean_squared_error: 0.0391\n",
      "Epoch 80/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6521 - acc: 0.3750 - mean_squared_error: 0.0391\n",
      "Epoch 81/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6520 - acc: 0.3756 - mean_squared_error: 0.0391\n",
      "Epoch 82/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6513 - acc: 0.3766 - mean_squared_error: 0.0391\n",
      "Epoch 83/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6512 - acc: 0.3763 - mean_squared_error: 0.0391\n",
      "Epoch 84/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6510 - acc: 0.3744 - mean_squared_error: 0.0391\n",
      "Epoch 85/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6512 - acc: 0.3754 - mean_squared_error: 0.0391\n",
      "Epoch 86/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6513 - acc: 0.3765 - mean_squared_error: 0.0391\n",
      "Epoch 87/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6504 - acc: 0.3764 - mean_squared_error: 0.0391\n",
      "Epoch 88/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6506 - acc: 0.3740 - mean_squared_error: 0.0391\n",
      "Epoch 89/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6504 - acc: 0.3755 - mean_squared_error: 0.0391\n",
      "Epoch 90/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6510 - acc: 0.3751 - mean_squared_error: 0.0391\n",
      "Epoch 91/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 1.6509 - acc: 0.3741 - mean_squared_error: 0.0391\n",
      "Epoch 92/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6504 - acc: 0.3751 - mean_squared_error: 0.0391\n",
      "Epoch 93/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 1.6504 - acc: 0.3756 - mean_squared_error: 0.0391\n",
      "Epoch 94/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6503 - acc: 0.3762 - mean_squared_error: 0.0391\n",
      "Epoch 95/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6505 - acc: 0.3753 - mean_squared_error: 0.0391\n",
      "Epoch 96/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.6511 - acc: 0.3783 - mean_squared_error: 0.0391\n",
      "Epoch 97/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 1.8665 - acc: 0.2955 - mean_squared_error: 0.0464\n",
      "Epoch 98/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.2060 - acc: 0.3093 - mean_squared_error: 0.0465\n",
      "Epoch 99/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.8814 - acc: 0.2468 - mean_squared_error: 0.0484\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64000/64000 [==============================] - 0s 3us/step - loss: 3.1409 - acc: 0.1603 - mean_squared_error: 0.0575\n",
      "Epoch 101/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3534 - acc: 0.1821 - mean_squared_error: 0.0522\n",
      "Epoch 102/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1642 - acc: 0.2213 - mean_squared_error: 0.0495\n",
      "Epoch 103/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1218 - acc: 0.2447 - mean_squared_error: 0.0478\n",
      "Epoch 104/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.0949 - acc: 0.2487 - mean_squared_error: 0.0470\n",
      "Epoch 105/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.2246 - acc: 0.2266 - mean_squared_error: 0.0493\n",
      "Epoch 106/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3702 - acc: 0.1532 - mean_squared_error: 0.0553\n",
      "Epoch 107/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3136 - acc: 0.1405 - mean_squared_error: 0.0549\n",
      "Epoch 108/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.2230 - acc: 0.1830 - mean_squared_error: 0.0520\n",
      "Epoch 109/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.2050 - acc: 0.1968 - mean_squared_error: 0.0511\n",
      "Epoch 110/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1744 - acc: 0.2123 - mean_squared_error: 0.0504\n",
      "Epoch 111/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1499 - acc: 0.2385 - mean_squared_error: 0.0490\n",
      "Epoch 112/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1438 - acc: 0.2202 - mean_squared_error: 0.0492\n",
      "Epoch 113/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1290 - acc: 0.2377 - mean_squared_error: 0.0483\n",
      "Epoch 114/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.1345 - acc: 0.2259 - mean_squared_error: 0.0487\n",
      "Epoch 115/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.1312 - acc: 0.2353 - mean_squared_error: 0.0485\n",
      "Epoch 116/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1525 - acc: 0.2142 - mean_squared_error: 0.0497\n",
      "Epoch 117/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.2509 - acc: 0.2212 - mean_squared_error: 0.0503\n",
      "Epoch 118/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.6494 - acc: 0.1322 - mean_squared_error: 0.0574\n",
      "Epoch 119/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.2677 - acc: 0.1928 - mean_squared_error: 0.0527\n",
      "Epoch 120/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.1903 - acc: 0.2284 - mean_squared_error: 0.0495\n",
      "Epoch 121/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3504 - acc: 0.1800 - mean_squared_error: 0.0540\n",
      "Epoch 122/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.2137 - acc: 0.1859 - mean_squared_error: 0.0518\n",
      "Epoch 123/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.4165 - acc: 0.1745 - mean_squared_error: 0.0533\n",
      "Epoch 124/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3863 - acc: 0.1775 - mean_squared_error: 0.0530\n",
      "Epoch 125/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3328 - acc: 0.1871 - mean_squared_error: 0.0511\n",
      "Epoch 126/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3189 - acc: 0.1882 - mean_squared_error: 0.0508\n",
      "Epoch 127/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3160 - acc: 0.1880 - mean_squared_error: 0.0508\n",
      "Epoch 128/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3144 - acc: 0.1877 - mean_squared_error: 0.0508\n",
      "Epoch 129/150\n",
      "64000/64000 [==============================] - 0s 6us/step - loss: 2.3141 - acc: 0.1887 - mean_squared_error: 0.0508\n",
      "Epoch 130/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 2.3133 - acc: 0.1864 - mean_squared_error: 0.0508\n",
      "Epoch 131/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3126 - acc: 0.1883 - mean_squared_error: 0.0508\n",
      "Epoch 132/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3133 - acc: 0.1878 - mean_squared_error: 0.0508\n",
      "Epoch 133/150\n",
      "64000/64000 [==============================] - 0s 5us/step - loss: 2.3128 - acc: 0.1888 - mean_squared_error: 0.0508\n",
      "Epoch 134/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3122 - acc: 0.1900 - mean_squared_error: 0.0508\n",
      "Epoch 135/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3122 - acc: 0.1890 - mean_squared_error: 0.0508\n",
      "Epoch 136/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3118 - acc: 0.1895 - mean_squared_error: 0.0508\n",
      "Epoch 137/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3126 - acc: 0.1873 - mean_squared_error: 0.0508\n",
      "Epoch 138/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3118 - acc: 0.1887 - mean_squared_error: 0.0508\n",
      "Epoch 139/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3115 - acc: 0.1891 - mean_squared_error: 0.0508\n",
      "Epoch 140/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3113 - acc: 0.1864 - mean_squared_error: 0.0508\n",
      "Epoch 141/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3115 - acc: 0.1881 - mean_squared_error: 0.0508\n",
      "Epoch 142/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3118 - acc: 0.1880 - mean_squared_error: 0.0508\n",
      "Epoch 143/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3114 - acc: 0.1893 - mean_squared_error: 0.0508\n",
      "Epoch 144/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3120 - acc: 0.1879 - mean_squared_error: 0.0508\n",
      "Epoch 145/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3139 - acc: 0.1871 - mean_squared_error: 0.0508\n",
      "Epoch 146/150\n",
      "64000/64000 [==============================] - 0s 3us/step - loss: 2.3131 - acc: 0.1867 - mean_squared_error: 0.0508\n",
      "Epoch 147/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3113 - acc: 0.1889 - mean_squared_error: 0.0508\n",
      "Epoch 148/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3113 - acc: 0.1869 - mean_squared_error: 0.0508\n",
      "Epoch 149/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3107 - acc: 0.1887 - mean_squared_error: 0.0508\n",
      "Epoch 150/150\n",
      "64000/64000 [==============================] - 0s 4us/step - loss: 2.3109 - acc: 0.1890 - mean_squared_error: 0.0508\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.53829]\n",
      "Es/No: 16 SER: 0.8122140625 Theor_SER_PAM: 0.3123019621637889\n",
      "(60000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           272         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            34          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2)            4           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2)            0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 2)            0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 2)            0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3)            0           lambda_13[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            8           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            12          dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 8)            40          dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 16)           144         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 514\n",
      "Trainable params: 510\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "60000/60000 [==============================] - 3s 51us/step - loss: 3.8614 - acc: 0.0647 - mean_squared_error: 0.0634\n",
      "Epoch 2/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.7803 - acc: 0.0618 - mean_squared_error: 0.0587\n",
      "Epoch 3/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.6629 - acc: 0.0943 - mean_squared_error: 0.0572\n",
      "Epoch 4/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.4496 - acc: 0.1353 - mean_squared_error: 0.0546\n",
      "Epoch 5/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3670 - acc: 0.1831 - mean_squared_error: 0.0520\n",
      "Epoch 6/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3236 - acc: 0.1885 - mean_squared_error: 0.0508\n",
      "Epoch 7/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3164 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 8/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3132 - acc: 0.1882 - mean_squared_error: 0.0507\n",
      "Epoch 9/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3117 - acc: 0.1902 - mean_squared_error: 0.0507\n",
      "Epoch 10/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3108 - acc: 0.1879 - mean_squared_error: 0.0507\n",
      "Epoch 11/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3102 - acc: 0.1894 - mean_squared_error: 0.0507\n",
      "Epoch 12/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3100 - acc: 0.1882 - mean_squared_error: 0.0507\n",
      "Epoch 13/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3097 - acc: 0.1890 - mean_squared_error: 0.0507\n",
      "Epoch 14/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3094 - acc: 0.1906 - mean_squared_error: 0.0507\n",
      "Epoch 15/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3092 - acc: 0.1867 - mean_squared_error: 0.0507\n",
      "Epoch 16/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3091 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 17/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3089 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 18/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3088 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 19/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3087 - acc: 0.1886 - mean_squared_error: 0.0507\n",
      "Epoch 20/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1883 - mean_squared_error: 0.0507\n",
      "Epoch 21/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 22/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1903 - mean_squared_error: 0.0507\n",
      "Epoch 23/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3084 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 24/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3084 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 25/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 26/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3083 - acc: 0.1902 - mean_squared_error: 0.0507\n",
      "Epoch 27/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3083 - acc: 0.1897 - mean_squared_error: 0.0507\n",
      "Epoch 28/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3082 - acc: 0.1904 - mean_squared_error: 0.0507\n",
      "Epoch 29/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3082 - acc: 0.1890 - mean_squared_error: 0.0507\n",
      "Epoch 30/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3084 - acc: 0.1895 - mean_squared_error: 0.0507\n",
      "Epoch 31/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3084 - acc: 0.1894 - mean_squared_error: 0.0507\n",
      "Epoch 32/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3082 - acc: 0.1887 - mean_squared_error: 0.0507\n",
      "Epoch 33/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1895 - mean_squared_error: 0.0507\n",
      "Epoch 34/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1899 - mean_squared_error: 0.0507\n",
      "Epoch 35/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 36/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 37/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1914 - mean_squared_error: 0.0507\n",
      "Epoch 38/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 39/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1893 - mean_squared_error: 0.0507\n",
      "Epoch 40/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1901 - mean_squared_error: 0.0507\n",
      "Epoch 41/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1910 - mean_squared_error: 0.0507\n",
      "Epoch 42/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1897 - mean_squared_error: 0.0507\n",
      "Epoch 43/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1886 - mean_squared_error: 0.0507\n",
      "Epoch 44/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 45/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1875 - mean_squared_error: 0.0507\n",
      "Epoch 46/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3082 - acc: 0.1874 - mean_squared_error: 0.0507\n",
      "Epoch 47/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3082 - acc: 0.1900 - mean_squared_error: 0.0507\n",
      "Epoch 48/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1899 - mean_squared_error: 0.0507\n",
      "Epoch 49/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1890 - mean_squared_error: 0.0507\n",
      "Epoch 50/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1896 - mean_squared_error: 0.0507\n",
      "Epoch 51/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1899 - mean_squared_error: 0.0507\n",
      "Epoch 52/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1889 - mean_squared_error: 0.0507\n",
      "Epoch 53/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1896 - mean_squared_error: 0.0507\n",
      "Epoch 54/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3082 - acc: 0.1904 - mean_squared_error: 0.0507\n",
      "Epoch 55/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1910 - mean_squared_error: 0.0507\n",
      "Epoch 56/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 57/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 58/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1867 - mean_squared_error: 0.0507\n",
      "Epoch 59/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1907 - mean_squared_error: 0.0507\n",
      "Epoch 60/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3083 - acc: 0.1891 - mean_squared_error: 0.0507\n",
      "Epoch 61/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1864 - mean_squared_error: 0.0507\n",
      "Epoch 62/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1901 - mean_squared_error: 0.0507\n",
      "Epoch 63/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3076 - acc: 0.1883 - mean_squared_error: 0.0507\n",
      "Epoch 64/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1882 - mean_squared_error: 0.0507\n",
      "Epoch 65/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1908 - mean_squared_error: 0.0507\n",
      "Epoch 66/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1895 - mean_squared_error: 0.0507\n",
      "Epoch 67/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1894 - mean_squared_error: 0.0507\n",
      "Epoch 68/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1869 - mean_squared_error: 0.0507\n",
      "Epoch 69/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1877 - mean_squared_error: 0.0507\n",
      "Epoch 70/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 71/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1885 - mean_squared_error: 0.0507\n",
      "Epoch 72/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1887 - mean_squared_error: 0.0507\n",
      "Epoch 73/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 74/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1907 - mean_squared_error: 0.0507\n",
      "Epoch 75/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1885 - mean_squared_error: 0.0507\n",
      "Epoch 76/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1874 - mean_squared_error: 0.0507\n",
      "Epoch 77/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1868 - mean_squared_error: 0.0507\n",
      "Epoch 78/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1881 - mean_squared_error: 0.0507\n",
      "Epoch 79/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 80/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 81/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1908 - mean_squared_error: 0.0507\n",
      "Epoch 82/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1905 - mean_squared_error: 0.0507\n",
      "Epoch 83/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3081 - acc: 0.1891 - mean_squared_error: 0.0507\n",
      "Epoch 84/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 85/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1871 - mean_squared_error: 0.0507\n",
      "Epoch 86/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1877 - mean_squared_error: 0.0507\n",
      "Epoch 87/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1882 - mean_squared_error: 0.0507\n",
      "Epoch 88/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1882 - mean_squared_error: 0.0507\n",
      "Epoch 89/150\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 2.3079 - acc: 0.1883 - mean_squared_error: 0.0507\n",
      "Epoch 90/150\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 2.3076 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 91/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1914 - mean_squared_error: 0.0507\n",
      "Epoch 92/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 93/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1889 - mean_squared_error: 0.0507\n",
      "Epoch 94/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3081 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 95/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1897 - mean_squared_error: 0.0507\n",
      "Epoch 96/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1893 - mean_squared_error: 0.0507\n",
      "Epoch 97/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1892 - mean_squared_error: 0.0507\n",
      "Epoch 98/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3085 - acc: 0.1886 - mean_squared_error: 0.0507\n",
      "Epoch 99/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1876 - mean_squared_error: 0.0507\n",
      "Epoch 100/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1905 - mean_squared_error: 0.0507\n",
      "Epoch 101/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3075 - acc: 0.1895 - mean_squared_error: 0.0507\n",
      "Epoch 102/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1873 - mean_squared_error: 0.0507\n",
      "Epoch 103/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1902 - mean_squared_error: 0.0507\n",
      "Epoch 104/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1883 - mean_squared_error: 0.0507\n",
      "Epoch 105/150\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 2.3079 - acc: 0.1891 - mean_squared_error: 0.0507\n",
      "Epoch 106/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1872 - mean_squared_error: 0.0507\n",
      "Epoch 107/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3080 - acc: 0.1864 - mean_squared_error: 0.0507\n",
      "Epoch 108/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1890 - mean_squared_error: 0.0507\n",
      "Epoch 109/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1903 - mean_squared_error: 0.0507\n",
      "Epoch 110/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1885 - mean_squared_error: 0.0507\n",
      "Epoch 111/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 112/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1886 - mean_squared_error: 0.0507\n",
      "Epoch 113/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1890 - mean_squared_error: 0.0507\n",
      "Epoch 114/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1889 - mean_squared_error: 0.0507\n",
      "Epoch 115/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 116/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1871 - mean_squared_error: 0.0507\n",
      "Epoch 117/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3082 - acc: 0.1886 - mean_squared_error: 0.0507\n",
      "Epoch 118/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 119/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1896 - mean_squared_error: 0.0507\n",
      "Epoch 120/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1887 - mean_squared_error: 0.0507\n",
      "Epoch 121/150\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 2.3079 - acc: 0.1880 - mean_squared_error: 0.0507\n",
      "Epoch 122/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3081 - acc: 0.1877 - mean_squared_error: 0.0507\n",
      "Epoch 123/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 124/150\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 2.3078 - acc: 0.1881 - mean_squared_error: 0.0507\n",
      "Epoch 125/150\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 2.3079 - acc: 0.1880 - mean_squared_error: 0.0507\n",
      "Epoch 126/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3080 - acc: 0.1884 - mean_squared_error: 0.0507\n",
      "Epoch 127/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3081 - acc: 0.1889 - mean_squared_error: 0.0507\n",
      "Epoch 128/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1871 - mean_squared_error: 0.0507\n",
      "Epoch 129/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1894 - mean_squared_error: 0.0507\n",
      "Epoch 130/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1879 - mean_squared_error: 0.0507\n",
      "Epoch 131/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 132/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1877 - mean_squared_error: 0.0507\n",
      "Epoch 133/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1900 - mean_squared_error: 0.0507\n",
      "Epoch 134/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1917 - mean_squared_error: 0.0507\n",
      "Epoch 135/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3079 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 136/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1880 - mean_squared_error: 0.0507\n",
      "Epoch 137/150\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 2.3078 - acc: 0.1880 - mean_squared_error: 0.0507\n",
      "Epoch 138/150\n",
      "60000/60000 [==============================] - 0s 5us/step - loss: 2.3077 - acc: 0.1887 - mean_squared_error: 0.0507\n",
      "Epoch 139/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3078 - acc: 0.1888 - mean_squared_error: 0.0507\n",
      "Epoch 140/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3076 - acc: 0.1893 - mean_squared_error: 0.0507\n",
      "Epoch 141/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1880 - mean_squared_error: 0.0507\n",
      "Epoch 142/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1906 - mean_squared_error: 0.0507\n",
      "Epoch 143/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1875 - mean_squared_error: 0.0507\n",
      "Epoch 144/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3076 - acc: 0.1908 - mean_squared_error: 0.0507\n",
      "Epoch 145/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3078 - acc: 0.1862 - mean_squared_error: 0.0507\n",
      "Epoch 146/150\n",
      "60000/60000 [==============================] - 0s 3us/step - loss: 2.3077 - acc: 0.1865 - mean_squared_error: 0.0507\n",
      "Epoch 147/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3075 - acc: 0.1878 - mean_squared_error: 0.0507\n",
      "Epoch 148/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3077 - acc: 0.1898 - mean_squared_error: 0.0507\n",
      "Epoch 149/150\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 2.3079 - acc: 0.1891 - mean_squared_error: 0.0507\n",
      "Epoch 150/150\n",
      "60000/60000 [==============================] - 0s 4us/step - loss: 2.3079 - acc: 0.1875 - mean_squared_error: 0.0507\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100.241974]\n"
     ]
    }
   ],
   "source": [
    "EsNodB_range = [12,16,20,25,26]\n",
    "N_array=[10000,64000,60000,20000,15000,16000]\n",
    "ser = [None]*len(EsNodB_range)\n",
    "theor_ser_qam = [None]*len(EsNodB_range)\n",
    "theor_ser = [None]*len(EsNodB_range)\n",
    "\n",
    "noise_std = np.sqrt(1)\n",
    "for n in range(0,len(EsNodB_range)):\n",
    "    \n",
    "    EsNo=10.0**(EsNodB_range[n]/10.0)\n",
    "    P = EsNo*(noise_std**2)\n",
    "    \n",
    "    no_errors = 0\n",
    "    \n",
    "    N=N_array[n]\n",
    "   \n",
    "    \n",
    "    autoencoder = set_up_train_nn(P,EsNodB_range[n])\n",
    "    \n",
    "    # generating data for checking SER\n",
    "    N=N*10\n",
    "    test_label = np.random.randint(M,size=N)\n",
    "    test_data = []\n",
    "\n",
    "    for i in test_label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        test_data.append(temp)\n",
    "\n",
    "    test_data = np.array(test_data)\n",
    "    \n",
    "    pred_final_signal = autoencoder.predict(test_data)\n",
    "    \n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ser[n] = no_errors / N \n",
    "    \n",
    "    P_sqrtM = 0.75*special.erfc(np.sqrt(EsNo/10))\n",
    "    theor_ser_qam[n] = 1-(1-P_sqrtM)**2\n",
    "    theor_ser[n] = (15/16)*special.erfc(np.sqrt(EsNo/85))\n",
    "    \n",
    "    print ('Es/No:',EsNodB_range[n],'SER:',ser[n],'Theor_SER_PAM:',theor_ser[n])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EsNodB_range, theor_ser, 'g--',label='16 PAM')\n",
    "plt.plot(EsNodB_range, ser, 'bo-',label='Conventional PD-both streams')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='best',ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
