{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,Callback,ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "from scipy import special\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Power Normalization\n",
    "def fixed_power_norm(x,P):\n",
    "    beta = K.sqrt(K.sum(K.square(x),axis=1))\n",
    "    return   np.sqrt(P)*x / beta[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 4\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 4\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "print('number of symbols:',M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_nn(P):\n",
    "    N=16000\n",
    "    EbNo_train = 5.01187\n",
    "    \n",
    "    label = np.random.randint(M,size=N)\n",
    "    # creating one hot encoded vectors\n",
    "    data = []\n",
    "    for i in label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        data.append(temp)\n",
    "        # checking data shape\n",
    "    data = np.array(data)\n",
    "    print (data.shape)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss',patience=5, verbose=1)\n",
    "    \n",
    "    # Defined Autoencoder\n",
    "    input_signal = Input(shape=(M,))\n",
    "    encoded = Dense(M, activation='relu')(input_signal)\n",
    "    encoded2 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "\n",
    "    # Normalize Power\n",
    "    encoded3 = Lambda(lambda x: fixed_power_norm(x,P))(encoded2)\n",
    "    \n",
    "    #Add antenna noise\n",
    "    encoded5 = Lambda(lambda x: x+K.random_normal_variable((4*4096,2), 0,np.sqrt(1/(2*R*EbNo_train)))[0:tf.shape(x)[0],:])(encoded3)\n",
    "\n",
    "    # Reciever Layer\n",
    "    decoded = Dense(M, activation='relu')(encoded5)\n",
    "    decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "    autoencoder = Model(input_signal, decoded1)\n",
    "\n",
    "    adam = Adam(lr=0.01)\n",
    "    epochs=70\n",
    "    \n",
    "    autoencoder.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "    # traning auto encoder\n",
    "    history = autoencoder.fit(data, data,epochs=epochs,batch_size=2048,callbacks=[es],validation_split=0.3)\n",
    "    \n",
    "    \n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    results = autoencoder.evaluate(data, data, batch_size=2048)\n",
    "    print('test loss, test acc:', results)\n",
    "\n",
    "    # making encoder from full autoencoder\n",
    "    encoder = Model(input_signal, encoded3)\n",
    "        \n",
    "    scatter_plot = []\n",
    "    for i in range(0,M):\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "    scatter_plot = np.array(scatter_plot)\n",
    "    print (scatter_plot.shape)\n",
    "    \n",
    "    # ploting constellation diagram\n",
    "    \n",
    "    scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "\n",
    "    plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "    #plt.axis((-2,2,-2,2))\n",
    "    plt.grid()\n",
    "    #plt.title('Splitting Receiver: rho = '+str(rho)+' P = '+str(P))\n",
    "    plt.xlabel('I Axis')\n",
    "    plt.ylabel('Q Axis')\n",
    "    plt.show()\n",
    "    p_av = np.sum(np.square(scatter_plot),axis=1)\n",
    "    print(sum(p_av)/4)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 4)\n",
      "Train on 11200 samples, validate on 4800 samples\n",
      "Epoch 1/70\n",
      "11200/11200 [==============================] - 1s 98us/step - loss: 1.5957 - acc: 0.2616 - val_loss: 1.4147 - val_acc: 0.4473\n",
      "Epoch 2/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.3344 - acc: 0.5361 - val_loss: 1.2477 - val_acc: 0.5156\n",
      "Epoch 3/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 1.2029 - acc: 0.5066 - val_loss: 1.1481 - val_acc: 0.4979\n",
      "Epoch 4/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.1036 - acc: 0.5024 - val_loss: 1.0491 - val_acc: 0.5006\n",
      "Epoch 5/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.0154 - acc: 0.5050 - val_loss: 0.9647 - val_acc: 0.5048\n",
      "Epoch 6/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.9365 - acc: 0.5157 - val_loss: 0.8974 - val_acc: 0.5142\n",
      "Epoch 7/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.8754 - acc: 0.5240 - val_loss: 0.8451 - val_acc: 0.5146\n",
      "Epoch 8/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.8266 - acc: 0.5225 - val_loss: 0.8017 - val_acc: 0.5225\n",
      "Epoch 9/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.7838 - acc: 0.5425 - val_loss: 0.7663 - val_acc: 0.5450\n",
      "Epoch 10/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.7524 - acc: 0.5751 - val_loss: 0.7343 - val_acc: 0.6258\n",
      "Epoch 11/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.7208 - acc: 0.6581 - val_loss: 0.7010 - val_acc: 0.7112\n",
      "Epoch 12/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.6860 - acc: 0.7427 - val_loss: 0.6629 - val_acc: 0.7831\n",
      "Epoch 13/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.6456 - acc: 0.7960 - val_loss: 0.6206 - val_acc: 0.8183\n",
      "Epoch 14/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.6020 - acc: 0.8395 - val_loss: 0.5739 - val_acc: 0.8833\n",
      "Epoch 15/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.5530 - acc: 0.9134 - val_loss: 0.5254 - val_acc: 0.9515\n",
      "Epoch 16/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.5043 - acc: 0.9605 - val_loss: 0.4710 - val_acc: 0.9731\n",
      "Epoch 17/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.4474 - acc: 0.9771 - val_loss: 0.4111 - val_acc: 0.9835\n",
      "Epoch 18/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3865 - acc: 0.9856 - val_loss: 0.3491 - val_acc: 0.9877\n",
      "Epoch 19/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3240 - acc: 0.9904 - val_loss: 0.2892 - val_acc: 0.9900\n",
      "Epoch 20/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2685 - acc: 0.9923 - val_loss: 0.2352 - val_acc: 0.9923\n",
      "Epoch 21/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.2180 - acc: 0.9936 - val_loss: 0.1902 - val_acc: 0.9942\n",
      "Epoch 22/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.1763 - acc: 0.9941 - val_loss: 0.1545 - val_acc: 0.9956\n",
      "Epoch 23/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.1433 - acc: 0.9957 - val_loss: 0.1275 - val_acc: 0.9958\n",
      "Epoch 24/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.1184 - acc: 0.9963 - val_loss: 0.1073 - val_acc: 0.9960\n",
      "Epoch 25/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.1004 - acc: 0.9961 - val_loss: 0.0922 - val_acc: 0.9971\n",
      "Epoch 26/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0878 - acc: 0.9964 - val_loss: 0.0804 - val_acc: 0.9971\n",
      "Epoch 27/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0764 - acc: 0.9964 - val_loss: 0.0714 - val_acc: 0.9967\n",
      "Epoch 28/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0675 - acc: 0.9965 - val_loss: 0.0640 - val_acc: 0.9967\n",
      "Epoch 29/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0600 - acc: 0.9974 - val_loss: 0.0583 - val_acc: 0.9967\n",
      "Epoch 30/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0560 - acc: 0.9977 - val_loss: 0.0534 - val_acc: 0.9969\n",
      "Epoch 31/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0513 - acc: 0.9971 - val_loss: 0.0494 - val_acc: 0.9969\n",
      "Epoch 32/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0474 - acc: 0.9974 - val_loss: 0.0459 - val_acc: 0.9971\n",
      "Epoch 33/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0451 - acc: 0.9967 - val_loss: 0.0429 - val_acc: 0.9969\n",
      "Epoch 34/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0422 - acc: 0.9975 - val_loss: 0.0402 - val_acc: 0.9969\n",
      "Epoch 35/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0390 - acc: 0.9975 - val_loss: 0.0379 - val_acc: 0.9971\n",
      "Epoch 36/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0371 - acc: 0.9974 - val_loss: 0.0359 - val_acc: 0.9971\n",
      "Epoch 37/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0348 - acc: 0.9977 - val_loss: 0.0341 - val_acc: 0.9973\n",
      "Epoch 38/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0336 - acc: 0.9974 - val_loss: 0.0324 - val_acc: 0.9973\n",
      "Epoch 39/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0320 - acc: 0.9973 - val_loss: 0.0312 - val_acc: 0.9971\n",
      "Epoch 40/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0310 - acc: 0.9976 - val_loss: 0.0296 - val_acc: 0.9973\n",
      "Epoch 41/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0290 - acc: 0.9977 - val_loss: 0.0285 - val_acc: 0.9969\n",
      "Epoch 42/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0291 - acc: 0.9971 - val_loss: 0.0273 - val_acc: 0.9975\n",
      "Epoch 43/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0273 - acc: 0.9981 - val_loss: 0.0261 - val_acc: 0.9973\n",
      "Epoch 44/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0254 - acc: 0.9979 - val_loss: 0.0252 - val_acc: 0.9973\n",
      "Epoch 45/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0249 - acc: 0.9978 - val_loss: 0.0243 - val_acc: 0.9975\n",
      "Epoch 46/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0236 - acc: 0.9979 - val_loss: 0.0235 - val_acc: 0.9973\n",
      "Epoch 47/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0228 - acc: 0.9984 - val_loss: 0.0229 - val_acc: 0.9971\n",
      "Epoch 48/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0229 - acc: 0.9973 - val_loss: 0.0222 - val_acc: 0.9973\n",
      "Epoch 49/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0223 - acc: 0.9974 - val_loss: 0.0213 - val_acc: 0.9975\n",
      "Epoch 50/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0212 - acc: 0.9980 - val_loss: 0.0207 - val_acc: 0.9973\n",
      "Epoch 51/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0201 - acc: 0.9979 - val_loss: 0.0201 - val_acc: 0.9975\n",
      "Epoch 52/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0203 - acc: 0.9975 - val_loss: 0.0196 - val_acc: 0.9975\n",
      "Epoch 53/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0193 - acc: 0.9978 - val_loss: 0.0191 - val_acc: 0.9975\n",
      "Epoch 54/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0186 - acc: 0.9986 - val_loss: 0.0186 - val_acc: 0.9973\n",
      "Epoch 55/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0188 - acc: 0.9977 - val_loss: 0.0181 - val_acc: 0.9975\n",
      "Epoch 56/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0186 - acc: 0.9971 - val_loss: 0.0177 - val_acc: 0.9975\n",
      "Epoch 57/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0170 - acc: 0.9980 - val_loss: 0.0172 - val_acc: 0.9975\n",
      "Epoch 58/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0178 - acc: 0.9978 - val_loss: 0.0169 - val_acc: 0.9973\n",
      "Epoch 59/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0171 - acc: 0.9974 - val_loss: 0.0164 - val_acc: 0.9975\n",
      "Epoch 60/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0165 - acc: 0.9977 - val_loss: 0.0162 - val_acc: 0.9975\n",
      "Epoch 61/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0161 - acc: 0.9976 - val_loss: 0.0159 - val_acc: 0.9975\n",
      "Epoch 62/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0156 - acc: 0.9979 - val_loss: 0.0157 - val_acc: 0.9975\n",
      "Epoch 63/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0146 - acc: 0.9983 - val_loss: 0.0150 - val_acc: 0.9975\n",
      "Epoch 64/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0146 - acc: 0.9983 - val_loss: 0.0148 - val_acc: 0.9975\n",
      "Epoch 65/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0148 - acc: 0.9978 - val_loss: 0.0149 - val_acc: 0.9975\n",
      "Epoch 66/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0143 - acc: 0.9986 - val_loss: 0.0146 - val_acc: 0.9973\n",
      "Epoch 67/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0154 - acc: 0.9973 - val_loss: 0.0139 - val_acc: 0.9975\n",
      "Epoch 68/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0141 - acc: 0.9982 - val_loss: 0.0138 - val_acc: 0.9977\n",
      "Epoch 69/70\n",
      "11200/11200 [==============================] - 0s 1us/step - loss: 0.0139 - acc: 0.9980 - val_loss: 0.0137 - val_acc: 0.9975\n",
      "Epoch 70/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.0138 - acc: 0.9979 - val_loss: 0.0135 - val_acc: 0.9977\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
      "16000/16000 [==============================] - 0s 1us/step\n",
      "test loss, test acc: [0.013339361540973187, 0.9980624995231628]\n",
      "(4, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHjRJREFUeJzt3X+UHWWd5/H3hwRCtNUE0DYEFoJmGJnJTGL3oA67Yzr8SPQPEjFoMv4IDpwcXcAzo6LJsKMeRg5BRpnjDKtmNIDjLI0wgK2GzYake51ZQZNs0PBjQ5qwu6SDgpLgtrSBhO/+UU8zlc693fd2V93bHT6vc+7pqqeep+rT1Z3+pqrurVJEYGZmNlbHNDuAmZkdHVxQzMysEC4oZmZWCBcUMzMrhAuKmZkVwgXFzMwK4YJiZmaFcEExM7NCuKCYmVkhJjc7QCOddNJJcfrpp496/G9+8xte/epXFxeoIM5VH+eqj3PV52jMtW3btl9GxOtH7BgRr5hXW1tbjEV3d/eYxpfFuerjXPVxrvocjbmArVHD31if8jIzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLipmZFaKpBUXSOklPS3qoynJJ+oqkXkk/k/TW3LIVknal14rGpTYzs0qa/cHGW4C/B75VZfm7gNnp9Tbgq8DbJJ0AfA5oBwLYJqkrIvaVntisIPds7+OGDTvZu3+Ak6dN5ao/PNTsSGZj0tQjlIj4IfDsMF0WA99Kn615AJgmaQawENgYEc+mIrIRWFR+YrNi3LO9j9V37aBv/wAB9O0foG/fAPds72t2NLNRG+/XUGYCT+bm96S2au1mE8ING3Yy8OLhRyQvRXDDhp1NSmQ2dso+Vd/EANLpwPcj4vcrLPsBcF1E/Gua3wR8GlgATImIL6T2vwKej4gvVVjHSmAlQGtra1tnZ+eos/b399PS0jLq8WVxrvqMh1w7+p47oq11KvxiAObMfF0TElU3HvZXJc5Vn7Hk6ujo2BYR7SP1a/Y1lJHsAU7NzZ8C7E3t84e091RaQUSsBdYCtLe3x/z58yt1q0lPTw9jGV8W56rPeMh19ZrN9O0fOKztk3MO0vnka7jyA/ObE6qK8bC/KnGu+jQi13g/5dUFfDi92+vtwHMR8RSwAbhA0nRJ04ELUpvZhHDVwjOZeuykw9qOkbhq4ZlNSmQ2dk09QpF0G9mRxkmS9pC9c+tYgIj4GrAeeDfQCzwPfCQte1bSXwNb0qquiYjhLu6bjStL5mWX/PLv8po5/dDL7WYTUVMLSkQsH2F5AJdXWbYOWFdGLrNGWDJv5mEFpKenp3lhzAow3k95mZnZBOGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWCBcUMzMrhAuKmZkVwgXFzMwK4YJiZmaFcEExM7NCuKCYmVkhXFDMzKwQLihmZlYIFxQzMytEUwuKpEWSdkrqlbSqwvIbJT2YXo9J2p9bdii3rKuxyc3MbKimPWBL0iTgJuB8smfEb5HUFRGPDPaJiL/I9b8SmJdbxUBEzG1UXjMzG14zj1DOBnojYndEvAB0AouH6b8cuK0hyczMrG7NLCgzgSdz83tS2xEknQbMAjbnmo+XtFXSA5KWlBfTzMxqoeyx7U3YsHQxsDAiLkvzHwLOjogrK/T9DHBKfpmkkyNir6QzyArNuRHxeIWxK4GVAK2trW2dnZ2jztzf309LS8uox5fFuerjXPVxrvocjbk6Ojq2RUT7iB0joikv4B3Ahtz8amB1lb7bgT8eZl23AEtH2mZbW1uMRXd395jGl8W56uNc9XGu+hyNuYCtUcPf9Wae8toCzJY0S9JxwDLgiHdrSToTmA7cn2ubLmlKmj4JOAd4ZOhYMzNrnKa9yysiDkq6AtgATALWRcTDkq4hq4aDxWU50Jmq5KC3AF+X9BLZdaA1kXt3mJmZNV7TCgpARKwH1g9p++yQ+c9XGPcjYE6p4czMrC7+pLyZmRXCBcXMzArhgmJmZoVwQTEzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLipmZFcIFxczMCuGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWCBcUMzMrRFMLiqRFknZK6pW0qsLySyQ9I+nB9Lost2yFpF3ptaKxyc3MbKimPbFR0iTgJuB8YA+wRVJXhUf53h4RVwwZewLwOaAdCGBbGruvAdHNzKyCZh6hnA30RsTuiHgB6AQW1zh2IbAxIp5NRWQjsKiknGZmVgNFRHM2LC0FFkXEZWn+Q8Db8kcjki4BrgOeAR4D/iIinpT0KeD4iPhC6vdXwEBE/E2F7awEVgK0tra2dXZ2jjpzf38/LS0tox5fFueqj3PVx7nqczTm6ujo2BYR7SP1a9opL0AV2oZWt+8Bt0XEAUkfBW4FFtQ4NmuMWAusBWhvb4/58+ePOnBPTw9jGV8W56qPc9XHuerzSs7VzFNee4BTc/OnAHvzHSLiVxFxIM3+A9BW61gzM2usZhaULcBsSbMkHQcsA7ryHSTNyM1eCDyapjcAF0iaLmk6cEFqMzOzJmnaKa+IOCjpCrJCMAlYFxEPS7oG2BoRXcDHJV0IHASeBS5JY5+V9NdkRQngmoh4tuHfhJmZvayZ11CIiPXA+iFtn81NrwZWVxm7DlhXakAzM6uZPylvZmaFcEExM7NCuKCYmVkhXFDMzKwQLihmZlYIFxQzMyuEC4qZmRXCBcXMzArhgmJmZoVwQTEzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLipmZFaKpBUXSIkk7JfVKWlVh+SckPSLpZ5I2STott+yQpAfTq2voWDMza6ymPWBL0iTgJuB8smfEb5HUFRGP5LptB9oj4nlJHwO+CLw/LRuIiLkNDW1mZlU18wjlbKA3InZHxAtAJ7A43yEiuiPi+TT7AHBKgzOamVmNmllQZgJP5ub3pLZqLgXuzc0fL2mrpAckLSkjoJmZ1U4R0ZwNSxcDCyPisjT/IeDsiLiyQt8PAlcA74yIA6nt5IjYK+kMYDNwbkQ8XmHsSmAlQGtra1tnZ+eoM/f399PS0jLq8WVxrvo4V32cqz5HY66Ojo5tEdE+YseIaMoLeAewITe/Glhdod95wKPAG4ZZ1y3A0pG22dbWFmPR3d09pvFlca76OFd9nKs+R2MuYGvU8He9mae8tgCzJc2SdBywDDjs3VqS5gFfBy6MiKdz7dMlTUnTJwHnAPmL+WZm1mBNe5dXRByUdAWwAZgErIuIhyVdQ1YNu4AbgBbgDkkA/zciLgTeAnxd0ktk14HWxOHvDjMzswZrWkEBiIj1wPohbZ/NTZ9XZdyPgDnlpjMzs3r4k/JmZlYIFxQzMytEU095mZlZOe7Z3scNG3ayd/8AJ0+bylV/eKj0bfoIxczsKHPP9j5W37WDvv0DBNC3f4C+fQPcs72v1O3WVVDS23X/oKwwZmY2djds2MnAi4cfkbwUwQ0bdpa63RELiqQeSa+VdALwU+BmSV8uNZWZmY3a3v0DdbUXpZYjlNdFxK+Bi4CbI6KN7NPrZmY2Dp08bWpd7UWppaBMljQDeB/w/VLTmJnZmF218EymHjvpsLZjJK5aeGap263lXV7XkH2a/V8jYku6GeOuUlOZmdmoLZmX3bg9/y6vmdMPvdxelhELSkTcAdyRm98NvLfMUGZmNjZL5s08rID09PSUvs2qBUXSpyPii5L+DjjiHvcR8fFSk5mZ2YQy3BHKo+nr1kYEMTOzia1qQYmI76XJ2yPit/ll6ZbxZmZmL6vlXV4/kfT2wRlJ7wV+VF4kMzObiGp5l9cHgHWSeoCTgROBBWWGMjOziWfEI5SI2AFcC3wU6ACuiIg9RWxc0iJJOyX1SlpVYfkUSben5T+WdHpu2erUvlPSwiLyVHPP9j7OWbOZHX3Pcc6azaXfD8fMbCKq5dYr3wT+HPgD4CPA9yRdPtYNS5oE3AS8CzgLWC7prCHdLgX2RcSbgRuB69PYs8geGfx7wCLgP6f1FS5/kzXIbrK2+q4dLipmZkPUcg3lIaAjIp6IiA3A24F5BWz7bKA3InZHxAtAJ7B4SJ/FwK1p+k7gXGXPAl4MdEbEgYh4AuhN6ytcpZusDbx4qPSbrJmZTTS1nPK6MSLyn0N5LVDEX9OZwJO5+T2prWKfiDgIPEd2DaeWsYVo1k3WzMwmmpoesJXeJnwxsJzsD/fdBWxbFdqGfoCyWp9axmYrkFYCKwFaW1vr/rToqrkv8cKhlwBonQqfnHMQgOMmHdOQT57Wor+/f9xkyXOu+jhXfZyrPo3INdwn5V8DvAf4U+B3yIrIGRFxSkHb3gOcmps/Bdhbpc8eSZOB1wHP1jgWgIhYC6wFaG9vj/nz59cVcn+6hjLw4iE+OecgX9oxmanHTuK6i+Ywv+T74tSqp6eHer+vRnCu+jhXfZyrPo3INdwpr6fJLopfC7wpIj4JvFDgtrcAsyXNknQc2UX2riF9uoAVaXopsDmdfusClqV3gc0CZgM/KTDby5bMm8l1F81hZrrt88xpU7nuojml32TNzGyiGe6U11+S/ZH/KvBfJN1e5IYj4qCkK8juZDwJWBcRD0u6BtgaEV3AN4F/lNRLdmSyLI19WNJ3gEeAg8DlEVHaA5MHb7LW09PDlR+YX9ZmzMwmtOFuvXIjcGO6Xf1y4B7gZEmfAe6OiMfGuvGIWA+sH9L22dz0b8mu3VQaey3Z0ZOZmY0DtbzLa3dEXBsRc4A/IruOcW/pyczMbEKp5XMoL4uIHRHxlxHxprICmZnZxFRXQTEzM6vGBcXMzAox4gcbJb0KeHOa3RkRB8qNZGZmE1HVIxRJx0r6W7IPEd5Mdk+t3YN3BZZUxP28zMzsKDHcEcqXgFcBp0XE/wOQ9FrgbyR9lewuv7PKj2hmZhPBcAXl3cDs/I0hI+LXkj4G/JLstvNmZmbA8BflXxpyl2EA0ifSn4mIB8qLZWZmE81wBeURSR8e2ijpg8Cj5UUyM7OJaLhTXpcDd0n6M2Ab2e3h/wiYSnYXYjMzs5cNdy+vPuBtkhaQPWpXwL0RsalR4czMbOIY8XMoEbEZ2NyALGZmNoH5k/JmZlYIFxQzMyuEC4qZmRWiKQVF0gmSNkralb5Or9BnrqT7JT0s6WeS3p9bdoukJyQ9mF5zG/sdmJnZUM06QlkFbIqI2cCmND/U88CHI+L3yG7z8reSpuWWXxURc9PrwfIjm5nZcJpVUBaT3WyS9HXJ0A4R8VhE7ErTe4Gngdc3LKGZmdWlWQWlNSKeAkhf3zBcZ0lnA8cBj+ear02nwm6UNKW8qGZmVgtVuF1XMSuW7gPeWGHR1cCtETEt13dfRBxxHSUtmwH0ACsG7x+W2n5OVmTWAo9HxDVVxq8EVgK0tra2dXZ2jvp76u/vp6WlZdTjy+Jc9XGu+jhXfY7GXB0dHdsion3EjhHR8BewE5iRpmeQPbirUr/XAv8TuHiYdc0Hvl/Ldtva2mIsuru7xzS+LM5VH+eqj3PV52jMBWyNGv7GNuuUVxewIk2vAL47tIOk44C7gW9FxB1Dls1IX0V2/eWhUtOamdmImlVQ1gDnS9oFnJ/mkdQu6Rupz/uAPwEuqfD24H+StAPYAZwEfKGx8c3MbKgR7+VVhoj4FXBuhfatwGVp+tvAt6uMX1BqQDMzq5s/KW9mZoVwQTEzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLipmZFcIFxczMCuGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWCBcUMzMrhAuKmZkVoikFRdIJkjZK2pW+Vnue/KHcw7W6cu2zJP04jb89Pd3RzMyaqFlHKKuATRExG9iU5isZiIi56XVhrv164MY0fh9wablxzcxsJM0qKIuBW9P0rWTPha9Jeo78AuDO0Yw3M7NyNKugtEbEUwDp6xuq9Dte0lZJD0gaLBonAvsj4mCa3wPMLDeumZmNRBFRzoql+4A3Vlh0NXBrREzL9d0XEUdcR5F0ckTslXQGsJnsOfS/Bu6PiDenPqcC6yNiTpUcK4GVAK2trW2dnZ2j/p76+/tpaWkZ9fiyOFd9nKs+zlWfozFXR0fHtohoH7FjRDT8BewEZqTpGcDOGsbcAiwFBPwSmJza3wFsqGW7bW1tMRbd3d1jGl8W56qPc9XHuepzNOYCtkYNf2ObdcqrC1iRplcA3x3aQdJ0SVPS9EnAOcAj6ZvrJisuVcebmVljNaugrAHOl7QLOD/NI6ld0jdSn7cAWyX9lKyArImIR9KyzwCfkNRLdk3lmw1Nb2ZmR5jcjI1GxK/IrocMbd8KXJamfwRUvC4SEbuBs8vMaGZm9fEn5c3MrBAuKGZmVggXFDMzK4QLipmZFcIFxczMCuGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWCBcUMzMrhAuKmZkVwgXFzMwK4YJiZmaFcEExM7NCuKCYmVkhmlJQJJ0gaaOkXenr9Ap9OiQ9mHv9VtKStOwWSU/kls1t/HdhZmZ5zTpCWQVsiojZwKY0f5iI6I6IuRExF1gAPA/8t1yXqwaXR8SDDUltZmZVNaugLAZuTdO3AktG6L8UuDcini81lZmZjZoiovEblfZHxLTc/L6IOOK0V275ZuDLEfH9NH8L8A7gAOkIJyIOVBm7ElgJ0Nra2tbZ2Tnq3P39/bS0tIx6fFmcqz7OVR/nqs/RmKujo2NbRLSP2DEiSnkB9wEPVXgtBvYP6btvmPXMAJ4Bjh3SJmAK2RHOZ2vJ1NbWFmPR3d09pvFlca76OFd9nKs+R2MuYGvU8Dd28qjKVQ0i4rxqyyT9QtKMiHhK0gzg6WFW9T7g7oh4Mbfup9LkAUk3A58qJLSZmY1as66hdAEr0vQK4LvD9F0O3JZvSEUISSK7/vJQCRnNzKwOzSooa4DzJe0Czk/zSGqX9I3BTpJOB04F/vuQ8f8kaQewAzgJ+EIDMpuZ2TBKO+U1nIj4FXBuhfatwGW5+f8NzKzQb0GZ+czMrH7+pLyZmRXCBcXMzArhgmJmZoVwQTEzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLipmZFcIFxczMCuGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWiKYUFEkXS3pY0kuSqj74XtIiSTsl9UpalWufJenHknZJul3ScY1JbmZm1TTrCOUh4CLgh9U6SJoE3AS8CzgLWC7prLT4euDGiJgN7AMuLTeuWXPcs72Pc9ZsZtaqH3DOms3cs72v2ZHMqmpKQYmIRyNi5wjdzgZ6I2J3RLwAdAKL03PkFwB3pn63kj1X3uyocs/2PlbftYO+/QME0Ld/gNV37XBRsXFrPF9DmQk8mZvfk9pOBPZHxMEh7WZHlRs27GTgxUOHtQ28eIgbNoz0fzGz5lBElLNi6T7gjRUWXR0R3019eoBPpWfJDx1/MbAwIi5L8x8iO2q5Brg/It6c2k8F1kfEnCo5VgIrAVpbW9s6OztH/T319/fT0tIy6vFlca76TJRcO/qeq9p3zszXNSISMHH213hxNObq6OjYFhFVr3cPmjyqtdcgIs4b4yr2AKfm5k8B9gK/BKZJmpyOUgbbq+VYC6wFaG9vj/nz5486UE9PD2MZXxbnqs9EyXX1ms307R84ot/MaVO58gPzj2hvVK7xwrnq04hc4/mU1xZgdnpH13HAMqArskOqbmBp6rcC+G6TMpqV5qqFZzL12EmHtU09dhJXLTyzSYnMhtestw2/R9Ie4B3ADyRtSO0nS1oPkI4+rgA2AI8C34mIh9MqPgN8QlIv2TWVbzb6ezAr25J5M7nuojnMnDYVkR2ZXHfRHJbM8yVDG59KO+U1nIi4G7i7Qvte4N25+fXA+gr9dpNdTzE7qi2ZN9MFxCaM8XzKy8zMJhAXFDMzK4QLipmZFcIFxczMCuGCYmZmhXBBMTOzQpR265XxSNIzwP8ZwypOIvuk/njjXPVxrvo4V32OxlynRcTrR+r0iiooYyVpay33s2k056qPc9XHuerzSs7lU15mZlYIFxQzMyuEC0p91jY7QBXOVR/nqo9z1ecVm8vXUMzMrBA+QjEzs0K4oAwh6WJJD0t6SVLVd0RIWiRpp6ReSaty7bMk/VjSLkm3p2e5FJHrBEkb03o3SppeoU+HpAdzr99KWpKW3SLpidyyuY3Klfodym27K9fezP01V9L96ef9M0nvzy0rdH9V+33JLZ+Svv/etD9Ozy1bndp3Slo4lhx1ZvqEpEfSvtkk6bTcsoo/zwblukTSM7ntX5ZbtiL9zHdJWtHgXDfmMj0maX9uWZn7a52kpyU9VGW5JH0l5f6ZpLfmlhW7vyLCr9wLeAtwJtADtFfpMwl4HDgDOA74KXBWWvYdYFma/hrwsYJyfRFYlaZXAdeP0P8E4FngVWn+FmBpCfurplxAf5X2pu0v4HeA2Wn6ZOApYFrR+2u435dcn/8IfC1NLwNuT9Nnpf5TgFlpPZMalKkj9/vzscFMw/08G5TrEuDvK4w9Adidvk5P09MblWtI/yuBdWXvr7TuPwHeCjxUZfm7gXsBAW8HflzW/vIRyhAR8WhE7Byh29lAb0TsjogXgE5gsSQBC4A7U79bgSUFRVuc1lfrepcC90bE8wVtv5p6c72s2fsrIh6LiF1pei/wNDDih7dGoeLvyzB57wTOTftnMdAZEQci4gmgl2KeBTRipojozv3+PED2uO2y1bKvqlkIbIyIZyNiH7ARWNSkXMuB2wra9rAi4odk/3msZjHwrcg8QPYI9RmUsL9cUEZnJvBkbn5PajsR2B/Z0ybz7UVojYinANLXN4zQfxlH/kJfmw55b5Q0pcG5jpe0VdIDg6fhGEf7S9LZZP/zfDzXXNT+qvb7UrFP2h/Pke2fWsaWlSnvUrL/5Q6q9PMsQq253pt+NndKOrXOsWXmIp0anAVszjWXtb9qUS174furKU9sbDZJ9wFvrLDo6oio5fn0qtAWw7SPOVet60jrmQHMIXt88qDVwM/J/miuJXuM8jUNzPXvImKvpDOAzZJ2AL+u0K9Z++sfgRUR8VJqHvX+qrSJCm1Dv89SfqeGUfN6JX0QaAfemWs+4ucZEY9XGl9Cru8Bt0XEAUkfJTuyW1Dj2DJzDVoG3BkRh3JtZe2vWjTsd+sVWVAi4rwxrmIPcGpu/hRgL9l9cqZJmpz+lznYPuZckn4haUZEPJX+AD49zKreB9wdES/m1v1Umjwg6WbgU43MlU4pERG7JfUA84B/psn7S9JrgR8A/ymdDhhc96j3VwXVfl8q9dkjaTLwOrLTGLWMLSsTks4jK9DvjIgDg+1Vfp5F/IEcMVdE/Co3+w/A9bmx84eM7SkgU025cpYBl+cbStxftaiWvfD95VNeo7MFmK3sHUrHkf0CdUV2paub7PoFwAqgliOeWnSl9dWy3iPO36Y/qoPXLZYAFd8RUkYuSdMHTxlJOgk4B3ik2fsr/ezuJju/fMeQZUXur4q/L8PkXQpsTvunC1im7F1gs4DZwE/GkKXmTJLmAV8HLoyIp3PtFX+eBWSqNdeM3OyFwKNpegNwQco3HbiAw4/SS82Vsp1JdoH7/lxbmfurFl3Ah9O7vd4OPJf+w1T8/irrnQcT9QW8h6xyHwB+AWxI7ScD63P93g08Rva/jKtz7WeQ/YPvBe4AphSU60RgE7ArfT0htbcD38j1Ox3oA44ZMn4zsIPsD+O3gZZG5QL+OG37p+nrpeNhfwEfBF4EHsy95paxvyr9vpCdQrswTR+fvv/etD/OyI29Oo3bCbyrwN/1kTLdl/4NDO6brpF+ng3KdR3wcNp+N/C7ubF/lvZhL/CRRuZK858H1gwZV/b+uo3sHYovkv3tuhT4KPDRtFzATSn3DnLvXi16f/mT8mZmVgif8jIzs0K4oJiZWSFcUMzMrBAuKGZmVggXFDMzK4QLilkJJPUPs+w9kkLS79awnnZJXyk2nVk5/LZhsxJI6o+IlirLvgPMADZFxOcbGsysRD5CMWsgSS1kn5S+lOzT1oPt75F0X/o08wxlz9N4o6T5kr6f+rxT//ZMje2SXtOkb8OsIhcUs8ZaAvzXiHgMeFbpYUcRcTfZzSgvJ7s/1eci4udDxn4KuDwi5gL/ARhoXGyzkbmgmDXWcrJnaZC+Ls8tu5LsLscHIqLSszT+B/BlSR8nexDYwQp9zJrmFXm3YbNmkHQi2W3Wf19SkD0FMCR9OrKLmTOBl4BWScfEv91KH4CIWCPpB2T3lHpA0nkR8b8a/G2YVeUjFLPGWUp2Z+PTIuL0iDgVeAL49+mW9TcDf0p299xPDB0s6U0RsSMirge2AiO+S8yskXyEYtY4y4E1Q9r+mayIdAD/EhH/IulBYEs6Gsn7c0kdwCGy25/fi9k44rcNm5lZIXzKy8zMCuGCYmZmhXBBMTOzQrigmJlZIVxQzMysEC4oZmZWCBcUMzMrhAuKmZkV4v8Dmzb3mg1oODoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = set_up_train_nn(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
