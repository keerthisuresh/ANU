{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 16\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 16\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "\n",
    "#Power splitting ratio\n",
    "rho = 0\n",
    "eps=1\n",
    "eta=1\n",
    "print('number of symbols:',M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_nn(P):\n",
    "    label = np.random.randint(M,size=N)\n",
    "\n",
    "    # creating one hot encoded vectors\n",
    "    data = []\n",
    "    for i in label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        data.append(temp)\n",
    "\n",
    "    # checking data shape\n",
    "    data = np.array(data)\n",
    "    print (data.shape)\n",
    "\n",
    "\n",
    "    # Defined Autoencoder\n",
    "    batch_size = 4096\n",
    "    \n",
    "    # Transmitter Layers\n",
    "    input_signal = Input(shape=(M,))\n",
    "    encoded = Dense(M, activation='relu')(input_signal)\n",
    "    encoded = Dense(8,activation='relu')(encoded)\n",
    "    encoded = Dense(4,activation='relu')(encoded)\n",
    "    encoded2 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "\n",
    "    # Normalize Power\n",
    "    encoded3 = BatchNormalization(momentum=0,epsilon=1e-6,center=False,scale=False,axis=1)(encoded2)\n",
    "    encoded3 = Lambda(lambda x: x*np.sqrt(P/2))(encoded3)\n",
    "\n",
    "    #adding channel noise\n",
    "    encoded4 = Lambda(lambda x: x+K.random_normal_variable((32768*2,2), 0,np.sqrt(0))[0:tf.shape(x)[0],:])(encoded3)\n",
    "\n",
    "\n",
    "    # Slicing into CD and PD data, and applying noise\n",
    "\n",
    "    cd_data = Lambda(lambda x: np.sqrt(rho)*np.sqrt(eps)*x)(encoded4)\n",
    "    cd_data = Lambda(lambda x: x+K.random_normal_variable((32768*2,2), 0,np.sqrt(0.5))[0:tf.shape(x)[0],:])(cd_data)\n",
    "\n",
    "    \n",
    "    pd_data = Lambda(lambda x: K.expand_dims((1-rho)*eta*eps*K.sum(K.square(x),axis=1),axis=1))(encoded4)\n",
    "    pd_data = Lambda(lambda x: x+K.random_normal_variable((32768*2,1), 0,np.sqrt(1))[0:tf.shape(x)[0]])(pd_data)\n",
    "\n",
    "    #combining the split data to feed the decoder\n",
    "    data_split=[]\n",
    "    data_split.append(cd_data)\n",
    "    data_split.append(pd_data)\n",
    "\n",
    "    data_split =  Concatenate(axis=1)(data_split)\n",
    "\n",
    "\n",
    "    # Reciever Layer\n",
    "    decoded = Dense(2, activation='linear')(data_split)\n",
    "    decoded = Dense(4, activation='relu')(decoded)\n",
    "    decoded = Dense(8, activation='relu')(decoded)\n",
    "    decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "    autoencoder = Model(input_signal, decoded1)\n",
    "\n",
    "    adam = Adam(lr=0.075)\n",
    "    sgd = SGD(lr=0.5)\n",
    "    autoencoder.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy','mse'])\n",
    "\n",
    "    # printing summary of layers and it's trainable parameters \n",
    "    print (autoencoder.summary())\n",
    "\n",
    "    # traning auto encoder\n",
    "    autoencoder.fit(data, data,\n",
    "                    epochs=200,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "    # making encoder from full autoencoder\n",
    "    encoder = Model(input_signal, encoded3)\n",
    "\n",
    "    # for plotting learned consteallation diagram\n",
    "\n",
    "    scatter_plot = []\n",
    "    for i in range(0,M):\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "    scatter_plot = np.array(scatter_plot)\n",
    "    print (scatter_plot.shape)\n",
    "\n",
    "    # ploting constellation diagram\n",
    "    import matplotlib.pyplot as plt\n",
    "    scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "\n",
    "    plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "    #plt.axis((-2,2,-2,2))\n",
    "    plt.grid()\n",
    "    #plt.title('Splitting Receiver: rho = '+str(rho)+' eps = '+str(eps))\n",
    "    plt.xlabel('I Axis')\n",
    "    plt.ylabel('Q Axis')\n",
    "    plt.show()\n",
    "    p_av = np.sum(np.square(scatter_plot),axis=1)\n",
    "    print(sum(p_av)/16)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17000, 16)\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           272         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 8)            136         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 4)            36          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            10          dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2)            4           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 2)            0           lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 1)            0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           lambda_4[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 2)            8           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            12          dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            40          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           144         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 662\n",
      "Trainable params: 658\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "17000/17000 [==============================] - 3s 185us/step - loss: 2.6907 - acc: 0.0458 - mean_squared_error: 0.0580\n",
      "Epoch 2/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 2.1998 - acc: 0.1263 - mean_squared_error: 0.0533\n",
      "Epoch 3/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.9054 - acc: 0.2398 - mean_squared_error: 0.0506\n",
      "Epoch 4/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.7518 - acc: 0.3170 - mean_squared_error: 0.0490\n",
      "Epoch 5/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.6087 - acc: 0.3474 - mean_squared_error: 0.0467\n",
      "Epoch 6/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 1.5183 - acc: 0.3848 - mean_squared_error: 0.0453\n",
      "Epoch 7/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.4834 - acc: 0.3525 - mean_squared_error: 0.0452\n",
      "Epoch 8/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.4468 - acc: 0.3681 - mean_squared_error: 0.0446\n",
      "Epoch 9/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.3545 - acc: 0.4191 - mean_squared_error: 0.0426\n",
      "Epoch 10/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.3005 - acc: 0.4043 - mean_squared_error: 0.0417\n",
      "Epoch 11/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 1.2787 - acc: 0.4133 - mean_squared_error: 0.0413\n",
      "Epoch 12/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 1.2510 - acc: 0.4348 - mean_squared_error: 0.0409\n",
      "Epoch 13/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 1.2390 - acc: 0.4151 - mean_squared_error: 0.0413\n",
      "Epoch 14/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 1.2083 - acc: 0.4445 - mean_squared_error: 0.0403\n",
      "Epoch 15/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 1.2514 - acc: 0.3826 - mean_squared_error: 0.0411\n",
      "Epoch 16/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 1.2424 - acc: 0.4051 - mean_squared_error: 0.0408\n",
      "Epoch 17/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.2191 - acc: 0.4502 - mean_squared_error: 0.0402\n",
      "Epoch 18/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.1930 - acc: 0.4171 - mean_squared_error: 0.0399\n",
      "Epoch 19/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.1361 - acc: 0.4992 - mean_squared_error: 0.0380\n",
      "Epoch 20/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 1.0953 - acc: 0.4874 - mean_squared_error: 0.0374\n",
      "Epoch 21/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0585 - acc: 0.4935 - mean_squared_error: 0.0361\n",
      "Epoch 22/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0322 - acc: 0.5171 - mean_squared_error: 0.0356\n",
      "Epoch 23/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0203 - acc: 0.5259 - mean_squared_error: 0.0349\n",
      "Epoch 24/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9993 - acc: 0.5170 - mean_squared_error: 0.0347\n",
      "Epoch 25/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0376 - acc: 0.5102 - mean_squared_error: 0.0358\n",
      "Epoch 26/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0304 - acc: 0.5041 - mean_squared_error: 0.0357\n",
      "Epoch 27/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0419 - acc: 0.4942 - mean_squared_error: 0.0362\n",
      "Epoch 28/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 1.0572 - acc: 0.4644 - mean_squared_error: 0.0365\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 0s 7us/step - loss: 1.3446 - acc: 0.3579 - mean_squared_error: 0.0444\n",
      "Epoch 30/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 1.1645 - acc: 0.4196 - mean_squared_error: 0.0398\n",
      "Epoch 31/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 1.0971 - acc: 0.4703 - mean_squared_error: 0.0382\n",
      "Epoch 32/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 1.0651 - acc: 0.4676 - mean_squared_error: 0.0373\n",
      "Epoch 33/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 1.0766 - acc: 0.4642 - mean_squared_error: 0.0371\n",
      "Epoch 34/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 1.0010 - acc: 0.5032 - mean_squared_error: 0.0350\n",
      "Epoch 35/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 1.0197 - acc: 0.4748 - mean_squared_error: 0.0356\n",
      "Epoch 36/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 1.0151 - acc: 0.5018 - mean_squared_error: 0.0356\n",
      "Epoch 37/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9671 - acc: 0.5168 - mean_squared_error: 0.0339\n",
      "Epoch 38/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9800 - acc: 0.4975 - mean_squared_error: 0.0345\n",
      "Epoch 39/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.9455 - acc: 0.5372 - mean_squared_error: 0.0335\n",
      "Epoch 40/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.9163 - acc: 0.5377 - mean_squared_error: 0.0327\n",
      "Epoch 41/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8906 - acc: 0.5908 - mean_squared_error: 0.0314\n",
      "Epoch 42/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.9368 - acc: 0.5589 - mean_squared_error: 0.0326\n",
      "Epoch 43/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9951 - acc: 0.4951 - mean_squared_error: 0.0354\n",
      "Epoch 44/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.9482 - acc: 0.5528 - mean_squared_error: 0.0332\n",
      "Epoch 45/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9157 - acc: 0.5642 - mean_squared_error: 0.0326\n",
      "Epoch 46/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9258 - acc: 0.5686 - mean_squared_error: 0.0327\n",
      "Epoch 47/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8698 - acc: 0.5884 - mean_squared_error: 0.0307\n",
      "Epoch 48/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8586 - acc: 0.6207 - mean_squared_error: 0.0298\n",
      "Epoch 49/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8510 - acc: 0.5995 - mean_squared_error: 0.0298\n",
      "Epoch 50/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8939 - acc: 0.5771 - mean_squared_error: 0.0316\n",
      "Epoch 51/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.9045 - acc: 0.5734 - mean_squared_error: 0.0321\n",
      "Epoch 52/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8990 - acc: 0.5725 - mean_squared_error: 0.0315\n",
      "Epoch 53/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.9712 - acc: 0.5171 - mean_squared_error: 0.0345\n",
      "Epoch 54/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.9552 - acc: 0.5529 - mean_squared_error: 0.0339\n",
      "Epoch 55/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8958 - acc: 0.5912 - mean_squared_error: 0.0314\n",
      "Epoch 56/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8677 - acc: 0.5966 - mean_squared_error: 0.0303\n",
      "Epoch 57/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8433 - acc: 0.6201 - mean_squared_error: 0.0295\n",
      "Epoch 58/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.8290 - acc: 0.6457 - mean_squared_error: 0.0288\n",
      "Epoch 59/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8429 - acc: 0.6187 - mean_squared_error: 0.0297\n",
      "Epoch 60/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8724 - acc: 0.5779 - mean_squared_error: 0.0309\n",
      "Epoch 61/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8884 - acc: 0.5894 - mean_squared_error: 0.0312\n",
      "Epoch 62/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.9133 - acc: 0.5553 - mean_squared_error: 0.0328\n",
      "Epoch 63/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.9281 - acc: 0.5568 - mean_squared_error: 0.0334\n",
      "Epoch 64/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.9061 - acc: 0.5602 - mean_squared_error: 0.0325\n",
      "Epoch 65/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8530 - acc: 0.6028 - mean_squared_error: 0.0303\n",
      "Epoch 66/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8700 - acc: 0.5994 - mean_squared_error: 0.0311\n",
      "Epoch 67/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8448 - acc: 0.6140 - mean_squared_error: 0.0298\n",
      "Epoch 68/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8077 - acc: 0.6409 - mean_squared_error: 0.0280\n",
      "Epoch 69/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8187 - acc: 0.6256 - mean_squared_error: 0.0287\n",
      "Epoch 70/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8695 - acc: 0.6149 - mean_squared_error: 0.0307\n",
      "Epoch 71/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8082 - acc: 0.6415 - mean_squared_error: 0.0280\n",
      "Epoch 72/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7912 - acc: 0.6595 - mean_squared_error: 0.0273\n",
      "Epoch 73/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.7846 - acc: 0.6509 - mean_squared_error: 0.0271\n",
      "Epoch 74/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8116 - acc: 0.6419 - mean_squared_error: 0.0281\n",
      "Epoch 75/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.7655 - acc: 0.6679 - mean_squared_error: 0.0264\n",
      "Epoch 76/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.7570 - acc: 0.6654 - mean_squared_error: 0.0259\n",
      "Epoch 77/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8584 - acc: 0.6009 - mean_squared_error: 0.0303\n",
      "Epoch 78/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8804 - acc: 0.5855 - mean_squared_error: 0.0312\n",
      "Epoch 79/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8957 - acc: 0.5722 - mean_squared_error: 0.0315\n",
      "Epoch 80/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 1.0547 - acc: 0.4638 - mean_squared_error: 0.0386\n",
      "Epoch 81/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8484 - acc: 0.6139 - mean_squared_error: 0.0294\n",
      "Epoch 82/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.9521 - acc: 0.5446 - mean_squared_error: 0.0340\n",
      "Epoch 83/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8929 - acc: 0.5841 - mean_squared_error: 0.0309\n",
      "Epoch 84/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8171 - acc: 0.6262 - mean_squared_error: 0.0285\n",
      "Epoch 85/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7839 - acc: 0.6508 - mean_squared_error: 0.0273\n",
      "Epoch 86/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.7503 - acc: 0.6759 - mean_squared_error: 0.0253\n",
      "Epoch 87/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7992 - acc: 0.6370 - mean_squared_error: 0.0279\n",
      "Epoch 88/200\n",
      "17000/17000 [==============================] - 0s 19us/step - loss: 0.7801 - acc: 0.6605 - mean_squared_error: 0.0269\n",
      "Epoch 89/200\n",
      "17000/17000 [==============================] - 0s 18us/step - loss: 0.8587 - acc: 0.6134 - mean_squared_error: 0.0303\n",
      "Epoch 90/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8093 - acc: 0.6191 - mean_squared_error: 0.0286\n",
      "Epoch 91/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8664 - acc: 0.5747 - mean_squared_error: 0.0316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/200\n",
      "17000/17000 [==============================] - 0s 17us/step - loss: 0.9120 - acc: 0.5734 - mean_squared_error: 0.0329\n",
      "Epoch 93/200\n",
      "17000/17000 [==============================] - 0s 21us/step - loss: 0.7982 - acc: 0.6321 - mean_squared_error: 0.0281\n",
      "Epoch 94/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7960 - acc: 0.6338 - mean_squared_error: 0.0278\n",
      "Epoch 95/200\n",
      "17000/17000 [==============================] - 0s 18us/step - loss: 0.7697 - acc: 0.6597 - mean_squared_error: 0.0264\n",
      "Epoch 96/200\n",
      "17000/17000 [==============================] - 0s 19us/step - loss: 0.8465 - acc: 0.6048 - mean_squared_error: 0.0300\n",
      "Epoch 97/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7809 - acc: 0.6515 - mean_squared_error: 0.0273\n",
      "Epoch 98/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.7959 - acc: 0.6436 - mean_squared_error: 0.0276\n",
      "Epoch 99/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8026 - acc: 0.6361 - mean_squared_error: 0.0281\n",
      "Epoch 100/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8044 - acc: 0.6324 - mean_squared_error: 0.0281\n",
      "Epoch 101/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7659 - acc: 0.6651 - mean_squared_error: 0.0265\n",
      "Epoch 102/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.7659 - acc: 0.6608 - mean_squared_error: 0.0265\n",
      "Epoch 103/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7205 - acc: 0.6865 - mean_squared_error: 0.0246\n",
      "Epoch 104/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.7185 - acc: 0.6885 - mean_squared_error: 0.0245\n",
      "Epoch 105/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8661 - acc: 0.6131 - mean_squared_error: 0.0301\n",
      "Epoch 106/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7897 - acc: 0.6323 - mean_squared_error: 0.0280\n",
      "Epoch 107/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.9147 - acc: 0.5779 - mean_squared_error: 0.0321\n",
      "Epoch 108/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8360 - acc: 0.6209 - mean_squared_error: 0.0291\n",
      "Epoch 109/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8031 - acc: 0.6476 - mean_squared_error: 0.0274\n",
      "Epoch 110/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8029 - acc: 0.6134 - mean_squared_error: 0.0285\n",
      "Epoch 111/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7981 - acc: 0.6286 - mean_squared_error: 0.0280\n",
      "Epoch 112/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8007 - acc: 0.6307 - mean_squared_error: 0.0282\n",
      "Epoch 113/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7992 - acc: 0.6312 - mean_squared_error: 0.0280\n",
      "Epoch 114/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7785 - acc: 0.6481 - mean_squared_error: 0.0271\n",
      "Epoch 115/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8409 - acc: 0.6155 - mean_squared_error: 0.0295\n",
      "Epoch 116/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.9843 - acc: 0.5627 - mean_squared_error: 0.0346\n",
      "Epoch 117/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.9321 - acc: 0.5699 - mean_squared_error: 0.0324\n",
      "Epoch 118/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8682 - acc: 0.5836 - mean_squared_error: 0.0307\n",
      "Epoch 119/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8198 - acc: 0.6297 - mean_squared_error: 0.0284\n",
      "Epoch 120/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.7983 - acc: 0.6352 - mean_squared_error: 0.0275\n",
      "Epoch 121/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7458 - acc: 0.6789 - mean_squared_error: 0.0253\n",
      "Epoch 122/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7508 - acc: 0.6639 - mean_squared_error: 0.0258\n",
      "Epoch 123/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7214 - acc: 0.6788 - mean_squared_error: 0.0247\n",
      "Epoch 124/200\n",
      "17000/17000 [==============================] - 0s 20us/step - loss: 0.7070 - acc: 0.6860 - mean_squared_error: 0.0242\n",
      "Epoch 125/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7234 - acc: 0.6786 - mean_squared_error: 0.0248\n",
      "Epoch 126/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7117 - acc: 0.6877 - mean_squared_error: 0.0242\n",
      "Epoch 127/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7026 - acc: 0.6889 - mean_squared_error: 0.0239\n",
      "Epoch 128/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.7432 - acc: 0.6695 - mean_squared_error: 0.0254\n",
      "Epoch 129/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7554 - acc: 0.6566 - mean_squared_error: 0.0264\n",
      "Epoch 130/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.7238 - acc: 0.6749 - mean_squared_error: 0.0250\n",
      "Epoch 131/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7219 - acc: 0.6844 - mean_squared_error: 0.0247\n",
      "Epoch 132/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.8051 - acc: 0.6386 - mean_squared_error: 0.0279\n",
      "Epoch 133/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.8018 - acc: 0.6413 - mean_squared_error: 0.0280\n",
      "Epoch 134/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.8468 - acc: 0.5961 - mean_squared_error: 0.0303\n",
      "Epoch 135/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7574 - acc: 0.6605 - mean_squared_error: 0.0261\n",
      "Epoch 136/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.8173 - acc: 0.6241 - mean_squared_error: 0.0286\n",
      "Epoch 137/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.7028 - acc: 0.6835 - mean_squared_error: 0.0241\n",
      "Epoch 138/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.6821 - acc: 0.6945 - mean_squared_error: 0.0233\n",
      "Epoch 139/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.6785 - acc: 0.7006 - mean_squared_error: 0.0231\n",
      "Epoch 140/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.7275 - acc: 0.6699 - mean_squared_error: 0.0249\n",
      "Epoch 141/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.6816 - acc: 0.6972 - mean_squared_error: 0.0231\n",
      "Epoch 142/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.7182 - acc: 0.6790 - mean_squared_error: 0.0247\n",
      "Epoch 143/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7199 - acc: 0.6686 - mean_squared_error: 0.0249\n",
      "Epoch 144/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7915 - acc: 0.6341 - mean_squared_error: 0.0278\n",
      "Epoch 145/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7256 - acc: 0.6604 - mean_squared_error: 0.0253\n",
      "Epoch 146/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8228 - acc: 0.6236 - mean_squared_error: 0.0291\n",
      "Epoch 147/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8056 - acc: 0.6295 - mean_squared_error: 0.0285\n",
      "Epoch 148/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.7785 - acc: 0.6380 - mean_squared_error: 0.0273\n",
      "Epoch 149/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7278 - acc: 0.6728 - mean_squared_error: 0.0251\n",
      "Epoch 150/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.6973 - acc: 0.6908 - mean_squared_error: 0.0238\n",
      "Epoch 151/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.7067 - acc: 0.6818 - mean_squared_error: 0.0243\n",
      "Epoch 152/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.6920 - acc: 0.6922 - mean_squared_error: 0.0234\n",
      "Epoch 153/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.7762 - acc: 0.6403 - mean_squared_error: 0.0276\n",
      "Epoch 154/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17000/17000 [==============================] - 0s 14us/step - loss: 0.7233 - acc: 0.6709 - mean_squared_error: 0.0251\n",
      "Epoch 155/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7547 - acc: 0.6534 - mean_squared_error: 0.0259\n",
      "Epoch 156/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.8950 - acc: 0.5728 - mean_squared_error: 0.0323\n",
      "Epoch 157/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8315 - acc: 0.6074 - mean_squared_error: 0.0298\n",
      "Epoch 158/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.8027 - acc: 0.6175 - mean_squared_error: 0.0284\n",
      "Epoch 159/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7406 - acc: 0.6638 - mean_squared_error: 0.0253\n",
      "Epoch 160/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7268 - acc: 0.6691 - mean_squared_error: 0.0248\n",
      "Epoch 161/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7457 - acc: 0.6659 - mean_squared_error: 0.0257\n",
      "Epoch 162/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7139 - acc: 0.6771 - mean_squared_error: 0.0242\n",
      "Epoch 163/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7390 - acc: 0.6606 - mean_squared_error: 0.0258\n",
      "Epoch 164/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.8018 - acc: 0.6201 - mean_squared_error: 0.0285\n",
      "Epoch 165/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7886 - acc: 0.6093 - mean_squared_error: 0.0283\n",
      "Epoch 166/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8348 - acc: 0.6065 - mean_squared_error: 0.0296\n",
      "Epoch 167/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.7508 - acc: 0.6525 - mean_squared_error: 0.0261\n",
      "Epoch 168/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 0.7977 - acc: 0.6282 - mean_squared_error: 0.0282\n",
      "Epoch 169/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.7192 - acc: 0.6665 - mean_squared_error: 0.0251\n",
      "Epoch 170/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.7195 - acc: 0.6640 - mean_squared_error: 0.0253\n",
      "Epoch 171/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.8304 - acc: 0.5953 - mean_squared_error: 0.0301\n",
      "Epoch 172/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8908 - acc: 0.5698 - mean_squared_error: 0.0321\n",
      "Epoch 173/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.8000 - acc: 0.6102 - mean_squared_error: 0.0288\n",
      "Epoch 174/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.8089 - acc: 0.6085 - mean_squared_error: 0.0288\n",
      "Epoch 175/200\n",
      "17000/17000 [==============================] - 0s 15us/step - loss: 0.8573 - acc: 0.6021 - mean_squared_error: 0.0300\n",
      "Epoch 176/200\n",
      "17000/17000 [==============================] - 0s 13us/step - loss: 0.9612 - acc: 0.5597 - mean_squared_error: 0.0339\n",
      "Epoch 177/200\n",
      "17000/17000 [==============================] - 0s 14us/step - loss: 1.0026 - acc: 0.5327 - mean_squared_error: 0.0358\n",
      "Epoch 178/200\n",
      "17000/17000 [==============================] - 0s 12us/step - loss: 0.7993 - acc: 0.6348 - mean_squared_error: 0.0277\n",
      "Epoch 179/200\n",
      "17000/17000 [==============================] - 0s 17us/step - loss: 0.8906 - acc: 0.5752 - mean_squared_error: 0.0324\n",
      "Epoch 180/200\n",
      "17000/17000 [==============================] - 0s 22us/step - loss: 0.8811 - acc: 0.5889 - mean_squared_error: 0.0316\n",
      "Epoch 181/200\n",
      "17000/17000 [==============================] - 0s 11us/step - loss: 0.9197 - acc: 0.5603 - mean_squared_error: 0.0329\n",
      "Epoch 182/200\n",
      "17000/17000 [==============================] - 0s 8us/step - loss: 0.8190 - acc: 0.6132 - mean_squared_error: 0.0288\n",
      "Epoch 183/200\n",
      "17000/17000 [==============================] - 0s 9us/step - loss: 1.0808 - acc: 0.5212 - mean_squared_error: 0.0360\n",
      "Epoch 184/200\n",
      "17000/17000 [==============================] - 0s 10us/step - loss: 0.9057 - acc: 0.5804 - mean_squared_error: 0.0315\n",
      "Epoch 185/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8259 - acc: 0.6156 - mean_squared_error: 0.0290\n",
      "Epoch 186/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8555 - acc: 0.5906 - mean_squared_error: 0.0304\n",
      "Epoch 187/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.7917 - acc: 0.6398 - mean_squared_error: 0.0276\n",
      "Epoch 188/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7790 - acc: 0.6379 - mean_squared_error: 0.0275\n",
      "Epoch 189/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8553 - acc: 0.5908 - mean_squared_error: 0.0308\n",
      "Epoch 190/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.9516 - acc: 0.5359 - mean_squared_error: 0.0353\n",
      "Epoch 191/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.7986 - acc: 0.6361 - mean_squared_error: 0.0279\n",
      "Epoch 192/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.8287 - acc: 0.6115 - mean_squared_error: 0.0295\n",
      "Epoch 193/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7863 - acc: 0.6342 - mean_squared_error: 0.0274\n",
      "Epoch 194/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8514 - acc: 0.5838 - mean_squared_error: 0.0299\n",
      "Epoch 195/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7754 - acc: 0.6420 - mean_squared_error: 0.0268\n",
      "Epoch 196/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.7306 - acc: 0.6692 - mean_squared_error: 0.0250\n",
      "Epoch 197/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.6989 - acc: 0.6884 - mean_squared_error: 0.0238\n",
      "Epoch 198/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.7078 - acc: 0.6811 - mean_squared_error: 0.0244\n",
      "Epoch 199/200\n",
      "17000/17000 [==============================] - 0s 7us/step - loss: 0.6751 - acc: 0.6942 - mean_squared_error: 0.0232\n",
      "Epoch 200/200\n",
      "17000/17000 [==============================] - 0s 6us/step - loss: 0.8269 - acc: 0.6062 - mean_squared_error: 0.0298\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE0pJREFUeJzt3X1wpWV5x/HvRVjGlKyNFc26YccVLanUpU2JyAy1JviyiA4uq9MRqnXGtjt1fIGpLLLQmXY6w0DNFJ1WR8dWGds6DTou6/gaQYxVOyhZAq6IoRTUkpURR6NEU1jC1T/yBHaXvJws55z7JOf7mWE25zlPznPduyG/c7+c+4nMRJKk40oXIElqDQaCJAkwECRJFQNBkgQYCJKkioEgSQIMBElSxUCQJAEGgiSpcnzpAlbjpJNOyq1bt5Yuo25+9atfceKJJ5Yuo+lsd/toxzZD67V7//79P83MZ6103poKhK1btzI+Pl66jLoZGxtjcHCwdBlNZ7vbRzu2GVqv3RHxw1rOc8hIkgQYCJKkioEgSQIMBElSxUCQJAEGgiSpsqaWnbaTfRNTDI9OcnB6ls3dneze3seO/t7SZUlaxwyEFrRvYoo9ew8we2gOgKnpWfbsPQBgKEhqGIeMWtDw6OTjYbBg9tAcw6OThSqS1A4MhBZ0cHp2VcclqR4cMmpBm7s7mVrkl//m7s4C1ahZnDdSafYQWtDu7X10bug44ljnhg52b+8rVJEabWHeaGp6luSJeaN9E1OlS1MbsYfQghbeFfpusX0sN2+0lv7dn9TL+b25lb+pltfx578pDIQWtaO/1/8B2sh6mDdabHXc1M/n2DcxtaqfZVfZleOQkdQClpofWkvzRov1ch7LXPXqOFfZlWMgSC1gPcwb1auXsx56S2uVgSC1gB39vVy9cxu93Z0E0NvdydU7t62pIZJ69XLWQ29prXIOQapRoyc61/q80e7tfUeM/QMcF7HqXs5ir7PWektrlYEg1cCJzpUttjqu9xlzq/77cZVdOQaCVIP1siy00Y7u5YyNjdXlddQcziFINXCiU+3AQJBq4ESn2oGBINVgPSwLlVbiHIJUAyc61Q4MBKlGTnRqvXPISJIEGAiSpIqBIEkCDARJUsVAkCQBBoIkqWIgSJIAA0GSVDEQJEmAgSBJqhQLhIjYEhFfjYi7IuLOiLi4VC2SpLJ7GT0KvDszb4uIjcD+iLgxM79XsCZJalvFegiZ+ePMvK36+iHgLsCdwySpkJaYQ4iIrUA/8K2ylUhS+4rMLFtARBfwNeCqzNy7yPO7gF0APT09Z4yMjDS5wsaZmZmhq6urdBlNZ7vbRzu2GVqv3UNDQ/szc2Cl84oGQkRsAD4HjGbmtSudPzAwkOPj440vrEnGxsYYHBwsXUbT2e720Y5thtZrd0TUFAglVxkF8FHgrlrCQJLUWCXnEM4G3gycExG3V/+dV7AeSWprxZadZuY3gCh1fUnSkVpilZEkqTwDQZIEGAiSpIqBIEkCDARJUqXk5naStC5Nzx7i7Gtu5uD0LJu7O9m9vY8d/a2/VZuBIEl1tG9iiqmfzzI13QHA1PQse/YeAGj5UHDISJLqaHh0kseO2hJo9tAcw6OThSqqnYEgSXV0cHp2VcdbiYEgSXW0ubtzVcdbiYEgSXW0e3sfx8WRu/J0buhg9/a+QhXVzkCQpDra0d9L7zM66e3uJIDe7k6u3rmt5SeUwVVGklR33Z0b+Oblg6XLWDV7CJIkwECQJFUMBEkSYCBIkioGgiQJMBAkSRUDQZIEGAiSpIqBIEkCDARJUsVAkCQBBoIkqWIgSJIAA0GSVDEQJEmAgSBJqhgIkiTAQJAkVQwESRLgPZWlY7JvYorh0UkOTs+yubuT3dv71sRN1KXlFO0hRMS5ETEZEfdExOUla5FqtW9iij17DzA1PUsCU9Oz7Nl7gH0TU6VLk56SYoEQER3AB4FXA6cBF0bEaaXqkWo1PDrJ7KG5I47NHprjkutv5+xrbjYYtGaV7CGcCdyTmfdm5iPACPC6gvVINTk4Pbvkc/YWtJZFZpa5cMQbgHMz88+rx28GXpKZ7zjqvF3ALoCenp4zRkZGml5ro8zMzNDV1VW6jKZb6+2efOAhHpl7bNlzTug4jr5NG484ttbbfSzasc3Qeu0eGhran5kDK51XclI5Fjn2pHTKzI8AHwEYGBjIwcHBBpfVPGNjY6yn9tRqrbd7emKKS66/fdlzArjvmsEjjq31dh+LdmwzrN12lxwyuh/Yctjjk4GDhWqRarajv5cTT+hY9pzN3Z1Nqkaqn5I9hFuB346I5wFTwBuBiwrWI9VsQ8dxwNyiz3Vu6GD39r7mFqR1qdnLm4sFQmY+GhHvAEaBDuBjmXlnqXqk1fjF7KEln7t65zY/k6CnbGF588KKtoUFC0DDfr6KfjAtM78AfKFkDdKx2NzdydQiq416uzsNgxr4wb6VLbW8eXh0smF/V25dIR2D3dv76Nxw5DyCQ0W18YN9tVlqefNyy56fKgNBOgY7+nu5euc2ers7CeZ7Bg4V1Wa5d756wlILExq5YMG9jKRjtKO/ty0D4KkO95R457sW7d7ed8QcAjS+F2ogSKpZPSY6l5p/canukRb+PttilZGktaceE50l3vmuVc3uhRoIkmpWj+GeEu98VZtVBUJEPAPYkpnfaVA9klpYvYZ72nX+pdWtuMooIsYi4ukR8VvAHcB1EXFt40uT1Gpcbru+1bLs9Dcz85fATuC6zDwDeEVjy5LUilxuu77VMmR0fEQ8B/hj4MoG1yOpxTncs37V0kP4O+b3G7onM2+NiFOA/25sWZKkZluxh5CZnwI+ddjje4HXN7IoSVLzLRkIEXFZZr43Iv6JxW9c866GViZJaqrlegh3VX+ON6MQSVJZSwZCZn62+vL6zPy/w5+LiJMaWpUkqelqmVT+dkSctfAgIl4P/FfjSpIklVDLstM/AT4WEWPAZuCZwDmNLEqS1Hy1rDI6EBFXAf8GPAT8UWbe3/DKJElNtWIgRMRHgecDpwOnAp+NiA9k5gcbXZwkqXlqmUP4LjCUmfdl5ihwFtDf2LIkSc1Wy5DR+4469HTAe91J0jpT0z2VI+KkiHhbRPwnMAb0NLQqSVLTLfdJ5Y3ABcBFzM8d3ACckpknN6k2SVITLTdk9BPg28BfA9/IzIyIC5pTliSp2ZYbMroCeBrwIWBPRDy/OSVJkkpYMhAy832Z+RLgfCCAfcDmiHhPRJzarAIlSc2x4qRyZt6bmVdl5jbgxcBvAl9seGWSpKaqaZXRgsw8kJlXZKbDR5K0zqwqECRJ65eBIEkCatvL6DeAF1QPJzPz4caWJEkqYckeQkRsiIj3A/cD1wEfB+6NiMur593PSJLWkeWGjP4B6AKem5lnZGY/8ELglIj4ELD3WC8aEcMR8f2I+E5E3BAR3cf6WpKk+lguEM4D/iIzH1o4kJm/BN4GvBG48Clc90bgRZl5OnA3sOcpvJYkqQ6WC4THMjOPPpiZc8CDmXnLsV40M7+cmY9WD28B3B9JkgpbLhC+FxF/evTBiHgTcFcda3grftBNkoqLRToB809E9DI/TzAL7AeS+U8qdwIXZObUsi8ccROwaZGnrszMz1TnXAkMADsX641U5+wCdgH09PScMTIyUkOz1oaZmRm6urpKl9F0trt9tGObofXaPTQ0tD8zB1Y6b8lAePyEiHOA32V+P6M7M/Mr9SgwIt4C/CXw8sz8dS3fMzAwkOPj4/W4fEsYGxtjcHCwdBlNZ7vbRzu2GVqv3RFRUyDUcse0m4Gb61JVJSLOBd4DvKzWMJAkNVapTyp/ANgI3BgRt0fEhwvVIUmqrNhDaITMfMHKZ0mSmsm9jCRJgIEgSaoYCJIkwECQJFUMBEkSYCBIkioGgiQJMBAkSRUDQZIEGAiSpIqBIEkCDARJUsVAkCQBBoIkqWIgSJIAA0GSVDEQJEmAgSBJqhgIkiTAQJAkVQwESRJgIEiSKgaCJAkwECRJFQNBkgQYCJKkioEgSQIMBElSxUCQJAEGgiSpYiBIkgADQZJUOb7kxSPiUmAYeFZm/rRkLQD7JqYYHp3k4PQsm7s72b29jx39vaXLkqSmKBYIEbEFeCXwo1I1HG7fxBR79h5g9tAcAFPTs+zZewDAUJDUFkoOGb0PuAzIgjU8bnh08vEwWDB7aI7h0clCFUlScxUJhIg4H5jKzDtKXH8xB6dnV3VcktabyGzMG/SIuAnYtMhTVwJXAK/KzF9ExA+AgaXmECJiF7ALoKen54yRkZGG1Dv5wEM8MvfYk46f0HEcfZs2NuSaMzMzdHV1NeS1W5ntbh/t2GZovXYPDQ3tz8yBlc5rWCAsecGIbcBXgF9Xh04GDgJnZuYDy33vwMBAjo+PN6Suo+cQADo3dHD1zm0Nm0MYGxtjcHCwIa/dymx3+2jHNkPrtTsiagqEpk8qZ+YB4NkLj1fqITTLwi99VxlJaldFl522mh39vQaApLZVPBAyc2vpGiRJflJZklQxECRJgIEgSaoYCJIkwECQJFUMBEkSYCBIkioGgiQJMBAkSRUDQZIEGAiSpIqBIEkCDARJUsVAkCQBBoIkqWIgSJIAA0GSVDEQJEmAgSBJqhgIkiTAQJAkVQwESRIAx5cuYD3ZNzHF8OgkB6dn2dzdye7tfezo7y1dliTVxECok30TU+zZe4DZQ3MATE3PsmfvAQBDQdKa4JBRnQyPTj4eBgtmD80xPDpZqCJJWh0DoU4OTs+u6rgktRoDoU42d3eu6rgktRoDoU52b++jc0PHEcc6N3Swe3tfoYokaXWcVK6ThYljVxlJWqsMhDra0d9rAEhasxwykiQBBoIkqWIgSJKAgoEQEe+MiMmIuDMi3luqDknSvCKTyhExBLwOOD0zH46IZ5eoQ5L0hFKrjN4GXJOZDwNk5k8adSE3nJOk2pQaMjoVeGlEfCsivhYRL27ERRY2nJuaniV5YsO5fRNTjbicJK1pkZmNeeGIm4BNizx1JXAVcDNwMfBi4HrglFykmIjYBewC6OnpOWNkZKTmGiYfeIhH5h570vETOo6jb9PGml+nUWZmZujq6ipdRtPZ7vbRjm2G1mv30NDQ/swcWOm8hgXCsheN+BLzQ0Zj1eP/Ac7KzAeX+76BgYEcHx+v+TrPu/zzLNa6AO675jW1F9wgY2NjDA4Oli6j6Wx3+2jHNkPrtTsiagqEUkNG+4BzACLiVOAE4Kf1vogbzklS7UoFwseAUyLiu8AI8JbFhoueKjeck6TaFVlllJmPAG9q9HXccE6SarfuN7dzwzlJqo1bV0iSAANBklQxECRJgIEgSaoYCJIkoNAnlY9VRDwI/LB0HXV0Eg34QN4aYLvbRzu2GVqv3c/NzGetdNKaCoT1JiLGa/k4+Xpju9tHO7YZ1m67HTKSJAEGgiSpYiCU9ZHSBRRiu9tHO7YZ1mi7nUOQJAH2ECRJFQOhRUTEpRGREXFS6VqaISKGI+L7EfGdiLghIrpL19QoEXFuRExGxD0RcXnpepohIrZExFcj4q6IuDMiLi5dUzNFREdETETE50rXshoGQguIiC3AK4Efla6liW4EXpSZpwN3A3sK19MQEdEBfBB4NXAacGFEnFa2qqZ4FHh3Zr4QOAt4e5u0e8HFwF2li1gtA6E1vA+4DBa94+e6lJlfzsxHq4e3ACeXrKeBzgTuycx7q/uAjACvK1xTw2XmjzPzturrh5j/5dgW+9BHxMnAa4B/KV3LahkIhUXE+cBUZt5RupaC3gp8sXQRDdIL/O9hj++nTX4xLoiIrUA/8K2ylTTN+5l/g/dY6UJWa93fIKcVRMRNwKZFnroSuAJ4VXMrao7l2p2Zn6nOuZL54YVPNLO2JopFjrVNTzAiuoBPA5dk5i9L19NoEfFa4CeZuT8iBkvXs1oGQhNk5isWOx4R24DnAXdEBMwPm9wWEWdm5gNNLLEhlmr3goh4C/Ba4OWNuKd2i7gf2HLY45OBg4VqaaqI2MB8GHwiM/eWrqdJzgbOj4jzgKcBT4+If8/Mht8yuB78HEILiYgfAAOZ2UqbYjVERJwLXAu8LDMfLF1Po0TE8cxPmr8cmAJuBS7KzDuLFtZgMf8O5+PAzzLzktL1lFD1EC7NzNeWrqVWziGolA8AG4EbI+L2iPhw6YIaoZo4fwcwyvzE6ifXexhUzgbeDJxT/fveXr1rVguzhyBJAuwhSJIqBoIkCTAQJEkVA0GSBBgIkqSKgSAtIiJmlnnugmpn2t+p4XUGIuIf61ud1BguO5UWEREzmdm1xHOfBJ4DfCUz/7aphUkNZA9BWoVqb56zgT8D3njY8Qsi4qaY95yIuDsiNkXE4MKe+BHxssM+pDURERsLNUNalIEgrc4O4EuZeTfws4j4A4DMvAF4AHg78M/A3yyyH9WlwNsz8/eBlwKzzStbWpmBIK3Ohczf04DqzwsPe+6dzN/o5+HM/I9FvvebwLUR8S6g+7D7QUgtwd1OpRpFxDOBc4AXRUQCHUBGxGXVbq29zO+B3xMRx2XmEfvhZ+Y1EfF54Dzgloh4RWZ+v8nNkJZkD0Gq3RuAf83M52bm1szcAtwH/GG1q+l1wEXMb2L3V0d/c0Q8PzMPZObfA+PAiquUpGayhyDV7kLgmqOOfZr5EBgCvp6ZX4+I24Fbq97A4S6JiCFgDvge6/cucVqjXHYqSQIcMpIkVQwESRJgIEiSKgaCJAkwECRJFQNBkgQYCJKkioEgSQLg/wEnydEMzSVPAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.138618]\n",
      "Es/No: 12 SER: 0.3508235294117647 Theor_SER_PAM: 0.5075803579279314\n",
      "(24000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           272         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8)            136         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 4)            36          dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            10          dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2)            4           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2)            0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 2)            0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 1)            0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 2)            0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 1)            0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3)            0           lambda_10[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            8           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            12          dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8)            40          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           144         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 662\n",
      "Trainable params: 658\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "24000/24000 [==============================] - 4s 176us/step - loss: 2.7444 - acc: 0.1041 - mean_squared_error: 0.0583\n",
      "Epoch 2/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 2.3233 - acc: 0.1184 - mean_squared_error: 0.0550\n",
      "Epoch 3/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 1.9075 - acc: 0.2207 - mean_squared_error: 0.0507\n",
      "Epoch 4/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 1.6279 - acc: 0.3728 - mean_squared_error: 0.0467\n",
      "Epoch 5/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 1.4363 - acc: 0.4012 - mean_squared_error: 0.0436\n",
      "Epoch 6/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 1.3324 - acc: 0.3725 - mean_squared_error: 0.0430\n",
      "Epoch 7/200\n",
      "24000/24000 [==============================] - 0s 9us/step - loss: 1.2024 - acc: 0.4373 - mean_squared_error: 0.0402\n",
      "Epoch 8/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 1.0689 - acc: 0.5280 - mean_squared_error: 0.0364\n",
      "Epoch 9/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.9549 - acc: 0.6078 - mean_squared_error: 0.0326\n",
      "Epoch 10/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.9017 - acc: 0.6378 - mean_squared_error: 0.0314\n",
      "Epoch 11/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.9197 - acc: 0.5981 - mean_squared_error: 0.0334\n",
      "Epoch 12/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.8380 - acc: 0.6801 - mean_squared_error: 0.0295\n",
      "Epoch 13/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7551 - acc: 0.7360 - mean_squared_error: 0.0262\n",
      "Epoch 14/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.8449 - acc: 0.6325 - mean_squared_error: 0.0306\n",
      "Epoch 15/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.8716 - acc: 0.6221 - mean_squared_error: 0.0309\n",
      "Epoch 16/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7691 - acc: 0.6810 - mean_squared_error: 0.0277\n",
      "Epoch 17/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.7310 - acc: 0.7111 - mean_squared_error: 0.0264\n",
      "Epoch 18/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7918 - acc: 0.6841 - mean_squared_error: 0.0286\n",
      "Epoch 19/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6872 - acc: 0.7178 - mean_squared_error: 0.0247\n",
      "Epoch 20/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6370 - acc: 0.7432 - mean_squared_error: 0.0224\n",
      "Epoch 21/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.6465 - acc: 0.7222 - mean_squared_error: 0.0234\n",
      "Epoch 22/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.6008 - acc: 0.7569 - mean_squared_error: 0.0218\n",
      "Epoch 23/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5904 - acc: 0.7740 - mean_squared_error: 0.0214\n",
      "Epoch 24/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6915 - acc: 0.7233 - mean_squared_error: 0.0258\n",
      "Epoch 25/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6504 - acc: 0.7492 - mean_squared_error: 0.0240\n",
      "Epoch 26/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5693 - acc: 0.7682 - mean_squared_error: 0.0209\n",
      "Epoch 27/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5371 - acc: 0.8045 - mean_squared_error: 0.0192\n",
      "Epoch 28/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5345 - acc: 0.7964 - mean_squared_error: 0.0194\n",
      "Epoch 29/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5758 - acc: 0.7727 - mean_squared_error: 0.0210\n",
      "Epoch 30/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5444 - acc: 0.7829 - mean_squared_error: 0.0200\n",
      "Epoch 31/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.4924 - acc: 0.8153 - mean_squared_error: 0.0177\n",
      "Epoch 32/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5790 - acc: 0.7389 - mean_squared_error: 0.0220\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5357 - acc: 0.7826 - mean_squared_error: 0.0199\n",
      "Epoch 34/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5278 - acc: 0.7769 - mean_squared_error: 0.0195\n",
      "Epoch 35/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6473 - acc: 0.7257 - mean_squared_error: 0.0238\n",
      "Epoch 36/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6115 - acc: 0.7140 - mean_squared_error: 0.0236\n",
      "Epoch 37/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5401 - acc: 0.7688 - mean_squared_error: 0.0200\n",
      "Epoch 38/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5265 - acc: 0.7651 - mean_squared_error: 0.0197\n",
      "Epoch 39/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4319 - acc: 0.8291 - mean_squared_error: 0.0156\n",
      "Epoch 40/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4741 - acc: 0.8080 - mean_squared_error: 0.0172\n",
      "Epoch 41/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4935 - acc: 0.7935 - mean_squared_error: 0.0181\n",
      "Epoch 42/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4467 - acc: 0.8273 - mean_squared_error: 0.0159\n",
      "Epoch 43/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4752 - acc: 0.8018 - mean_squared_error: 0.0179\n",
      "Epoch 44/200\n",
      "24000/24000 [==============================] - 0s 13us/step - loss: 0.5725 - acc: 0.7500 - mean_squared_error: 0.0218\n",
      "Epoch 45/200\n",
      "24000/24000 [==============================] - 0s 9us/step - loss: 0.7383 - acc: 0.6680 - mean_squared_error: 0.0280\n",
      "Epoch 46/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5067 - acc: 0.7603 - mean_squared_error: 0.0199\n",
      "Epoch 47/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4442 - acc: 0.7950 - mean_squared_error: 0.0167\n",
      "Epoch 48/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4686 - acc: 0.7878 - mean_squared_error: 0.0179\n",
      "Epoch 49/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6872 - acc: 0.6972 - mean_squared_error: 0.0259\n",
      "Epoch 50/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.6238 - acc: 0.7114 - mean_squared_error: 0.0241\n",
      "Epoch 51/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6164 - acc: 0.7056 - mean_squared_error: 0.0240\n",
      "Epoch 52/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5483 - acc: 0.7731 - mean_squared_error: 0.0201\n",
      "Epoch 53/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.5125 - acc: 0.7889 - mean_squared_error: 0.0188\n",
      "Epoch 54/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5658 - acc: 0.7297 - mean_squared_error: 0.0214\n",
      "Epoch 55/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6176 - acc: 0.7086 - mean_squared_error: 0.0237\n",
      "Epoch 56/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5848 - acc: 0.7332 - mean_squared_error: 0.0219\n",
      "Epoch 57/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5315 - acc: 0.7747 - mean_squared_error: 0.0197\n",
      "Epoch 58/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.5605 - acc: 0.7614 - mean_squared_error: 0.0200\n",
      "Epoch 59/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7629 - acc: 0.6410 - mean_squared_error: 0.0291\n",
      "Epoch 60/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7316 - acc: 0.6347 - mean_squared_error: 0.0284\n",
      "Epoch 61/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5510 - acc: 0.7508 - mean_squared_error: 0.0208\n",
      "Epoch 62/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.4954 - acc: 0.7982 - mean_squared_error: 0.0181\n",
      "Epoch 63/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4687 - acc: 0.8044 - mean_squared_error: 0.0175\n",
      "Epoch 64/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4968 - acc: 0.7941 - mean_squared_error: 0.0181\n",
      "Epoch 65/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5152 - acc: 0.7555 - mean_squared_error: 0.0201\n",
      "Epoch 66/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5525 - acc: 0.7529 - mean_squared_error: 0.0211\n",
      "Epoch 67/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4451 - acc: 0.8243 - mean_squared_error: 0.0161\n",
      "Epoch 68/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5001 - acc: 0.7545 - mean_squared_error: 0.0194\n",
      "Epoch 69/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.4832 - acc: 0.7908 - mean_squared_error: 0.0182\n",
      "Epoch 70/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.6176 - acc: 0.6853 - mean_squared_error: 0.0242\n",
      "Epoch 71/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6726 - acc: 0.6822 - mean_squared_error: 0.0264\n",
      "Epoch 72/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5383 - acc: 0.7575 - mean_squared_error: 0.0207\n",
      "Epoch 73/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4533 - acc: 0.7934 - mean_squared_error: 0.0173\n",
      "Epoch 74/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4439 - acc: 0.8067 - mean_squared_error: 0.0164\n",
      "Epoch 75/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4788 - acc: 0.8020 - mean_squared_error: 0.0172\n",
      "Epoch 76/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4232 - acc: 0.8069 - mean_squared_error: 0.0161\n",
      "Epoch 77/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3460 - acc: 0.8543 - mean_squared_error: 0.0123\n",
      "Epoch 78/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4054 - acc: 0.8181 - mean_squared_error: 0.0152\n",
      "Epoch 79/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.5174 - acc: 0.7626 - mean_squared_error: 0.0199\n",
      "Epoch 80/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.6260 - acc: 0.6938 - mean_squared_error: 0.0247\n",
      "Epoch 81/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.7803 - acc: 0.6501 - mean_squared_error: 0.0293\n",
      "Epoch 82/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6781 - acc: 0.6808 - mean_squared_error: 0.0261\n",
      "Epoch 83/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4817 - acc: 0.8081 - mean_squared_error: 0.0174\n",
      "Epoch 84/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4413 - acc: 0.8157 - mean_squared_error: 0.0161\n",
      "Epoch 85/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3884 - acc: 0.8474 - mean_squared_error: 0.0139\n",
      "Epoch 86/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3253 - acc: 0.8680 - mean_squared_error: 0.0116\n",
      "Epoch 87/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4264 - acc: 0.8017 - mean_squared_error: 0.0166\n",
      "Epoch 88/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5325 - acc: 0.7904 - mean_squared_error: 0.0188\n",
      "Epoch 89/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.6274 - acc: 0.7027 - mean_squared_error: 0.0249\n",
      "Epoch 90/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3787 - acc: 0.8370 - mean_squared_error: 0.0141\n",
      "Epoch 91/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3913 - acc: 0.8337 - mean_squared_error: 0.0147\n",
      "Epoch 92/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3727 - acc: 0.8429 - mean_squared_error: 0.0137\n",
      "Epoch 93/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3478 - acc: 0.8519 - mean_squared_error: 0.0128\n",
      "Epoch 94/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.4131 - acc: 0.8197 - mean_squared_error: 0.0154\n",
      "Epoch 95/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.3120 - acc: 0.8647 - mean_squared_error: 0.0115\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.2983 - acc: 0.8758 - mean_squared_error: 0.0107\n",
      "Epoch 97/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4160 - acc: 0.8176 - mean_squared_error: 0.0157\n",
      "Epoch 98/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.5501 - acc: 0.7307 - mean_squared_error: 0.0217\n",
      "Epoch 99/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4876 - acc: 0.7660 - mean_squared_error: 0.0191\n",
      "Epoch 100/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.4363 - acc: 0.8078 - mean_squared_error: 0.0165\n",
      "Epoch 101/200\n",
      "24000/24000 [==============================] - 0s 8us/step - loss: 0.4667 - acc: 0.7696 - mean_squared_error: 0.0184\n",
      "Epoch 102/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3863 - acc: 0.8320 - mean_squared_error: 0.0146\n",
      "Epoch 103/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5694 - acc: 0.7548 - mean_squared_error: 0.0212\n",
      "Epoch 104/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.7141 - acc: 0.7229 - mean_squared_error: 0.0242\n",
      "Epoch 105/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.5565 - acc: 0.7201 - mean_squared_error: 0.0224\n",
      "Epoch 106/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5447 - acc: 0.7553 - mean_squared_error: 0.0203\n",
      "Epoch 107/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4345 - acc: 0.8014 - mean_squared_error: 0.0165\n",
      "Epoch 108/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3267 - acc: 0.8643 - mean_squared_error: 0.0117\n",
      "Epoch 109/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3626 - acc: 0.8349 - mean_squared_error: 0.0138\n",
      "Epoch 110/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3354 - acc: 0.8544 - mean_squared_error: 0.0124\n",
      "Epoch 111/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.3459 - acc: 0.8431 - mean_squared_error: 0.0130\n",
      "Epoch 112/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3268 - acc: 0.8523 - mean_squared_error: 0.0121\n",
      "Epoch 113/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2661 - acc: 0.8862 - mean_squared_error: 0.0094\n",
      "Epoch 114/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2509 - acc: 0.8926 - mean_squared_error: 0.0088\n",
      "Epoch 115/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3145 - acc: 0.8609 - mean_squared_error: 0.0116\n",
      "Epoch 116/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4055 - acc: 0.7992 - mean_squared_error: 0.0160\n",
      "Epoch 117/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2836 - acc: 0.8789 - mean_squared_error: 0.0103\n",
      "Epoch 118/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2450 - acc: 0.8977 - mean_squared_error: 0.0086\n",
      "Epoch 119/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2692 - acc: 0.8866 - mean_squared_error: 0.0098\n",
      "Epoch 120/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2928 - acc: 0.8659 - mean_squared_error: 0.0109\n",
      "Epoch 121/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3935 - acc: 0.8171 - mean_squared_error: 0.0151\n",
      "Epoch 122/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.4190 - acc: 0.8069 - mean_squared_error: 0.0158\n",
      "Epoch 123/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2880 - acc: 0.8719 - mean_squared_error: 0.0105\n",
      "Epoch 124/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3200 - acc: 0.8605 - mean_squared_error: 0.0118\n",
      "Epoch 125/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3326 - acc: 0.8512 - mean_squared_error: 0.0125\n",
      "Epoch 126/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2983 - acc: 0.8628 - mean_squared_error: 0.0111\n",
      "Epoch 127/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2843 - acc: 0.8748 - mean_squared_error: 0.0105\n",
      "Epoch 128/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2313 - acc: 0.8979 - mean_squared_error: 0.0083\n",
      "Epoch 129/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2853 - acc: 0.8736 - mean_squared_error: 0.0106\n",
      "Epoch 130/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3673 - acc: 0.8381 - mean_squared_error: 0.0135\n",
      "Epoch 131/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2824 - acc: 0.8764 - mean_squared_error: 0.0103\n",
      "Epoch 132/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.2898 - acc: 0.8640 - mean_squared_error: 0.0109\n",
      "Epoch 133/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3343 - acc: 0.8575 - mean_squared_error: 0.0123\n",
      "Epoch 134/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4916 - acc: 0.7834 - mean_squared_error: 0.0184\n",
      "Epoch 135/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5063 - acc: 0.7851 - mean_squared_error: 0.0181\n",
      "Epoch 136/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4656 - acc: 0.7856 - mean_squared_error: 0.0182\n",
      "Epoch 137/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3700 - acc: 0.8453 - mean_squared_error: 0.0138\n",
      "Epoch 138/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4794 - acc: 0.7812 - mean_squared_error: 0.0186\n",
      "Epoch 139/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3109 - acc: 0.8685 - mean_squared_error: 0.0113\n",
      "Epoch 140/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3837 - acc: 0.8168 - mean_squared_error: 0.0149\n",
      "Epoch 141/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4502 - acc: 0.7959 - mean_squared_error: 0.0170\n",
      "Epoch 142/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.4284 - acc: 0.8203 - mean_squared_error: 0.0159\n",
      "Epoch 143/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4122 - acc: 0.8089 - mean_squared_error: 0.0156\n",
      "Epoch 144/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.7872 - acc: 0.7122 - mean_squared_error: 0.0250\n",
      "Epoch 145/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.7377 - acc: 0.6497 - mean_squared_error: 0.0285\n",
      "Epoch 146/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4324 - acc: 0.7926 - mean_squared_error: 0.0168\n",
      "Epoch 147/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.5680 - acc: 0.7482 - mean_squared_error: 0.0209\n",
      "Epoch 148/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4176 - acc: 0.8178 - mean_squared_error: 0.0155\n",
      "Epoch 149/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4941 - acc: 0.7803 - mean_squared_error: 0.0190\n",
      "Epoch 150/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4204 - acc: 0.8074 - mean_squared_error: 0.0158\n",
      "Epoch 151/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3873 - acc: 0.8271 - mean_squared_error: 0.0147\n",
      "Epoch 152/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3663 - acc: 0.8236 - mean_squared_error: 0.0142\n",
      "Epoch 153/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4622 - acc: 0.7733 - mean_squared_error: 0.0185\n",
      "Epoch 154/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4231 - acc: 0.7923 - mean_squared_error: 0.0168\n",
      "Epoch 155/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.6776 - acc: 0.7093 - mean_squared_error: 0.0253\n",
      "Epoch 156/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5117 - acc: 0.7612 - mean_squared_error: 0.0198\n",
      "Epoch 157/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5503 - acc: 0.7560 - mean_squared_error: 0.0205\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3398 - acc: 0.8427 - mean_squared_error: 0.0129\n",
      "Epoch 159/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3174 - acc: 0.8644 - mean_squared_error: 0.0116\n",
      "Epoch 160/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2913 - acc: 0.8701 - mean_squared_error: 0.0107\n",
      "Epoch 161/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.3143 - acc: 0.8560 - mean_squared_error: 0.0118\n",
      "Epoch 162/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.3125 - acc: 0.8566 - mean_squared_error: 0.0118\n",
      "Epoch 163/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.2572 - acc: 0.8800 - mean_squared_error: 0.0094\n",
      "Epoch 164/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.2885 - acc: 0.8644 - mean_squared_error: 0.0108\n",
      "Epoch 165/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3284 - acc: 0.8500 - mean_squared_error: 0.0124\n",
      "Epoch 166/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3259 - acc: 0.8542 - mean_squared_error: 0.0121\n",
      "Epoch 167/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.2803 - acc: 0.8768 - mean_squared_error: 0.0101\n",
      "Epoch 168/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.3567 - acc: 0.8421 - mean_squared_error: 0.0135\n",
      "Epoch 169/200\n",
      "24000/24000 [==============================] - 0s 6us/step - loss: 0.2728 - acc: 0.8785 - mean_squared_error: 0.0099\n",
      "Epoch 170/200\n",
      "24000/24000 [==============================] - 0s 7us/step - loss: 0.2919 - acc: 0.8775 - mean_squared_error: 0.0106\n",
      "Epoch 171/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5325 - acc: 0.7466 - mean_squared_error: 0.0210\n",
      "Epoch 172/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 1.0956 - acc: 0.7185 - mean_squared_error: 0.0243\n",
      "Epoch 173/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.6779 - acc: 0.7071 - mean_squared_error: 0.0252\n",
      "Epoch 174/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.5468 - acc: 0.7417 - mean_squared_error: 0.0213\n",
      "Epoch 175/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.6012 - acc: 0.7180 - mean_squared_error: 0.0236\n",
      "Epoch 176/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4788 - acc: 0.7709 - mean_squared_error: 0.0185\n",
      "Epoch 177/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3932 - acc: 0.8207 - mean_squared_error: 0.0149\n",
      "Epoch 178/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4756 - acc: 0.7968 - mean_squared_error: 0.0173\n",
      "Epoch 179/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5608 - acc: 0.7510 - mean_squared_error: 0.0209\n",
      "Epoch 180/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4185 - acc: 0.8040 - mean_squared_error: 0.0162\n",
      "Epoch 181/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4842 - acc: 0.7694 - mean_squared_error: 0.0189\n",
      "Epoch 182/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3225 - acc: 0.8542 - mean_squared_error: 0.0121\n",
      "Epoch 183/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.4469 - acc: 0.7942 - mean_squared_error: 0.0168\n",
      "Epoch 184/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3167 - acc: 0.8512 - mean_squared_error: 0.0119\n",
      "Epoch 185/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.3263 - acc: 0.8515 - mean_squared_error: 0.0123\n",
      "Epoch 186/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.4014 - acc: 0.8094 - mean_squared_error: 0.0156\n",
      "Epoch 187/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3134 - acc: 0.8631 - mean_squared_error: 0.0116\n",
      "Epoch 188/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.3157 - acc: 0.8544 - mean_squared_error: 0.0118\n",
      "Epoch 189/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2595 - acc: 0.8885 - mean_squared_error: 0.0092\n",
      "Epoch 190/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2990 - acc: 0.8640 - mean_squared_error: 0.0111\n",
      "Epoch 191/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2655 - acc: 0.8810 - mean_squared_error: 0.0098\n",
      "Epoch 192/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2785 - acc: 0.8726 - mean_squared_error: 0.0105\n",
      "Epoch 193/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.2721 - acc: 0.8718 - mean_squared_error: 0.0102\n",
      "Epoch 194/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5662 - acc: 0.7703 - mean_squared_error: 0.0203\n",
      "Epoch 195/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.6115 - acc: 0.7283 - mean_squared_error: 0.0230\n",
      "Epoch 196/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.6025 - acc: 0.7345 - mean_squared_error: 0.0228\n",
      "Epoch 197/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.5552 - acc: 0.7223 - mean_squared_error: 0.0222\n",
      "Epoch 198/200\n",
      "24000/24000 [==============================] - 0s 4us/step - loss: 0.3990 - acc: 0.8177 - mean_squared_error: 0.0153\n",
      "Epoch 199/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3110 - acc: 0.8598 - mean_squared_error: 0.0117\n",
      "Epoch 200/200\n",
      "24000/24000 [==============================] - 0s 5us/step - loss: 0.3049 - acc: 0.8616 - mean_squared_error: 0.0114\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39.26757]\n",
      "Es/No: 16 SER: 0.18741666666666668 Theor_SER_PAM: 0.3123019621637889\n",
      "(32000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           272         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 8)            136         dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 4)            36          dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            10          dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2)            4           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 2)            0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 2)            0           lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 2)            0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 1)            0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 2)            0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 1)            0           lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3)            0           lambda_16[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            8           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            12          dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 8)            40          dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 16)           144         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 662\n",
      "Trainable params: 658\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "32000/32000 [==============================] - 3s 105us/step - loss: 4.6177 - acc: 0.0615 - mean_squared_error: 0.0677\n",
      "Epoch 2/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.5506 - acc: 0.1000 - mean_squared_error: 0.0616\n",
      "Epoch 3/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.4411 - acc: 0.1224 - mean_squared_error: 0.0598\n",
      "Epoch 4/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3582 - acc: 0.1240 - mean_squared_error: 0.0582\n",
      "Epoch 5/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3294 - acc: 0.1258 - mean_squared_error: 0.0579\n",
      "Epoch 6/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3183 - acc: 0.1251 - mean_squared_error: 0.0578\n",
      "Epoch 7/200\n",
      "32000/32000 [==============================] - 0s 5us/step - loss: 3.3131 - acc: 0.1256 - mean_squared_error: 0.0578\n",
      "Epoch 8/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3102 - acc: 0.1257 - mean_squared_error: 0.0578\n",
      "Epoch 9/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3085 - acc: 0.1247 - mean_squared_error: 0.0578\n",
      "Epoch 10/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3069 - acc: 0.1252 - mean_squared_error: 0.0578\n",
      "Epoch 11/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3064 - acc: 0.1241 - mean_squared_error: 0.0578\n",
      "Epoch 12/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3055 - acc: 0.1238 - mean_squared_error: 0.0578\n",
      "Epoch 13/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3047 - acc: 0.1244 - mean_squared_error: 0.0578\n",
      "Epoch 14/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3044 - acc: 0.1235 - mean_squared_error: 0.0578\n",
      "Epoch 15/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3042 - acc: 0.1243 - mean_squared_error: 0.0578\n",
      "Epoch 16/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3038 - acc: 0.1241 - mean_squared_error: 0.0578\n",
      "Epoch 17/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3033 - acc: 0.1251 - mean_squared_error: 0.0578\n",
      "Epoch 18/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3028 - acc: 0.1242 - mean_squared_error: 0.0578\n",
      "Epoch 19/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3027 - acc: 0.1259 - mean_squared_error: 0.0578\n",
      "Epoch 20/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3025 - acc: 0.1240 - mean_squared_error: 0.0578\n",
      "Epoch 21/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3026 - acc: 0.1212 - mean_squared_error: 0.0578\n",
      "Epoch 22/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3028 - acc: 0.1243 - mean_squared_error: 0.0578\n",
      "Epoch 23/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3022 - acc: 0.1257 - mean_squared_error: 0.0578\n",
      "Epoch 24/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3022 - acc: 0.1238 - mean_squared_error: 0.0579\n",
      "Epoch 25/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3019 - acc: 0.1245 - mean_squared_error: 0.0578\n",
      "Epoch 26/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3018 - acc: 0.1233 - mean_squared_error: 0.0578\n",
      "Epoch 27/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3016 - acc: 0.1243 - mean_squared_error: 0.0578\n",
      "Epoch 28/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3024 - acc: 0.1237 - mean_squared_error: 0.0578\n",
      "Epoch 29/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3016 - acc: 0.1234 - mean_squared_error: 0.0578\n",
      "Epoch 30/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3013 - acc: 0.1243 - mean_squared_error: 0.0578\n",
      "Epoch 31/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3015 - acc: 0.1241 - mean_squared_error: 0.0578\n",
      "Epoch 32/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3011 - acc: 0.1229 - mean_squared_error: 0.0578\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3013 - acc: 0.1235 - mean_squared_error: 0.0578\n",
      "Epoch 34/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3011 - acc: 0.1260 - mean_squared_error: 0.0578\n",
      "Epoch 35/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3014 - acc: 0.1238 - mean_squared_error: 0.0578\n",
      "Epoch 36/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3013 - acc: 0.1251 - mean_squared_error: 0.0578\n",
      "Epoch 37/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3016 - acc: 0.1254 - mean_squared_error: 0.0578\n",
      "Epoch 38/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3013 - acc: 0.1235 - mean_squared_error: 0.0578\n",
      "Epoch 39/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3023 - acc: 0.1247 - mean_squared_error: 0.0578\n",
      "Epoch 40/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3015 - acc: 0.1232 - mean_squared_error: 0.0578\n",
      "Epoch 41/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3020 - acc: 0.1234 - mean_squared_error: 0.0578\n",
      "Epoch 42/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3012 - acc: 0.1225 - mean_squared_error: 0.0578\n",
      "Epoch 43/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3011 - acc: 0.1228 - mean_squared_error: 0.0578\n",
      "Epoch 44/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3008 - acc: 0.1228 - mean_squared_error: 0.0578\n",
      "Epoch 45/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3009 - acc: 0.1249 - mean_squared_error: 0.0578\n",
      "Epoch 46/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3013 - acc: 0.1237 - mean_squared_error: 0.0578\n",
      "Epoch 47/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3009 - acc: 0.1248 - mean_squared_error: 0.0578\n",
      "Epoch 48/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3017 - acc: 0.1232 - mean_squared_error: 0.0578\n",
      "Epoch 49/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3018 - acc: 0.1241 - mean_squared_error: 0.0578\n",
      "Epoch 50/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3007 - acc: 0.1262 - mean_squared_error: 0.0578\n",
      "Epoch 51/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3006 - acc: 0.1227 - mean_squared_error: 0.0578\n",
      "Epoch 52/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3012 - acc: 0.1219 - mean_squared_error: 0.0578\n",
      "Epoch 53/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3002 - acc: 0.1244 - mean_squared_error: 0.0578\n",
      "Epoch 54/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3007 - acc: 0.1216 - mean_squared_error: 0.0578\n",
      "Epoch 55/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3006 - acc: 0.1254 - mean_squared_error: 0.0578\n",
      "Epoch 56/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3005 - acc: 0.1230 - mean_squared_error: 0.0578\n",
      "Epoch 57/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3007 - acc: 0.1227 - mean_squared_error: 0.0578\n",
      "Epoch 58/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3010 - acc: 0.1234 - mean_squared_error: 0.0578\n",
      "Epoch 59/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3007 - acc: 0.1240 - mean_squared_error: 0.0578\n",
      "Epoch 60/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.3008 - acc: 0.1242 - mean_squared_error: 0.0578\n",
      "Epoch 61/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3005 - acc: 0.1233 - mean_squared_error: 0.0578\n",
      "Epoch 62/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.3018 - acc: 0.1258 - mean_squared_error: 0.0578\n",
      "Epoch 63/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 3.6044 - acc: 0.0834 - mean_squared_error: 0.0612\n",
      "Epoch 64/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.4632 - acc: 0.0715 - mean_squared_error: 0.0635\n",
      "Epoch 65/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.1320 - acc: 0.0612 - mean_squared_error: 0.0592\n",
      "Epoch 66/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.0839 - acc: 0.0590 - mean_squared_error: 0.0590\n",
      "Epoch 67/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 3.0123 - acc: 0.0614 - mean_squared_error: 0.0589\n",
      "Epoch 68/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.9226 - acc: 0.0618 - mean_squared_error: 0.0589\n",
      "Epoch 69/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.8364 - acc: 0.0605 - mean_squared_error: 0.0588\n",
      "Epoch 70/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7866 - acc: 0.0610 - mean_squared_error: 0.0587\n",
      "Epoch 71/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7758 - acc: 0.0602 - mean_squared_error: 0.0586\n",
      "Epoch 72/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7770 - acc: 0.0616 - mean_squared_error: 0.0586\n",
      "Epoch 73/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7743 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 74/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 75/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 76/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 77/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 78/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0610 - mean_squared_error: 0.0586\n",
      "Epoch 79/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 80/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0612 - mean_squared_error: 0.0586\n",
      "Epoch 81/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0633 - mean_squared_error: 0.0586\n",
      "Epoch 82/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 83/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 84/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0621 - mean_squared_error: 0.0586\n",
      "Epoch 85/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 86/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0607 - mean_squared_error: 0.0586\n",
      "Epoch 87/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 88/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 89/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 90/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 91/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0626 - mean_squared_error: 0.0586\n",
      "Epoch 92/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 93/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 94/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 95/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0633 - mean_squared_error: 0.0586\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7726 - acc: 0.0621 - mean_squared_error: 0.0586\n",
      "Epoch 97/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 98/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 99/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 100/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0597 - mean_squared_error: 0.0586\n",
      "Epoch 101/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 102/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 103/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0604 - mean_squared_error: 0.0586\n",
      "Epoch 104/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 105/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 106/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 107/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 108/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0610 - mean_squared_error: 0.0586\n",
      "Epoch 109/200\n",
      "32000/32000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 110/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 111/200\n",
      "32000/32000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 112/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 113/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 114/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 115/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0635 - mean_squared_error: 0.0586\n",
      "Epoch 116/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0612 - mean_squared_error: 0.0586\n",
      "Epoch 117/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 118/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 119/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 120/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 121/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 122/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0613 - mean_squared_error: 0.0586\n",
      "Epoch 123/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 124/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 125/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 126/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7726 - acc: 0.0618 - mean_squared_error: 0.0586\n",
      "Epoch 127/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 128/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 129/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 130/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0618 - mean_squared_error: 0.0586\n",
      "Epoch 131/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 132/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0635 - mean_squared_error: 0.0586\n",
      "Epoch 133/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 134/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 135/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0635 - mean_squared_error: 0.0586\n",
      "Epoch 136/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 137/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 138/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0603 - mean_squared_error: 0.0586\n",
      "Epoch 139/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 140/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 141/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0618 - mean_squared_error: 0.0586\n",
      "Epoch 142/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 143/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0619 - mean_squared_error: 0.0586\n",
      "Epoch 144/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 145/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 146/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0617 - mean_squared_error: 0.0586\n",
      "Epoch 147/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 148/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0619 - mean_squared_error: 0.0586\n",
      "Epoch 149/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 150/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0627 - mean_squared_error: 0.0586\n",
      "Epoch 151/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0621 - mean_squared_error: 0.0586\n",
      "Epoch 152/200\n",
      "32000/32000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 153/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7733 - acc: 0.0615 - mean_squared_error: 0.0586\n",
      "Epoch 154/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 155/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 156/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 157/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0621 - mean_squared_error: 0.0586\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 159/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0603 - mean_squared_error: 0.0586\n",
      "Epoch 160/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0612 - mean_squared_error: 0.0586\n",
      "Epoch 161/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 162/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 163/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0622 - mean_squared_error: 0.0586\n",
      "Epoch 164/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0618 - mean_squared_error: 0.0586\n",
      "Epoch 165/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0627 - mean_squared_error: 0.0586\n",
      "Epoch 166/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 167/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 168/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 169/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 170/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0607 - mean_squared_error: 0.0586\n",
      "Epoch 171/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0619 - mean_squared_error: 0.0586\n",
      "Epoch 172/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 173/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0618 - mean_squared_error: 0.0586\n",
      "Epoch 174/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 175/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 176/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 177/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 178/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7733 - acc: 0.0626 - mean_squared_error: 0.0586\n",
      "Epoch 179/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7735 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 180/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0657 - mean_squared_error: 0.0586\n",
      "Epoch 181/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 182/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7726 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 183/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 184/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0614 - mean_squared_error: 0.0586\n",
      "Epoch 185/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0612 - mean_squared_error: 0.0586\n",
      "Epoch 186/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 187/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0616 - mean_squared_error: 0.0586\n",
      "Epoch 188/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 189/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7731 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 190/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0619 - mean_squared_error: 0.0586\n",
      "Epoch 191/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0626 - mean_squared_error: 0.0586\n",
      "Epoch 192/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 193/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7729 - acc: 0.0619 - mean_squared_error: 0.0586\n",
      "Epoch 194/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0651 - mean_squared_error: 0.0586\n",
      "Epoch 195/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 196/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 197/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7732 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 198/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7728 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 199/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7734 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 200/200\n",
      "32000/32000 [==============================] - 0s 3us/step - loss: 2.7730 - acc: 0.0614 - mean_squared_error: 0.0586\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01586232]\n",
      "Es/No: 20 SER: 0.93584375 Theor_SER_PAM: 0.11723145012290671\n",
      "(20000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 16)           272         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 8)            136         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 4)            36          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 2)            10          dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 2)            4           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 2)            0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 2)            0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 2)            0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 1)            0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 2)            0           lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 1)            0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3)            0           lambda_22[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 2)            8           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 4)            12          dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 8)            40          dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 16)           144         dense_31[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 662\n",
      "Trainable params: 658\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "20000/20000 [==============================] - 4s 189us/step - loss: 13.9504 - acc: 0.0702 - mean_squared_error: 0.0978\n",
      "Epoch 2/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 14.1727 - acc: 0.0539 - mean_squared_error: 0.0926\n",
      "Epoch 3/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 14.2042 - acc: 0.0645 - mean_squared_error: 0.1084\n",
      "Epoch 4/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 14.1737 - acc: 0.0877 - mean_squared_error: 0.1128\n",
      "Epoch 5/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 14.3940 - acc: 0.0904 - mean_squared_error: 0.1134\n",
      "Epoch 6/200\n",
      "20000/20000 [==============================] - 0s 7us/step - loss: 14.1238 - acc: 0.1137 - mean_squared_error: 0.1106\n",
      "Epoch 7/200\n",
      "20000/20000 [==============================] - 0s 7us/step - loss: 13.8982 - acc: 0.1262 - mean_squared_error: 0.1046\n",
      "Epoch 8/200\n",
      "20000/20000 [==============================] - 0s 7us/step - loss: 14.0876 - acc: 0.1261 - mean_squared_error: 0.1038\n",
      "Epoch 9/200\n",
      "20000/20000 [==============================] - 0s 7us/step - loss: 14.4900 - acc: 0.0856 - mean_squared_error: 0.1113\n",
      "Epoch 10/200\n",
      "20000/20000 [==============================] - 0s 7us/step - loss: 13.5258 - acc: 0.1015 - mean_squared_error: 0.1088\n",
      "Epoch 11/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 12.8600 - acc: 0.1090 - mean_squared_error: 0.1056\n",
      "Epoch 12/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 6.0127 - acc: 0.0888 - mean_squared_error: 0.0752\n",
      "Epoch 13/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.9461 - acc: 0.0608 - mean_squared_error: 0.0599\n",
      "Epoch 14/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.8488 - acc: 0.0608 - mean_squared_error: 0.0591\n",
      "Epoch 15/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.8201 - acc: 0.0629 - mean_squared_error: 0.0589\n",
      "Epoch 16/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.8082 - acc: 0.0639 - mean_squared_error: 0.0588\n",
      "Epoch 17/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7888 - acc: 0.0640 - mean_squared_error: 0.0587\n",
      "Epoch 18/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7789 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 19/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7764 - acc: 0.0651 - mean_squared_error: 0.0586\n",
      "Epoch 20/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7756 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 21/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7747 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 22/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7737 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 23/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 24/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7726 - acc: 0.0657 - mean_squared_error: 0.0586\n",
      "Epoch 25/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 26/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 27/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 28/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0622 - mean_squared_error: 0.0586\n",
      "Epoch 29/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 30/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 31/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 32/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 34/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 35/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7722 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 36/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 37/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 38/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 39/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 40/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 41/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 42/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 43/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 44/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 45/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 46/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 47/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 48/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 49/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 50/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 51/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 52/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7722 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 53/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 54/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 55/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 56/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 57/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 58/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 59/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 60/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 61/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 62/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 63/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 64/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 65/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 66/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 67/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 68/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 69/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 70/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0664 - mean_squared_error: 0.0586\n",
      "Epoch 71/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 72/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 73/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 74/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 75/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 76/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 77/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 78/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 79/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0616 - mean_squared_error: 0.0586\n",
      "Epoch 80/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 81/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 82/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 83/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0633 - mean_squared_error: 0.0586\n",
      "Epoch 84/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 85/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 86/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 87/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 88/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0648 - mean_squared_error: 0.0586\n",
      "Epoch 89/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 90/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 91/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 92/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 93/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 94/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 95/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 96/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 97/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 98/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0662 - mean_squared_error: 0.0586\n",
      "Epoch 99/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 100/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 101/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 102/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 103/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7724 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 104/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7726 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 105/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 106/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 107/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 108/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 109/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 110/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 111/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 112/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 113/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 114/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 115/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 116/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 117/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 118/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 119/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0617 - mean_squared_error: 0.0586\n",
      "Epoch 120/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 121/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 122/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7726 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 123/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 124/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 125/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 126/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 127/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 128/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 129/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 130/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 131/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0653 - mean_squared_error: 0.0586\n",
      "Epoch 132/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 133/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 134/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 135/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 136/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 137/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 138/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 139/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 140/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 141/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 142/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 143/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 144/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7724 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 145/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 146/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 147/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0617 - mean_squared_error: 0.0586\n",
      "Epoch 148/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 149/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 150/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 151/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 152/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7726 - acc: 0.0612 - mean_squared_error: 0.0586\n",
      "Epoch 153/200\n",
      "20000/20000 [==============================] - 0s 6us/step - loss: 2.7725 - acc: 0.0617 - mean_squared_error: 0.0586\n",
      "Epoch 154/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7724 - acc: 0.0658 - mean_squared_error: 0.0586\n",
      "Epoch 155/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7724 - acc: 0.0633 - mean_squared_error: 0.0586\n",
      "Epoch 156/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7726 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 157/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0653 - mean_squared_error: 0.0586\n",
      "Epoch 158/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 159/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0648 - mean_squared_error: 0.0586\n",
      "Epoch 160/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 161/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 162/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 163/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 164/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 165/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0615 - mean_squared_error: 0.0586\n",
      "Epoch 166/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 167/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 168/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 169/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 170/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 171/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 172/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 173/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 174/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 175/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 176/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 177/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7723 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 178/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0615 - mean_squared_error: 0.0586\n",
      "Epoch 179/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 180/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 181/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 182/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 183/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 184/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 185/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 186/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 187/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0616 - mean_squared_error: 0.0586\n",
      "Epoch 188/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 189/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 190/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7725 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 191/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0655 - mean_squared_error: 0.0586\n",
      "Epoch 192/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7724 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 193/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7724 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 194/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7725 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 195/200\n",
      "20000/20000 [==============================] - 0s 3us/step - loss: 2.7727 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 196/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7723 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 197/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0633 - mean_squared_error: 0.0586\n",
      "Epoch 198/200\n",
      "20000/20000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 199/200\n",
      "20000/20000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 200/200\n",
      "20000/20000 [==============================] - 0s 8us/step - loss: 2.7725 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[302.87897]\n",
      "Es/No: 25 SER: 0.9366 Theor_SER_PAM: 0.00597813169126268\n",
      "(21000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 16)           272         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 8)            136         dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 4)            36          dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 2)            10          dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 2)            4           dense_36[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 2)            0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 2)            0           lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 2)            0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 1)            0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 2)            0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 1)            0           lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 3)            0           lambda_28[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 2)            8           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 4)            12          dense_37[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 8)            40          dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 16)           144         dense_39[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 662\n",
      "Trainable params: 658\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "21000/21000 [==============================] - 6s 266us/step - loss: 10.4832 - acc: 0.0820 - mean_squared_error: 0.0958\n",
      "Epoch 2/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7460 - acc: 0.0607 - mean_squared_error: 0.0581\n",
      "Epoch 3/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.5667 - acc: 0.1191 - mean_squared_error: 0.0558\n",
      "Epoch 4/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.5290 - acc: 0.1077 - mean_squared_error: 0.0554\n",
      "Epoch 5/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.5260 - acc: 0.1356 - mean_squared_error: 0.0557\n",
      "Epoch 6/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4796 - acc: 0.1360 - mean_squared_error: 0.0553\n",
      "Epoch 7/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4358 - acc: 0.1214 - mean_squared_error: 0.0549\n",
      "Epoch 8/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4268 - acc: 0.1238 - mean_squared_error: 0.0548\n",
      "Epoch 9/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4122 - acc: 0.1238 - mean_squared_error: 0.0544\n",
      "Epoch 10/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3929 - acc: 0.1639 - mean_squared_error: 0.0535\n",
      "Epoch 11/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3683 - acc: 0.1873 - mean_squared_error: 0.0523\n",
      "Epoch 12/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3467 - acc: 0.1884 - mean_squared_error: 0.0513\n",
      "Epoch 13/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3348 - acc: 0.1880 - mean_squared_error: 0.0510\n",
      "Epoch 14/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3293 - acc: 0.1864 - mean_squared_error: 0.0510\n",
      "Epoch 15/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3276 - acc: 0.1852 - mean_squared_error: 0.0509\n",
      "Epoch 16/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.3279 - acc: 0.1856 - mean_squared_error: 0.0510\n",
      "Epoch 17/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.5545 - acc: 0.1584 - mean_squared_error: 0.0540\n",
      "Epoch 18/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4015 - acc: 0.1622 - mean_squared_error: 0.0542\n",
      "Epoch 19/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.4864 - acc: 0.1743 - mean_squared_error: 0.0552\n",
      "Epoch 20/200\n",
      "21000/21000 [==============================] - 0s 3us/step - loss: 3.0966 - acc: 0.0880 - mean_squared_error: 0.0599\n",
      "Epoch 21/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 3.0418 - acc: 0.0666 - mean_squared_error: 0.0591\n",
      "Epoch 22/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.9809 - acc: 0.0666 - mean_squared_error: 0.0591\n",
      "Epoch 23/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.9013 - acc: 0.0666 - mean_squared_error: 0.0590\n",
      "Epoch 24/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.8299 - acc: 0.0666 - mean_squared_error: 0.0589\n",
      "Epoch 25/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7859 - acc: 0.0666 - mean_squared_error: 0.0587\n",
      "Epoch 26/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7756 - acc: 0.0607 - mean_squared_error: 0.0586\n",
      "Epoch 27/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7854 - acc: 0.0595 - mean_squared_error: 0.0587\n",
      "Epoch 28/200\n",
      "21000/21000 [==============================] - 0s 8us/step - loss: 2.7765 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 29/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.9104 - acc: 0.0631 - mean_squared_error: 0.0593\n",
      "Epoch 30/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7736 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 31/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 32/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7733 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 34/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 35/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0622 - mean_squared_error: 0.0586\n",
      "Epoch 36/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0624 - mean_squared_error: 0.0586\n",
      "Epoch 37/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 38/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 39/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7732 - acc: 0.0622 - mean_squared_error: 0.0586\n",
      "Epoch 40/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 41/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7729 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 42/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 43/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7727 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 44/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7733 - acc: 0.0610 - mean_squared_error: 0.0586\n",
      "Epoch 45/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7727 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 46/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7732 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 47/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0663 - mean_squared_error: 0.0586\n",
      "Epoch 48/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 49/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 50/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7732 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 51/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7732 - acc: 0.0605 - mean_squared_error: 0.0586\n",
      "Epoch 52/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7733 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 53/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7736 - acc: 0.0638 - mean_squared_error: 0.0586\n",
      "Epoch 54/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 55/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7735 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 56/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 57/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7732 - acc: 0.0637 - mean_squared_error: 0.0586\n",
      "Epoch 58/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0650 - mean_squared_error: 0.0586\n",
      "Epoch 59/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7727 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 60/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 61/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7729 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 62/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7733 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 63/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0665 - mean_squared_error: 0.0586\n",
      "Epoch 64/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7734 - acc: 0.0588 - mean_squared_error: 0.0586\n",
      "Epoch 65/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 66/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7732 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 67/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0667 - mean_squared_error: 0.0586\n",
      "Epoch 68/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 69/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0665 - mean_squared_error: 0.0586\n",
      "Epoch 70/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7732 - acc: 0.0626 - mean_squared_error: 0.0586\n",
      "Epoch 71/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7726 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 72/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 73/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7733 - acc: 0.0667 - mean_squared_error: 0.0586\n",
      "Epoch 74/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7730 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 75/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7731 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 76/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7726 - acc: 0.0659 - mean_squared_error: 0.0586\n",
      "Epoch 77/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7735 - acc: 0.0625 - mean_squared_error: 0.0586\n",
      "Epoch 78/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0652 - mean_squared_error: 0.0586\n",
      "Epoch 79/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7732 - acc: 0.0623 - mean_squared_error: 0.0586\n",
      "Epoch 80/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 81/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0662 - mean_squared_error: 0.0586\n",
      "Epoch 82/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 83/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 84/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0682 - mean_squared_error: 0.0586\n",
      "Epoch 85/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 86/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0653 - mean_squared_error: 0.0586\n",
      "Epoch 87/200\n",
      "21000/21000 [==============================] - 0s 10us/step - loss: 2.7729 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 88/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 89/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7728 - acc: 0.0646 - mean_squared_error: 0.0586\n",
      "Epoch 90/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7730 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 91/200\n",
      "21000/21000 [==============================] - 0s 17us/step - loss: 2.7729 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 92/200\n",
      "16384/21000 [======================>.......] - ETA: 0s - loss: 2.7725 - acc: 0.0682 - mean_squared_error: 0.0586"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.249990). Check your callbacks.\n",
      "  % delta_t_median)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7727 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 93/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 94/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 95/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0651 - mean_squared_error: 0.0586\n",
      "Epoch 96/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7734 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 97/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7726 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 98/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7729 - acc: 0.0639 - mean_squared_error: 0.0586\n",
      "Epoch 99/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0651 - mean_squared_error: 0.0586\n",
      "Epoch 100/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7729 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 101/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7730 - acc: 0.0630 - mean_squared_error: 0.0586\n",
      "Epoch 102/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7729 - acc: 0.0629 - mean_squared_error: 0.0586\n",
      "Epoch 103/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7726 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 104/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0644 - mean_squared_error: 0.0586\n",
      "Epoch 105/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0640 - mean_squared_error: 0.0586\n",
      "Epoch 106/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 107/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7730 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 108/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 109/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 110/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7730 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 111/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7733 - acc: 0.0609 - mean_squared_error: 0.0586\n",
      "Epoch 112/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0645 - mean_squared_error: 0.0586\n",
      "Epoch 113/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7736 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 114/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7735 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 115/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7735 - acc: 0.0615 - mean_squared_error: 0.0586\n",
      "Epoch 116/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0668 - mean_squared_error: 0.0586\n",
      "Epoch 117/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7734 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 118/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 119/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7733 - acc: 0.0679 - mean_squared_error: 0.0586\n",
      "Epoch 120/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7733 - acc: 0.0648 - mean_squared_error: 0.0586\n",
      "Epoch 121/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7736 - acc: 0.0632 - mean_squared_error: 0.0586\n",
      "Epoch 122/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0649 - mean_squared_error: 0.0586\n",
      "Epoch 123/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 124/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 125/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7737 - acc: 0.0617 - mean_squared_error: 0.0586\n",
      "Epoch 126/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7731 - acc: 0.0628 - mean_squared_error: 0.0586\n",
      "Epoch 127/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7730 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 128/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 129/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 130/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0631 - mean_squared_error: 0.0586\n",
      "Epoch 131/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7727 - acc: 0.0636 - mean_squared_error: 0.0586\n",
      "Epoch 132/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0634 - mean_squared_error: 0.0586\n",
      "Epoch 133/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 134/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7728 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 135/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7730 - acc: 0.0641 - mean_squared_error: 0.0586\n",
      "Epoch 136/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7726 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 137/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7732 - acc: 0.0592 - mean_squared_error: 0.0586\n",
      "Epoch 138/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7731 - acc: 0.0626 - mean_squared_error: 0.0586\n",
      "Epoch 139/200\n",
      "21000/21000 [==============================] - 0s 7us/step - loss: 2.7729 - acc: 0.0611 - mean_squared_error: 0.0586\n",
      "Epoch 140/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7732 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 141/200\n",
      "21000/21000 [==============================] - 0s 6us/step - loss: 2.7734 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 142/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7729 - acc: 0.0647 - mean_squared_error: 0.0586\n",
      "Epoch 143/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7735 - acc: 0.0606 - mean_squared_error: 0.0586\n",
      "Epoch 144/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7728 - acc: 0.0643 - mean_squared_error: 0.0586\n",
      "Epoch 145/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7733 - acc: 0.0610 - mean_squared_error: 0.0586\n",
      "Epoch 146/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7730 - acc: 0.0666 - mean_squared_error: 0.0586\n",
      "Epoch 147/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7734 - acc: 0.0620 - mean_squared_error: 0.0586\n",
      "Epoch 148/200\n",
      "21000/21000 [==============================] - 0s 4us/step - loss: 2.7727 - acc: 0.0642 - mean_squared_error: 0.0586\n",
      "Epoch 149/200\n",
      "21000/21000 [==============================] - 0s 5us/step - loss: 2.7727 - acc: 0.0654 - mean_squared_error: 0.0586\n",
      "Epoch 150/200\n",
      "16384/21000 [======================>.......] - ETA: 0s - loss: 2.7728 - acc: 0.0670 - mean_squared_error: 0.0586"
     ]
    }
   ],
   "source": [
    "EsNodB_range = [12,16,20,25,26]\n",
    "N_array=[17000,24000,32000,20000,21000]\n",
    "ser = [None]*len(EsNodB_range)\n",
    "theor_ser_qam = [None]*len(EsNodB_range)\n",
    "theor_ser = [None]*len(EsNodB_range)\n",
    "\n",
    "noise_std = np.sqrt(1)\n",
    "for n in range(0,len(EsNodB_range)):\n",
    "    \n",
    "    EsNo=10.0**(EsNodB_range[n]/10.0)\n",
    "    P = EsNo*(noise_std**2)\n",
    "    \n",
    "    no_errors = 0\n",
    "    \n",
    "    N=N_array[n]\n",
    "   \n",
    "    \n",
    "    autoencoder = set_up_train_nn(P)\n",
    "    \n",
    "    # generating data for checking SER\n",
    "    test_label = np.random.randint(M,size=N)\n",
    "    test_data = []\n",
    "\n",
    "    for i in test_label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        test_data.append(temp)\n",
    "\n",
    "    test_data = np.array(test_data)\n",
    "    \n",
    "    pred_final_signal = autoencoder.predict(test_data)\n",
    "    \n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ser[n] = no_errors / N \n",
    "    \n",
    "    theor_ser[n] = (15/16)*special.erfc(np.sqrt(EsNo/85))\n",
    "    \n",
    "    print ('Es/No:',EsNodB_range[n],'SER:',ser[n],'Theor_SER_PAM:',theor_ser[n])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EsNodB_range, theor_ser, 'g--',label='16 PAM')\n",
    "plt.plot(EsNodB_range, ser, 'bo-',label='Conventional PD-both streams')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='best',ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
