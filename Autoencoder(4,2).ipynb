{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,Callback,ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "\n",
    "from scipy import special\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average Power Normalization\n",
    "def fixed_power_norm(x,P):\n",
    "    beta = K.sqrt(K.sum(K.square(x),axis=1))\n",
    "    return   np.sqrt(P)*x / beta[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 16\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 16\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "print('number of symbols:',M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_nn(P):\n",
    "    N=16000\n",
    "    EbNo_train = 5.01187\n",
    "    label = np.random.randint(M,size=N)\n",
    "    \n",
    "    # creating one hot encoded vectors\n",
    "    data = []\n",
    "    for i in label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        data.append(temp)\n",
    "        # checking data shape\n",
    "    data = np.array(data)\n",
    "    print (data.shape)\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss',patience=5, verbose=1)\n",
    "    \n",
    "    # Defined Autoencoder\n",
    "    input_signal = Input(shape=(M,))\n",
    "    encoded = Dense(M, activation='relu')(input_signal)\n",
    "    encoded2 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "\n",
    "    # Normalize Power\n",
    "    encoded3 = Lambda(lambda x: fixed_power_norm(x,P))(encoded2)\n",
    "    \n",
    "    #Add antenna noise\n",
    "    encoded5 = Lambda(lambda x: x+K.random_normal_variable((4*4096,2), 0,np.sqrt(1/(2*R*EbNo_train)))[0:tf.shape(x)[0],:])(encoded3)\n",
    "\n",
    "    # Reciever Layer\n",
    "    decoded = Dense(M, activation='relu')(encoded5)\n",
    "    decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "    autoencoder = Model(input_signal, decoded1)\n",
    "\n",
    "    adam = Adam(lr=0.01)\n",
    "    epochs=70\n",
    "    autoencoder.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    \n",
    "    # traning auto encoder\n",
    "    history = autoencoder.fit(data, data,epochs=epochs,batch_size=2048,callbacks=[es],validation_split=0.3)\n",
    "    \n",
    "    # list all data in history\n",
    "    print(history.history.keys())\n",
    "    \n",
    "    results = autoencoder.evaluate(data, data, batch_size=2048)\n",
    "    print('test loss, test acc:', results)\n",
    "\n",
    "    \n",
    "    # making encoder from full autoencoder\n",
    "    encoder = Model(input_signal, encoded3)\n",
    "    \n",
    "    \n",
    "    scatter_plot = []\n",
    "    for i in range(0,M):\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "    scatter_plot = np.array(scatter_plot)\n",
    "    print (scatter_plot.shape)\n",
    "    \n",
    "    # ploting constellation diagram\n",
    "    \n",
    "    scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "\n",
    "    plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "    #plt.axis((-2,2,-2,2))\n",
    "    plt.grid()\n",
    "    #plt.title('Splitting Receiver: rho = '+str(rho)+' P = '+str(P))\n",
    "    plt.xlabel('I Axis')\n",
    "    plt.ylabel('Q Axis')\n",
    "    plt.show()\n",
    "    p_av = np.sum(np.square(scatter_plot),axis=1)\n",
    "    print(sum(p_av)/16)\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 16)\n",
      "Train on 11200 samples, validate on 4800 samples\n",
      "Epoch 1/70\n",
      "11200/11200 [==============================] - 1s 67us/step - loss: 2.6449 - acc: 0.1918 - val_loss: 2.4657 - val_acc: 0.2498\n",
      "Epoch 2/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 2.3686 - acc: 0.2913 - val_loss: 2.2327 - val_acc: 0.3060\n",
      "Epoch 3/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 2.1323 - acc: 0.3217 - val_loss: 1.9848 - val_acc: 0.3252\n",
      "Epoch 4/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.8842 - acc: 0.3719 - val_loss: 1.7515 - val_acc: 0.3937\n",
      "Epoch 5/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.6634 - acc: 0.4313 - val_loss: 1.5496 - val_acc: 0.4542\n",
      "Epoch 6/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.4777 - acc: 0.5143 - val_loss: 1.3839 - val_acc: 0.5758\n",
      "Epoch 7/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.3267 - acc: 0.6254 - val_loss: 1.2554 - val_acc: 0.6460\n",
      "Epoch 8/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 1.2074 - acc: 0.6691 - val_loss: 1.1504 - val_acc: 0.6671\n",
      "Epoch 9/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 1.1097 - acc: 0.7092 - val_loss: 1.0613 - val_acc: 0.7250\n",
      "Epoch 10/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 1.0258 - acc: 0.7388 - val_loss: 0.9864 - val_acc: 0.7421\n",
      "Epoch 11/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.9553 - acc: 0.7550 - val_loss: 0.9238 - val_acc: 0.7502\n",
      "Epoch 12/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.8976 - acc: 0.7697 - val_loss: 0.8704 - val_acc: 0.7708\n",
      "Epoch 13/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.8461 - acc: 0.7956 - val_loss: 0.8212 - val_acc: 0.8079\n",
      "Epoch 14/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.7990 - acc: 0.8147 - val_loss: 0.7760 - val_acc: 0.8165\n",
      "Epoch 15/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.7554 - acc: 0.8349 - val_loss: 0.7337 - val_acc: 0.8442\n",
      "Epoch 16/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.7147 - acc: 0.8479 - val_loss: 0.6929 - val_acc: 0.8531\n",
      "Epoch 17/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.6787 - acc: 0.8516 - val_loss: 0.6603 - val_acc: 0.8665\n",
      "Epoch 18/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.6486 - acc: 0.8646 - val_loss: 0.6308 - val_acc: 0.8685\n",
      "Epoch 19/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.6198 - acc: 0.8694 - val_loss: 0.6046 - val_acc: 0.8796\n",
      "Epoch 20/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.5947 - acc: 0.8885 - val_loss: 0.5778 - val_acc: 0.8871\n",
      "Epoch 21/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.5663 - acc: 0.8915 - val_loss: 0.5555 - val_acc: 0.8992\n",
      "Epoch 22/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.5437 - acc: 0.8985 - val_loss: 0.5304 - val_acc: 0.9017\n",
      "Epoch 23/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.5207 - acc: 0.9038 - val_loss: 0.5106 - val_acc: 0.9046\n",
      "Epoch 24/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4985 - acc: 0.9058 - val_loss: 0.4924 - val_acc: 0.9058\n",
      "Epoch 25/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4819 - acc: 0.9010 - val_loss: 0.4706 - val_acc: 0.9123\n",
      "Epoch 26/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.4629 - acc: 0.9091 - val_loss: 0.4597 - val_acc: 0.9052\n",
      "Epoch 27/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4474 - acc: 0.9054 - val_loss: 0.4405 - val_acc: 0.9100\n",
      "Epoch 28/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4335 - acc: 0.9079 - val_loss: 0.4283 - val_acc: 0.9071\n",
      "Epoch 29/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4193 - acc: 0.9055 - val_loss: 0.4139 - val_acc: 0.9104\n",
      "Epoch 30/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.4072 - acc: 0.9087 - val_loss: 0.3996 - val_acc: 0.9142\n",
      "Epoch 31/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3922 - acc: 0.9149 - val_loss: 0.3916 - val_acc: 0.9085\n",
      "Epoch 32/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3818 - acc: 0.9102 - val_loss: 0.3776 - val_acc: 0.9148\n",
      "Epoch 33/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3753 - acc: 0.9104 - val_loss: 0.3673 - val_acc: 0.9146\n",
      "Epoch 34/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3643 - acc: 0.9113 - val_loss: 0.3627 - val_acc: 0.9146\n",
      "Epoch 35/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.3575 - acc: 0.9098 - val_loss: 0.3548 - val_acc: 0.9083\n",
      "Epoch 36/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3458 - acc: 0.9112 - val_loss: 0.3467 - val_acc: 0.9102\n",
      "Epoch 37/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.3414 - acc: 0.9093 - val_loss: 0.3350 - val_acc: 0.9129\n",
      "Epoch 38/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3317 - acc: 0.9145 - val_loss: 0.3298 - val_acc: 0.9156\n",
      "Epoch 39/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.3261 - acc: 0.9136 - val_loss: 0.3225 - val_acc: 0.9150\n",
      "Epoch 40/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.3216 - acc: 0.9087 - val_loss: 0.3181 - val_acc: 0.9156\n",
      "Epoch 41/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3152 - acc: 0.9110 - val_loss: 0.3119 - val_acc: 0.9148\n",
      "Epoch 42/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.3107 - acc: 0.9080 - val_loss: 0.3087 - val_acc: 0.9098\n",
      "Epoch 43/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.3063 - acc: 0.9085 - val_loss: 0.2992 - val_acc: 0.9154\n",
      "Epoch 44/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2981 - acc: 0.9129 - val_loss: 0.2950 - val_acc: 0.9152\n",
      "Epoch 45/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2928 - acc: 0.9166 - val_loss: 0.2940 - val_acc: 0.9135\n",
      "Epoch 46/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2903 - acc: 0.9127 - val_loss: 0.2860 - val_acc: 0.9177\n",
      "Epoch 47/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2870 - acc: 0.9139 - val_loss: 0.2864 - val_acc: 0.9131\n",
      "Epoch 48/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2853 - acc: 0.9075 - val_loss: 0.2802 - val_acc: 0.9131\n",
      "Epoch 49/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2802 - acc: 0.9129 - val_loss: 0.2758 - val_acc: 0.9131\n",
      "Epoch 50/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2809 - acc: 0.9102 - val_loss: 0.2781 - val_acc: 0.9146\n",
      "Epoch 51/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2729 - acc: 0.9127 - val_loss: 0.2733 - val_acc: 0.9167\n",
      "Epoch 52/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2747 - acc: 0.9083 - val_loss: 0.2701 - val_acc: 0.9167\n",
      "Epoch 53/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2706 - acc: 0.9104 - val_loss: 0.2682 - val_acc: 0.9142\n",
      "Epoch 54/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2697 - acc: 0.9138 - val_loss: 0.2625 - val_acc: 0.9150\n",
      "Epoch 55/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2644 - acc: 0.9140 - val_loss: 0.2637 - val_acc: 0.9123\n",
      "Epoch 56/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2670 - acc: 0.9062 - val_loss: 0.2573 - val_acc: 0.9160\n",
      "Epoch 57/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2593 - acc: 0.9155 - val_loss: 0.2580 - val_acc: 0.9138\n",
      "Epoch 58/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2617 - acc: 0.9096 - val_loss: 0.2560 - val_acc: 0.9148\n",
      "Epoch 59/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2584 - acc: 0.9108 - val_loss: 0.2558 - val_acc: 0.9110\n",
      "Epoch 60/70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2549 - acc: 0.9112 - val_loss: 0.2549 - val_acc: 0.9173\n",
      "Epoch 61/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2525 - acc: 0.9114 - val_loss: 0.2497 - val_acc: 0.9163\n",
      "Epoch 62/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2550 - acc: 0.9088 - val_loss: 0.2516 - val_acc: 0.9131\n",
      "Epoch 63/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2506 - acc: 0.9122 - val_loss: 0.2506 - val_acc: 0.9119\n",
      "Epoch 64/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2578 - acc: 0.9100 - val_loss: 0.2543 - val_acc: 0.9100\n",
      "Epoch 65/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2523 - acc: 0.9088 - val_loss: 0.2435 - val_acc: 0.9163\n",
      "Epoch 66/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2538 - acc: 0.9067 - val_loss: 0.2498 - val_acc: 0.9129\n",
      "Epoch 67/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2484 - acc: 0.9140 - val_loss: 0.2479 - val_acc: 0.9119\n",
      "Epoch 68/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2484 - acc: 0.9120 - val_loss: 0.2484 - val_acc: 0.9119\n",
      "Epoch 69/70\n",
      "11200/11200 [==============================] - 0s 3us/step - loss: 0.2447 - acc: 0.9117 - val_loss: 0.2447 - val_acc: 0.9146\n",
      "Epoch 70/70\n",
      "11200/11200 [==============================] - 0s 4us/step - loss: 0.2400 - acc: 0.9150 - val_loss: 0.2424 - val_acc: 0.9156\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n",
      "16000/16000 [==============================] - 0s 2us/step\n",
      "test loss, test acc: [0.2465314247608185, 0.9103125019073486]\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.]\n"
     ]
    }
   ],
   "source": [
    "# Calculating SER from -4dB to 14dB SNR\n",
    "autoencoder = set_up_train_nn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
