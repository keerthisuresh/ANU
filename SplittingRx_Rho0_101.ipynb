{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# MIT License\n",
    "\n",
    "# Copyright (c) [2019] [Jayden Booth]\n",
    "\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "# Import Libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Dense, GaussianNoise,Lambda,Dropout, Concatenate\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam,SGD\n",
    "from keras import backend as K\n",
    "from keras.constraints import max_norm\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interpolate\n",
    "from scipy import special"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of symbols: 16\n"
     ]
    }
   ],
   "source": [
    "# Set the defining parameters\n",
    "# n = n_channel complex numbers (so 2n real numbers)\n",
    "# k = log2(M), where M is the number of messages to encode\n",
    "# EbNo is the energy per bit to noise power density\n",
    "\n",
    "# Encoder Parameters\n",
    "M = 16\n",
    "k = np.log2(M)\n",
    "n_channel = 1\n",
    "R = k/n_channel\n",
    "\n",
    "#Power splitting ratio\n",
    "rho = 0\n",
    "eps=1\n",
    "eta=1\n",
    "print('number of symbols:',M)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_up_train_nn(P,EsNodB):\n",
    "    label = np.random.randint(M,size=N)\n",
    "\n",
    "    # creating one hot encoded vectors\n",
    "    data = []\n",
    "    for i in label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        data.append(temp)\n",
    "\n",
    "    # checking data shape\n",
    "    data = np.array(data)\n",
    "    print (data.shape)\n",
    "\n",
    "\n",
    "    # Defined Autoencoder\n",
    "    batch_size = 1024\n",
    "    \n",
    "    # Transmitter Layers\n",
    "    input_signal = Input(shape=(M,))\n",
    "    encoded = Dense(M, activation='relu')(input_signal)\n",
    "    encoded2 = Dense(8, activation='relu')(encoded)\n",
    "    encoded2 = Dense(4, activation='relu')(encoded)\n",
    "    encoded2 = Dense(2*n_channel, activation='linear')(encoded)\n",
    "\n",
    "    # Normalize Power\n",
    "    encoded3 = BatchNormalization(momentum=0,epsilon=1e-6,center=False,scale=False,axis=1)(encoded2)\n",
    "    encoded3 = Lambda(lambda x: x*np.sqrt(P/2))(encoded3)\n",
    "\n",
    "    #adding channel noise\n",
    "    encoded4 = Lambda(lambda x: x+K.random_normal_variable((32768*2,2), 0,np.sqrt(0.5))[0:tf.shape(x)[0],:])(encoded3)\n",
    "\n",
    "\n",
    "    # Slicing into CD and PD data, and applying noise\n",
    "\n",
    "    cd_data = Lambda(lambda x: np.sqrt(rho)*np.sqrt(eps)*x)(encoded4)\n",
    "    \n",
    "    \n",
    "    pd_data = Lambda(lambda x: K.expand_dims((1-rho)*eta*eps*K.sum(K.square(x),axis=1),axis=1))(encoded4)\n",
    "    pd_data = Lambda(lambda x: x+K.random_normal_variable((32768*2,1), 0,np.sqrt(0.1))[0:tf.shape(x)[0]])(pd_data)\n",
    "\n",
    "    #combining the split data to feed the decoder\n",
    "    data_split=[]\n",
    "    data_split.append(cd_data)\n",
    "    data_split.append(pd_data)\n",
    "\n",
    "    data_split =  Concatenate(axis=1)(data_split)\n",
    "\n",
    "\n",
    "    # Reciever Layer\n",
    "    decoded = Dense(2, activation='linear')(data_split)\n",
    "    decoded = Dense(4, activation='relu')(data_split)\n",
    "    decoded = Dense(8, activation='relu')(decoded)\n",
    "    decoded1 = Dense(M, activation='softmax')(decoded)\n",
    "    autoencoder = Model(input_signal, decoded1)\n",
    "\n",
    "    adam = Adam(lr=0.1)\n",
    "    sgd = SGD(lr=0.5)\n",
    "    autoencoder.compile(optimizer=adam, loss='categorical_crossentropy',metrics=['accuracy','mse'])\n",
    "\n",
    "    # printing summary of layers and it's trainable parameters \n",
    "    print (autoencoder.summary())\n",
    "\n",
    "    # traning auto encoder\n",
    "    autoencoder.fit(data, data,\n",
    "                    epochs=200,\n",
    "                    batch_size=batch_size)\n",
    "\n",
    "    # making encoder from full autoencoder\n",
    "    encoder = Model(input_signal, encoded3)\n",
    "\n",
    "    # for plotting learned consteallation diagram\n",
    "\n",
    "    scatter_plot = []\n",
    "    for i in range(0,M):\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        scatter_plot.append(encoder.predict(np.expand_dims(temp,axis=0)))\n",
    "    scatter_plot = np.array(scatter_plot)\n",
    "    print (scatter_plot.shape)\n",
    "\n",
    "    # ploting constellation diagram\n",
    "    import matplotlib.pyplot as plt\n",
    "    scatter_plot = scatter_plot.reshape(M,2,1)\n",
    "\n",
    "    plt.scatter(scatter_plot[:,0],scatter_plot[:,1])\n",
    "    #plt.axis((-2,2,-2,2))\n",
    "    plt.grid()\n",
    "    #plt.title('Splitting Receiver: rho = '+str(rho)+' eps = '+str(eps))\n",
    "    plt.xlabel('I Axis')\n",
    "    plt.ylabel('Q Axis')\n",
    "    plt.show()\n",
    "    p_av = np.sum(np.square(scatter_plot),axis=1)\n",
    "    print(sum(p_av)/16)\n",
    "\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75000, 16)\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           272         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 2)            34          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 2)            4           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 2)            0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 2)            0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 1)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 2)            0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1)            0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           lambda_3[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 4)            16          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 8)            40          dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           144         dense_7[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 510\n",
      "Trainable params: 506\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\u1081001\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/200\n",
      "75000/75000 [==============================] - 4s 49us/step - loss: 2.1084 - acc: 0.2189 - mean_squared_error: 0.0518\n",
      "Epoch 2/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6939 - acc: 0.2740 - mean_squared_error: 0.0476\n",
      "Epoch 3/200\n",
      "75000/75000 [==============================] - 1s 10us/step - loss: 1.6708 - acc: 0.2854 - mean_squared_error: 0.0475\n",
      "Epoch 4/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6535 - acc: 0.2940 - mean_squared_error: 0.0471\n",
      "Epoch 5/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6302 - acc: 0.2982 - mean_squared_error: 0.0466\n",
      "Epoch 6/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6390 - acc: 0.2963 - mean_squared_error: 0.0467\n",
      "Epoch 7/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6452 - acc: 0.2940 - mean_squared_error: 0.0469\n",
      "Epoch 8/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6157 - acc: 0.3014 - mean_squared_error: 0.0462\n",
      "Epoch 9/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6068 - acc: 0.2998 - mean_squared_error: 0.0461\n",
      "Epoch 10/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6274 - acc: 0.2944 - mean_squared_error: 0.0466\n",
      "Epoch 11/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6038 - acc: 0.3056 - mean_squared_error: 0.0460\n",
      "Epoch 12/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6105 - acc: 0.2999 - mean_squared_error: 0.0463\n",
      "Epoch 13/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6016 - acc: 0.3038 - mean_squared_error: 0.0459\n",
      "Epoch 14/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6039 - acc: 0.3037 - mean_squared_error: 0.0460\n",
      "Epoch 15/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6179 - acc: 0.3010 - mean_squared_error: 0.0463\n",
      "Epoch 16/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6147 - acc: 0.3032 - mean_squared_error: 0.0461\n",
      "Epoch 17/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6346 - acc: 0.2994 - mean_squared_error: 0.0465\n",
      "Epoch 18/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5949 - acc: 0.3104 - mean_squared_error: 0.0458\n",
      "Epoch 19/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6045 - acc: 0.3107 - mean_squared_error: 0.0459\n",
      "Epoch 20/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5960 - acc: 0.3133 - mean_squared_error: 0.0458\n",
      "Epoch 21/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6170 - acc: 0.3110 - mean_squared_error: 0.0461\n",
      "Epoch 22/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6030 - acc: 0.3070 - mean_squared_error: 0.0460\n",
      "Epoch 23/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6044 - acc: 0.3077 - mean_squared_error: 0.0459\n",
      "Epoch 24/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6081 - acc: 0.3030 - mean_squared_error: 0.0461\n",
      "Epoch 25/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5989 - acc: 0.3108 - mean_squared_error: 0.0457\n",
      "Epoch 26/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6053 - acc: 0.3088 - mean_squared_error: 0.0459\n",
      "Epoch 27/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6141 - acc: 0.3036 - mean_squared_error: 0.0461\n",
      "Epoch 28/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6193 - acc: 0.3034 - mean_squared_error: 0.0462\n",
      "Epoch 29/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6151 - acc: 0.3071 - mean_squared_error: 0.0462\n",
      "Epoch 30/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6121 - acc: 0.3086 - mean_squared_error: 0.0461\n",
      "Epoch 31/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6045 - acc: 0.3077 - mean_squared_error: 0.0459\n",
      "Epoch 32/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6117 - acc: 0.3086 - mean_squared_error: 0.0461\n",
      "Epoch 33/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6295 - acc: 0.2992 - mean_squared_error: 0.0465\n",
      "Epoch 34/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6014 - acc: 0.3089 - mean_squared_error: 0.0459\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6029 - acc: 0.3095 - mean_squared_error: 0.0460\n",
      "Epoch 36/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5978 - acc: 0.3100 - mean_squared_error: 0.0459\n",
      "Epoch 37/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5987 - acc: 0.3106 - mean_squared_error: 0.0458\n",
      "Epoch 38/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6009 - acc: 0.3098 - mean_squared_error: 0.0459\n",
      "Epoch 39/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5950 - acc: 0.3115 - mean_squared_error: 0.0457\n",
      "Epoch 40/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6098 - acc: 0.3057 - mean_squared_error: 0.0460\n",
      "Epoch 41/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5918 - acc: 0.3116 - mean_squared_error: 0.0456\n",
      "Epoch 42/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5901 - acc: 0.3112 - mean_squared_error: 0.0456\n",
      "Epoch 43/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6184 - acc: 0.3029 - mean_squared_error: 0.0463\n",
      "Epoch 44/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6034 - acc: 0.3067 - mean_squared_error: 0.0459\n",
      "Epoch 45/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6023 - acc: 0.3075 - mean_squared_error: 0.0460\n",
      "Epoch 46/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5902 - acc: 0.3085 - mean_squared_error: 0.0457\n",
      "Epoch 47/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5949 - acc: 0.3089 - mean_squared_error: 0.0458\n",
      "Epoch 48/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6063 - acc: 0.3072 - mean_squared_error: 0.0460\n",
      "Epoch 49/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5971 - acc: 0.3085 - mean_squared_error: 0.0458\n",
      "Epoch 50/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6295 - acc: 0.3013 - mean_squared_error: 0.0464\n",
      "Epoch 51/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6153 - acc: 0.3025 - mean_squared_error: 0.0463\n",
      "Epoch 52/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6468 - acc: 0.2959 - mean_squared_error: 0.0467\n",
      "Epoch 53/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6021 - acc: 0.3064 - mean_squared_error: 0.0460\n",
      "Epoch 54/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6300 - acc: 0.2974 - mean_squared_error: 0.0465\n",
      "Epoch 55/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6098 - acc: 0.3079 - mean_squared_error: 0.0460\n",
      "Epoch 56/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5894 - acc: 0.3157 - mean_squared_error: 0.0455\n",
      "Epoch 57/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5988 - acc: 0.3144 - mean_squared_error: 0.0457\n",
      "Epoch 58/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5926 - acc: 0.3155 - mean_squared_error: 0.0457\n",
      "Epoch 59/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6029 - acc: 0.3126 - mean_squared_error: 0.0458\n",
      "Epoch 60/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6042 - acc: 0.3112 - mean_squared_error: 0.0458\n",
      "Epoch 61/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6021 - acc: 0.3116 - mean_squared_error: 0.0458\n",
      "Epoch 62/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6071 - acc: 0.3096 - mean_squared_error: 0.0460\n",
      "Epoch 63/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5870 - acc: 0.3181 - mean_squared_error: 0.0455\n",
      "Epoch 64/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6130 - acc: 0.3042 - mean_squared_error: 0.0460\n",
      "Epoch 65/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6024 - acc: 0.3080 - mean_squared_error: 0.0458\n",
      "Epoch 66/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5970 - acc: 0.3093 - mean_squared_error: 0.0457\n",
      "Epoch 67/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6032 - acc: 0.3052 - mean_squared_error: 0.0459\n",
      "Epoch 68/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5988 - acc: 0.3087 - mean_squared_error: 0.0458\n",
      "Epoch 69/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5934 - acc: 0.3103 - mean_squared_error: 0.0457\n",
      "Epoch 70/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6059 - acc: 0.3067 - mean_squared_error: 0.0459\n",
      "Epoch 71/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5917 - acc: 0.3118 - mean_squared_error: 0.0456\n",
      "Epoch 72/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6058 - acc: 0.3092 - mean_squared_error: 0.0459\n",
      "Epoch 73/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6019 - acc: 0.3082 - mean_squared_error: 0.0458\n",
      "Epoch 74/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6081 - acc: 0.3061 - mean_squared_error: 0.0460\n",
      "Epoch 75/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6203 - acc: 0.3067 - mean_squared_error: 0.0462\n",
      "Epoch 76/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5973 - acc: 0.3094 - mean_squared_error: 0.0457\n",
      "Epoch 77/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5938 - acc: 0.3105 - mean_squared_error: 0.0457\n",
      "Epoch 78/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6060 - acc: 0.3065 - mean_squared_error: 0.0459\n",
      "Epoch 79/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6080 - acc: 0.3102 - mean_squared_error: 0.0460\n",
      "Epoch 80/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6039 - acc: 0.3063 - mean_squared_error: 0.0459\n",
      "Epoch 81/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5978 - acc: 0.3157 - mean_squared_error: 0.0457\n",
      "Epoch 82/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5964 - acc: 0.3101 - mean_squared_error: 0.0458\n",
      "Epoch 83/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6022 - acc: 0.3097 - mean_squared_error: 0.0459\n",
      "Epoch 84/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6176 - acc: 0.3058 - mean_squared_error: 0.0462\n",
      "Epoch 85/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6172 - acc: 0.3071 - mean_squared_error: 0.0461\n",
      "Epoch 86/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6069 - acc: 0.3073 - mean_squared_error: 0.0459\n",
      "Epoch 87/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5943 - acc: 0.3146 - mean_squared_error: 0.0456\n",
      "Epoch 88/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6092 - acc: 0.3115 - mean_squared_error: 0.0458\n",
      "Epoch 89/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6032 - acc: 0.3114 - mean_squared_error: 0.0458\n",
      "Epoch 90/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6018 - acc: 0.3132 - mean_squared_error: 0.0457\n",
      "Epoch 91/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6119 - acc: 0.3106 - mean_squared_error: 0.0459\n",
      "Epoch 92/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5998 - acc: 0.3168 - mean_squared_error: 0.0457\n",
      "Epoch 93/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6092 - acc: 0.3112 - mean_squared_error: 0.0459\n",
      "Epoch 94/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6181 - acc: 0.3088 - mean_squared_error: 0.0460\n",
      "Epoch 95/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5946 - acc: 0.3101 - mean_squared_error: 0.0457\n",
      "Epoch 96/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5856 - acc: 0.3142 - mean_squared_error: 0.0454\n",
      "Epoch 97/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5875 - acc: 0.3112 - mean_squared_error: 0.0456\n",
      "Epoch 98/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5977 - acc: 0.3102 - mean_squared_error: 0.0457\n",
      "Epoch 99/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6050 - acc: 0.3079 - mean_squared_error: 0.0458\n",
      "Epoch 100/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5964 - acc: 0.3120 - mean_squared_error: 0.0456\n",
      "Epoch 101/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6041 - acc: 0.3100 - mean_squared_error: 0.0458\n",
      "Epoch 102/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6315 - acc: 0.3005 - mean_squared_error: 0.0464\n",
      "Epoch 103/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6051 - acc: 0.3096 - mean_squared_error: 0.0459\n",
      "Epoch 104/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6050 - acc: 0.3082 - mean_squared_error: 0.0458\n",
      "Epoch 105/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6019 - acc: 0.3079 - mean_squared_error: 0.0458\n",
      "Epoch 106/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5940 - acc: 0.3116 - mean_squared_error: 0.0456\n",
      "Epoch 107/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6015 - acc: 0.3069 - mean_squared_error: 0.0459\n",
      "Epoch 108/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6048 - acc: 0.3086 - mean_squared_error: 0.0458\n",
      "Epoch 109/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6064 - acc: 0.3110 - mean_squared_error: 0.0459\n",
      "Epoch 110/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5991 - acc: 0.3096 - mean_squared_error: 0.0458\n",
      "Epoch 111/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6060 - acc: 0.3057 - mean_squared_error: 0.0459\n",
      "Epoch 112/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6081 - acc: 0.3092 - mean_squared_error: 0.0457\n",
      "Epoch 113/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6326 - acc: 0.2991 - mean_squared_error: 0.0464\n",
      "Epoch 114/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6068 - acc: 0.3066 - mean_squared_error: 0.0459\n",
      "Epoch 115/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6194 - acc: 0.3074 - mean_squared_error: 0.0462\n",
      "Epoch 116/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6009 - acc: 0.3105 - mean_squared_error: 0.0457\n",
      "Epoch 117/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5952 - acc: 0.3132 - mean_squared_error: 0.0457\n",
      "Epoch 118/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5944 - acc: 0.3124 - mean_squared_error: 0.0455\n",
      "Epoch 119/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6190 - acc: 0.3046 - mean_squared_error: 0.0463\n",
      "Epoch 120/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5891 - acc: 0.3136 - mean_squared_error: 0.0456\n",
      "Epoch 121/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6015 - acc: 0.3101 - mean_squared_error: 0.0458\n",
      "Epoch 122/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5960 - acc: 0.3126 - mean_squared_error: 0.0457\n",
      "Epoch 123/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6116 - acc: 0.3107 - mean_squared_error: 0.0460\n",
      "Epoch 124/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6066 - acc: 0.3053 - mean_squared_error: 0.0460\n",
      "Epoch 125/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6046 - acc: 0.3075 - mean_squared_error: 0.0458\n",
      "Epoch 126/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.6111 - acc: 0.3038 - mean_squared_error: 0.0460\n",
      "Epoch 127/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5924 - acc: 0.3119 - mean_squared_error: 0.0455\n",
      "Epoch 128/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5914 - acc: 0.3156 - mean_squared_error: 0.0455\n",
      "Epoch 129/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5958 - acc: 0.3165 - mean_squared_error: 0.0455\n",
      "Epoch 130/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5896 - acc: 0.3164 - mean_squared_error: 0.0455\n",
      "Epoch 131/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6005 - acc: 0.3137 - mean_squared_error: 0.0457\n",
      "Epoch 132/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6075 - acc: 0.3112 - mean_squared_error: 0.0459\n",
      "Epoch 133/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5867 - acc: 0.3195 - mean_squared_error: 0.0453\n",
      "Epoch 134/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5879 - acc: 0.3186 - mean_squared_error: 0.0454\n",
      "Epoch 135/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5975 - acc: 0.3133 - mean_squared_error: 0.0457\n",
      "Epoch 136/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6061 - acc: 0.3085 - mean_squared_error: 0.0459\n",
      "Epoch 137/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6200 - acc: 0.3023 - mean_squared_error: 0.0462\n",
      "Epoch 138/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6002 - acc: 0.3111 - mean_squared_error: 0.0457\n",
      "Epoch 139/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6129 - acc: 0.3052 - mean_squared_error: 0.0461\n",
      "Epoch 140/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5961 - acc: 0.3148 - mean_squared_error: 0.0456\n",
      "Epoch 141/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5911 - acc: 0.3135 - mean_squared_error: 0.0455\n",
      "Epoch 142/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.5950 - acc: 0.3151 - mean_squared_error: 0.0456\n",
      "Epoch 143/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5829 - acc: 0.3187 - mean_squared_error: 0.0454\n",
      "Epoch 144/200\n",
      "75000/75000 [==============================] - 1s 7us/step - loss: 1.6050 - acc: 0.3088 - mean_squared_error: 0.0459\n",
      "Epoch 145/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6044 - acc: 0.3111 - mean_squared_error: 0.0458\n",
      "Epoch 146/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6050 - acc: 0.3084 - mean_squared_error: 0.0459\n",
      "Epoch 147/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6303 - acc: 0.2990 - mean_squared_error: 0.0464\n",
      "Epoch 148/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5974 - acc: 0.3098 - mean_squared_error: 0.0457\n",
      "Epoch 149/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5885 - acc: 0.3160 - mean_squared_error: 0.0455\n",
      "Epoch 150/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.6099 - acc: 0.3078 - mean_squared_error: 0.0460\n",
      "Epoch 151/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5996 - acc: 0.3114 - mean_squared_error: 0.0457\n",
      "Epoch 152/200\n",
      "75000/75000 [==============================] - 1s 8us/step - loss: 1.5956 - acc: 0.3087 - mean_squared_error: 0.0457\n",
      "Epoch 153/200\n",
      "75000/75000 [==============================] - 1s 10us/step - loss: 1.6152 - acc: 0.3004 - mean_squared_error: 0.0461\n",
      "Epoch 154/200\n",
      "75000/75000 [==============================] - 1s 9us/step - loss: 1.5915 - acc: 0.3134 - mean_squared_error: 0.0455\n",
      "Epoch 155/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5813 - acc: 0.3165 - mean_squared_error: 0.0453\n",
      "Epoch 156/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5996 - acc: 0.3094 - mean_squared_error: 0.0458\n",
      "Epoch 157/200\n",
      "75000/75000 [==============================] - 1s 10us/step - loss: 1.6070 - acc: 0.3093 - mean_squared_error: 0.0460\n",
      "Epoch 158/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5850 - acc: 0.3213 - mean_squared_error: 0.0453\n",
      "Epoch 159/200\n",
      "75000/75000 [==============================] - 1s 17us/step - loss: 1.6124 - acc: 0.3093 - mean_squared_error: 0.0460\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.6103 - acc: 0.3102 - mean_squared_error: 0.0459\n",
      "Epoch 161/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5865 - acc: 0.3134 - mean_squared_error: 0.0454\n",
      "Epoch 162/200\n",
      "75000/75000 [==============================] - 1s 10us/step - loss: 1.5958 - acc: 0.3125 - mean_squared_error: 0.0456\n",
      "Epoch 163/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5996 - acc: 0.3084 - mean_squared_error: 0.0458\n",
      "Epoch 164/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5959 - acc: 0.3122 - mean_squared_error: 0.0456\n",
      "Epoch 165/200\n",
      "75000/75000 [==============================] - 1s 14us/step - loss: 1.5908 - acc: 0.3133 - mean_squared_error: 0.0456\n",
      "Epoch 166/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.6083 - acc: 0.3094 - mean_squared_error: 0.0459\n",
      "Epoch 167/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.6219 - acc: 0.3053 - mean_squared_error: 0.0462\n",
      "Epoch 168/200\n",
      "75000/75000 [==============================] - 1s 16us/step - loss: 1.5963 - acc: 0.3094 - mean_squared_error: 0.0457\n",
      "Epoch 169/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5859 - acc: 0.3156 - mean_squared_error: 0.0455\n",
      "Epoch 170/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5931 - acc: 0.3139 - mean_squared_error: 0.0455\n",
      "Epoch 171/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5971 - acc: 0.3127 - mean_squared_error: 0.0457\n",
      "Epoch 172/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5893 - acc: 0.3152 - mean_squared_error: 0.0454\n",
      "Epoch 173/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5923 - acc: 0.3162 - mean_squared_error: 0.0455\n",
      "Epoch 174/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5966 - acc: 0.3128 - mean_squared_error: 0.0457\n",
      "Epoch 175/200\n",
      "75000/75000 [==============================] - 1s 14us/step - loss: 1.5874 - acc: 0.3129 - mean_squared_error: 0.0454\n",
      "Epoch 176/200\n",
      "75000/75000 [==============================] - 1s 14us/step - loss: 1.5930 - acc: 0.3154 - mean_squared_error: 0.0456\n",
      "Epoch 177/200\n",
      "75000/75000 [==============================] - 1s 18us/step - loss: 1.5935 - acc: 0.3110 - mean_squared_error: 0.0456\n",
      "Epoch 178/200\n",
      "75000/75000 [==============================] - 1s 19us/step - loss: 1.6005 - acc: 0.3113 - mean_squared_error: 0.0458\n",
      "Epoch 179/200\n",
      "75000/75000 [==============================] - 2s 24us/step - loss: 1.5875 - acc: 0.3173 - mean_squared_error: 0.0455\n",
      "Epoch 180/200\n",
      "75000/75000 [==============================] - 1s 13us/step - loss: 1.5921 - acc: 0.3153 - mean_squared_error: 0.0455\n",
      "Epoch 181/200\n",
      "75000/75000 [==============================] - 1s 13us/step - loss: 1.5883 - acc: 0.3165 - mean_squared_error: 0.0455\n",
      "Epoch 182/200\n",
      "75000/75000 [==============================] - 1s 14us/step - loss: 1.6091 - acc: 0.3083 - mean_squared_error: 0.0459\n",
      "Epoch 183/200\n",
      "75000/75000 [==============================] - 1s 15us/step - loss: 1.6040 - acc: 0.3118 - mean_squared_error: 0.0459\n",
      "Epoch 184/200\n",
      "75000/75000 [==============================] - 1s 15us/step - loss: 1.5864 - acc: 0.3146 - mean_squared_error: 0.0455\n",
      "Epoch 185/200\n",
      "75000/75000 [==============================] - 2s 23us/step - loss: 1.5882 - acc: 0.3161 - mean_squared_error: 0.0455\n",
      "Epoch 186/200\n",
      "75000/75000 [==============================] - 1s 19us/step - loss: 1.5972 - acc: 0.3085 - mean_squared_error: 0.0457\n",
      "Epoch 187/200\n",
      "75000/75000 [==============================] - 3s 37us/step - loss: 1.5982 - acc: 0.3114 - mean_squared_error: 0.0457\n",
      "Epoch 188/200\n",
      "75000/75000 [==============================] - 1s 17us/step - loss: 1.6028 - acc: 0.3086 - mean_squared_error: 0.0458\n",
      "Epoch 189/200\n",
      "75000/75000 [==============================] - 1s 19us/step - loss: 1.6119 - acc: 0.3020 - mean_squared_error: 0.0461\n",
      "Epoch 190/200\n",
      "75000/75000 [==============================] - 1s 11us/step - loss: 1.5996 - acc: 0.3087 - mean_squared_error: 0.0459\n",
      "Epoch 191/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.6251 - acc: 0.3003 - mean_squared_error: 0.0464\n",
      "Epoch 192/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.6044 - acc: 0.3079 - mean_squared_error: 0.0460\n",
      "Epoch 193/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5944 - acc: 0.3152 - mean_squared_error: 0.0456\n",
      "Epoch 194/200\n",
      "75000/75000 [==============================] - 1s 13us/step - loss: 1.5965 - acc: 0.3104 - mean_squared_error: 0.0457\n",
      "Epoch 195/200\n",
      "75000/75000 [==============================] - 1s 13us/step - loss: 1.5980 - acc: 0.3140 - mean_squared_error: 0.0457\n",
      "Epoch 196/200\n",
      "75000/75000 [==============================] - 1s 13us/step - loss: 1.6010 - acc: 0.3074 - mean_squared_error: 0.0459\n",
      "Epoch 197/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5898 - acc: 0.3116 - mean_squared_error: 0.0456\n",
      "Epoch 198/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5876 - acc: 0.3127 - mean_squared_error: 0.0455\n",
      "Epoch 199/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.5971 - acc: 0.3075 - mean_squared_error: 0.0458\n",
      "Epoch 200/200\n",
      "75000/75000 [==============================] - 1s 12us/step - loss: 1.6058 - acc: 0.3107 - mean_squared_error: 0.0458\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.625101]\n",
      "Es/No: 12 SER: 0.6949066666666667 Theor_SER_PAM: 0.5075803579279314\n",
      "(60000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           272         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 2)            34          dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2)            4           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 2)            0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 2)            0           lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 1)            0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 2)            0           lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 1)            0           lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3)            0           lambda_8[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 4)            16          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 8)            40          dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16)           144         dense_15[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 510\n",
      "Trainable params: 506\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 2.0124 - acc: 0.2360 - mean_squared_error: 0.0510\n",
      "Epoch 2/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.5719 - acc: 0.3208 - mean_squared_error: 0.0455\n",
      "Epoch 3/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.5310 - acc: 0.3253 - mean_squared_error: 0.0450\n",
      "Epoch 4/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.5010 - acc: 0.3281 - mean_squared_error: 0.0444\n",
      "Epoch 5/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4998 - acc: 0.3257 - mean_squared_error: 0.0445\n",
      "Epoch 6/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.5190 - acc: 0.3185 - mean_squared_error: 0.0449\n",
      "Epoch 7/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4840 - acc: 0.3298 - mean_squared_error: 0.0442\n",
      "Epoch 8/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4703 - acc: 0.3363 - mean_squared_error: 0.0439\n",
      "Epoch 9/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4579 - acc: 0.3440 - mean_squared_error: 0.0436\n",
      "Epoch 10/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4831 - acc: 0.3358 - mean_squared_error: 0.0443\n",
      "Epoch 11/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4589 - acc: 0.3430 - mean_squared_error: 0.0435\n",
      "Epoch 12/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4476 - acc: 0.3531 - mean_squared_error: 0.0432\n",
      "Epoch 13/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4667 - acc: 0.3419 - mean_squared_error: 0.0436\n",
      "Epoch 14/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4552 - acc: 0.3455 - mean_squared_error: 0.0434\n",
      "Epoch 15/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4585 - acc: 0.3543 - mean_squared_error: 0.0432\n",
      "Epoch 16/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4318 - acc: 0.3654 - mean_squared_error: 0.0426\n",
      "Epoch 17/200\n",
      "60000/60000 [==============================] - 1s 22us/step - loss: 1.4442 - acc: 0.3659 - mean_squared_error: 0.0429\n",
      "Epoch 18/200\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 1.4446 - acc: 0.3693 - mean_squared_error: 0.04 - 1s 14us/step - loss: 1.4458 - acc: 0.3690 - mean_squared_error: 0.0429\n",
      "Epoch 19/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4583 - acc: 0.3568 - mean_squared_error: 0.0434\n",
      "Epoch 20/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4358 - acc: 0.3747 - mean_squared_error: 0.0425\n",
      "Epoch 21/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4445 - acc: 0.3676 - mean_squared_error: 0.0429\n",
      "Epoch 22/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4281 - acc: 0.3773 - mean_squared_error: 0.0423\n",
      "Epoch 23/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4416 - acc: 0.3698 - mean_squared_error: 0.0427\n",
      "Epoch 24/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4484 - acc: 0.3651 - mean_squared_error: 0.0431\n",
      "Epoch 25/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4714 - acc: 0.3558 - mean_squared_error: 0.0436\n",
      "Epoch 26/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4615 - acc: 0.3575 - mean_squared_error: 0.0432\n",
      "Epoch 27/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4387 - acc: 0.3728 - mean_squared_error: 0.0425\n",
      "Epoch 28/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4256 - acc: 0.3750 - mean_squared_error: 0.0422\n",
      "Epoch 29/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4229 - acc: 0.3818 - mean_squared_error: 0.0421\n",
      "Epoch 30/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4403 - acc: 0.3697 - mean_squared_error: 0.0426\n",
      "Epoch 31/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4348 - acc: 0.3734 - mean_squared_error: 0.0425\n",
      "Epoch 32/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4397 - acc: 0.3728 - mean_squared_error: 0.0426\n",
      "Epoch 33/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4297 - acc: 0.3770 - mean_squared_error: 0.0422\n",
      "Epoch 34/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4231 - acc: 0.3791 - mean_squared_error: 0.0421\n",
      "Epoch 35/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4657 - acc: 0.3601 - mean_squared_error: 0.0434\n",
      "Epoch 36/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4398 - acc: 0.3697 - mean_squared_error: 0.0426\n",
      "Epoch 37/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4376 - acc: 0.3703 - mean_squared_error: 0.0425\n",
      "Epoch 38/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4442 - acc: 0.3704 - mean_squared_error: 0.0427\n",
      "Epoch 39/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4273 - acc: 0.3755 - mean_squared_error: 0.0422\n",
      "Epoch 40/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4394 - acc: 0.3690 - mean_squared_error: 0.0427\n",
      "Epoch 41/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4484 - acc: 0.3673 - mean_squared_error: 0.0428\n",
      "Epoch 42/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4470 - acc: 0.3697 - mean_squared_error: 0.0426\n",
      "Epoch 43/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4260 - acc: 0.3755 - mean_squared_error: 0.0423\n",
      "Epoch 44/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4296 - acc: 0.3743 - mean_squared_error: 0.0423\n",
      "Epoch 45/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4229 - acc: 0.3780 - mean_squared_error: 0.0420\n",
      "Epoch 46/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4381 - acc: 0.3724 - mean_squared_error: 0.0425\n",
      "Epoch 47/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4360 - acc: 0.3704 - mean_squared_error: 0.0425\n",
      "Epoch 48/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4279 - acc: 0.3755 - mean_squared_error: 0.0423\n",
      "Epoch 49/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4454 - acc: 0.3735 - mean_squared_error: 0.0426\n",
      "Epoch 50/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4353 - acc: 0.3737 - mean_squared_error: 0.0424\n",
      "Epoch 51/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4765 - acc: 0.3591 - mean_squared_error: 0.0434\n",
      "Epoch 52/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4463 - acc: 0.3691 - mean_squared_error: 0.0428\n",
      "Epoch 53/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4423 - acc: 0.3720 - mean_squared_error: 0.0426\n",
      "Epoch 54/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4547 - acc: 0.3682 - mean_squared_error: 0.0429\n",
      "Epoch 55/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4359 - acc: 0.3731 - mean_squared_error: 0.0423\n",
      "Epoch 56/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4784 - acc: 0.3587 - mean_squared_error: 0.0434\n",
      "Epoch 57/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4361 - acc: 0.3764 - mean_squared_error: 0.0423\n",
      "Epoch 58/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4490 - acc: 0.3681 - mean_squared_error: 0.0428\n",
      "Epoch 59/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4272 - acc: 0.3761 - mean_squared_error: 0.0422\n",
      "Epoch 60/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4513 - acc: 0.3660 - mean_squared_error: 0.0429\n",
      "Epoch 61/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4122 - acc: 0.3828 - mean_squared_error: 0.0418\n",
      "Epoch 62/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4271 - acc: 0.3779 - mean_squared_error: 0.0422\n",
      "Epoch 63/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4624 - acc: 0.3627 - mean_squared_error: 0.0432\n",
      "Epoch 64/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4494 - acc: 0.3674 - mean_squared_error: 0.0427\n",
      "Epoch 65/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4133 - acc: 0.3845 - mean_squared_error: 0.0417\n",
      "Epoch 66/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4269 - acc: 0.3763 - mean_squared_error: 0.0423\n",
      "Epoch 67/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4298 - acc: 0.3758 - mean_squared_error: 0.0423\n",
      "Epoch 68/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4268 - acc: 0.3753 - mean_squared_error: 0.0421\n",
      "Epoch 69/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4387 - acc: 0.3718 - mean_squared_error: 0.0425\n",
      "Epoch 70/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4160 - acc: 0.3790 - mean_squared_error: 0.0419\n",
      "Epoch 71/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4450 - acc: 0.3692 - mean_squared_error: 0.0427\n",
      "Epoch 72/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4368 - acc: 0.3705 - mean_squared_error: 0.0425\n",
      "Epoch 73/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4288 - acc: 0.3783 - mean_squared_error: 0.0422\n",
      "Epoch 74/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4299 - acc: 0.3734 - mean_squared_error: 0.0423\n",
      "Epoch 75/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4433 - acc: 0.3720 - mean_squared_error: 0.0426\n",
      "Epoch 76/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4482 - acc: 0.3672 - mean_squared_error: 0.0428\n",
      "Epoch 77/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4140 - acc: 0.3839 - mean_squared_error: 0.0417\n",
      "Epoch 78/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4963 - acc: 0.3569 - mean_squared_error: 0.0437\n",
      "Epoch 79/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4306 - acc: 0.3740 - mean_squared_error: 0.0422\n",
      "Epoch 80/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4387 - acc: 0.3676 - mean_squared_error: 0.0425\n",
      "Epoch 81/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4218 - acc: 0.3782 - mean_squared_error: 0.0419\n",
      "Epoch 82/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4491 - acc: 0.3673 - mean_squared_error: 0.0428\n",
      "Epoch 83/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4429 - acc: 0.3720 - mean_squared_error: 0.0427\n",
      "Epoch 84/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4373 - acc: 0.3732 - mean_squared_error: 0.0424\n",
      "Epoch 85/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4299 - acc: 0.3765 - mean_squared_error: 0.0422\n",
      "Epoch 86/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4262 - acc: 0.3759 - mean_squared_error: 0.0422\n",
      "Epoch 87/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4614 - acc: 0.3649 - mean_squared_error: 0.0431\n",
      "Epoch 88/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4337 - acc: 0.3751 - mean_squared_error: 0.0422\n",
      "Epoch 89/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4374 - acc: 0.3701 - mean_squared_error: 0.0424\n",
      "Epoch 90/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4438 - acc: 0.3666 - mean_squared_error: 0.0426\n",
      "Epoch 91/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4554 - acc: 0.3687 - mean_squared_error: 0.0427\n",
      "Epoch 92/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4292 - acc: 0.3749 - mean_squared_error: 0.0422\n",
      "Epoch 93/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4468 - acc: 0.3708 - mean_squared_error: 0.0427\n",
      "Epoch 94/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.5032 - acc: 0.3499 - mean_squared_error: 0.0439\n",
      "Epoch 95/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4319 - acc: 0.3721 - mean_squared_error: 0.0422\n",
      "Epoch 96/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4417 - acc: 0.3700 - mean_squared_error: 0.0425\n",
      "Epoch 97/200\n",
      "60000/60000 [==============================] - 1s 24us/step - loss: 1.4417 - acc: 0.3677 - mean_squared_error: 0.0426\n",
      "Epoch 98/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4493 - acc: 0.3662 - mean_squared_error: 0.0428\n",
      "Epoch 99/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4262 - acc: 0.3776 - mean_squared_error: 0.0420\n",
      "Epoch 100/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4179 - acc: 0.3763 - mean_squared_error: 0.0420\n",
      "Epoch 101/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4238 - acc: 0.3752 - mean_squared_error: 0.0421\n",
      "Epoch 102/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4185 - acc: 0.3781 - mean_squared_error: 0.0419\n",
      "Epoch 103/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4395 - acc: 0.3708 - mean_squared_error: 0.0425\n",
      "Epoch 104/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4266 - acc: 0.3764 - mean_squared_error: 0.0420\n",
      "Epoch 105/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4571 - acc: 0.3635 - mean_squared_error: 0.0429\n",
      "Epoch 106/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4202 - acc: 0.3744 - mean_squared_error: 0.0420\n",
      "Epoch 107/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4179 - acc: 0.3769 - mean_squared_error: 0.0420\n",
      "Epoch 108/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4370 - acc: 0.3701 - mean_squared_error: 0.0424\n",
      "Epoch 109/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4317 - acc: 0.3705 - mean_squared_error: 0.0423\n",
      "Epoch 110/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4445 - acc: 0.3668 - mean_squared_error: 0.0426\n",
      "Epoch 111/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4117 - acc: 0.3753 - mean_squared_error: 0.0418\n",
      "Epoch 112/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4510 - acc: 0.3648 - mean_squared_error: 0.0428\n",
      "Epoch 113/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4414 - acc: 0.3680 - mean_squared_error: 0.0426\n",
      "Epoch 114/200\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 1.4367 - acc: 0.3680 - mean_squared_error: 0.0423\n",
      "Epoch 115/200\n",
      "60000/60000 [==============================] - 1s 23us/step - loss: 1.4348 - acc: 0.3681 - mean_squared_error: 0.0423\n",
      "Epoch 116/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4273 - acc: 0.3716 - mean_squared_error: 0.0421\n",
      "Epoch 117/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4259 - acc: 0.3698 - mean_squared_error: 0.0422\n",
      "Epoch 118/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4318 - acc: 0.3669 - mean_squared_error: 0.0423\n",
      "Epoch 119/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4370 - acc: 0.3703 - mean_squared_error: 0.0425\n",
      "Epoch 120/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4245 - acc: 0.3732 - mean_squared_error: 0.0420\n",
      "Epoch 121/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4393 - acc: 0.3662 - mean_squared_error: 0.0425\n",
      "Epoch 122/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4388 - acc: 0.3678 - mean_squared_error: 0.0424\n",
      "Epoch 123/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4287 - acc: 0.3734 - mean_squared_error: 0.0421\n",
      "Epoch 124/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4528 - acc: 0.3627 - mean_squared_error: 0.0428\n",
      "Epoch 125/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4572 - acc: 0.3637 - mean_squared_error: 0.0428\n",
      "Epoch 126/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4476 - acc: 0.3686 - mean_squared_error: 0.0426\n",
      "Epoch 127/200\n",
      "60000/60000 [==============================] - 1s 20us/step - loss: 1.4579 - acc: 0.3593 - mean_squared_error: 0.0429\n",
      "Epoch 128/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4350 - acc: 0.3692 - mean_squared_error: 0.0422\n",
      "Epoch 129/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4649 - acc: 0.3536 - mean_squared_error: 0.0432\n",
      "Epoch 130/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4355 - acc: 0.3663 - mean_squared_error: 0.0424\n",
      "Epoch 131/200\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 1.4514 - acc: 0.3633 - mean_squared_error: 0.0429\n",
      "Epoch 132/200\n",
      "60000/60000 [==============================] - 1s 18us/step - loss: 1.4154 - acc: 0.3758 - mean_squared_error: 0.0418\n",
      "Epoch 133/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4203 - acc: 0.3757 - mean_squared_error: 0.0419\n",
      "Epoch 134/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4350 - acc: 0.3714 - mean_squared_error: 0.0423\n",
      "Epoch 135/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4249 - acc: 0.3743 - mean_squared_error: 0.0420\n",
      "Epoch 136/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4287 - acc: 0.3739 - mean_squared_error: 0.0422\n",
      "Epoch 137/200\n",
      "60000/60000 [==============================] - 1s 25us/step - loss: 1.4195 - acc: 0.3767 - mean_squared_error: 0.0419\n",
      "Epoch 138/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4418 - acc: 0.3692 - mean_squared_error: 0.0425\n",
      "Epoch 139/200\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 1.4351 - acc: 0.3734 - mean_squared_error: 0.0424\n",
      "Epoch 140/200\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 1.4229 - acc: 0.3754 - mean_squared_error: 0.0418\n",
      "Epoch 141/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4338 - acc: 0.3679 - mean_squared_error: 0.0424\n",
      "Epoch 142/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4366 - acc: 0.3688 - mean_squared_error: 0.0423\n",
      "Epoch 143/200\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 1.4300 - acc: 0.3696 - mean_squared_error: 0.0423\n",
      "Epoch 144/200\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 1.4343 - acc: 0.3727 - mean_squared_error: 0.0423\n",
      "Epoch 145/200\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 1.4176 - acc: 0.3779 - mean_squared_error: 0.0420\n",
      "Epoch 146/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4282 - acc: 0.3712 - mean_squared_error: 0.0422\n",
      "Epoch 147/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4233 - acc: 0.3767 - mean_squared_error: 0.0421\n",
      "Epoch 148/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4449 - acc: 0.3666 - mean_squared_error: 0.0425\n",
      "Epoch 149/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4318 - acc: 0.3741 - mean_squared_error: 0.0422\n",
      "Epoch 150/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4427 - acc: 0.3733 - mean_squared_error: 0.0425\n",
      "Epoch 151/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4747 - acc: 0.3562 - mean_squared_error: 0.0434\n",
      "Epoch 152/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4271 - acc: 0.3741 - mean_squared_error: 0.0421\n",
      "Epoch 153/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4208 - acc: 0.3798 - mean_squared_error: 0.0419\n",
      "Epoch 154/200\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 1.4382 - acc: 0.3699 - mean_squared_error: 0.0424\n",
      "Epoch 155/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4318 - acc: 0.3734 - mean_squared_error: 0.0423\n",
      "Epoch 156/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4244 - acc: 0.3760 - mean_squared_error: 0.0420\n",
      "Epoch 157/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4408 - acc: 0.3705 - mean_squared_error: 0.0425\n",
      "Epoch 158/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4396 - acc: 0.3715 - mean_squared_error: 0.0424\n",
      "Epoch 159/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4316 - acc: 0.3725 - mean_squared_error: 0.0422\n",
      "Epoch 160/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4341 - acc: 0.3729 - mean_squared_error: 0.0423\n",
      "Epoch 161/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4348 - acc: 0.3720 - mean_squared_error: 0.0423\n",
      "Epoch 162/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4247 - acc: 0.3751 - mean_squared_error: 0.0421\n",
      "Epoch 163/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4210 - acc: 0.3751 - mean_squared_error: 0.0420\n",
      "Epoch 164/200\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 1.4306 - acc: 0.3721 - mean_squared_error: 0.0423\n",
      "Epoch 165/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4600 - acc: 0.3599 - mean_squared_error: 0.0432\n",
      "Epoch 166/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4833 - acc: 0.3549 - mean_squared_error: 0.0435\n",
      "Epoch 167/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4298 - acc: 0.3706 - mean_squared_error: 0.0422\n",
      "Epoch 168/200\n",
      "60000/60000 [==============================] - 1s 11us/step - loss: 1.4373 - acc: 0.3704 - mean_squared_error: 0.0425\n",
      "Epoch 169/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4143 - acc: 0.3796 - mean_squared_error: 0.0417\n",
      "Epoch 170/200\n",
      "60000/60000 [==============================] - 0s 8us/step - loss: 1.4155 - acc: 0.3808 - mean_squared_error: 0.0418\n",
      "Epoch 171/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4600 - acc: 0.3609 - mean_squared_error: 0.0431\n",
      "Epoch 172/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4520 - acc: 0.3630 - mean_squared_error: 0.0428\n",
      "Epoch 173/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4360 - acc: 0.3686 - mean_squared_error: 0.0424\n",
      "Epoch 174/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4238 - acc: 0.3752 - mean_squared_error: 0.0420\n",
      "Epoch 175/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4562 - acc: 0.3643 - mean_squared_error: 0.0429\n",
      "Epoch 176/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4329 - acc: 0.3706 - mean_squared_error: 0.0423\n",
      "Epoch 177/200\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 1.4379 - acc: 0.3701 - mean_squared_error: 0.0424\n",
      "Epoch 178/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4171 - acc: 0.3780 - mean_squared_error: 0.0419\n",
      "Epoch 179/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4166 - acc: 0.3765 - mean_squared_error: 0.0419\n",
      "Epoch 180/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4572 - acc: 0.3626 - mean_squared_error: 0.0430\n",
      "Epoch 181/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4459 - acc: 0.3634 - mean_squared_error: 0.0426\n",
      "Epoch 182/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4319 - acc: 0.3722 - mean_squared_error: 0.0423\n",
      "Epoch 183/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4500 - acc: 0.3640 - mean_squared_error: 0.0427\n",
      "Epoch 184/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4370 - acc: 0.3682 - mean_squared_error: 0.0424\n",
      "Epoch 185/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4340 - acc: 0.3734 - mean_squared_error: 0.0423\n",
      "Epoch 186/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4288 - acc: 0.3728 - mean_squared_error: 0.0423\n",
      "Epoch 187/200\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 1.4410 - acc: 0.3702 - mean_squared_error: 0.0425\n",
      "Epoch 188/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4283 - acc: 0.3769 - mean_squared_error: 0.0421\n",
      "Epoch 189/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4303 - acc: 0.3722 - mean_squared_error: 0.0423\n",
      "Epoch 190/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4209 - acc: 0.3773 - mean_squared_error: 0.0420\n",
      "Epoch 191/200\n",
      "60000/60000 [==============================] - 0s 6us/step - loss: 1.4771 - acc: 0.3589 - mean_squared_error: 0.0434\n",
      "Epoch 192/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4322 - acc: 0.3699 - mean_squared_error: 0.0423\n",
      "Epoch 193/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4433 - acc: 0.3687 - mean_squared_error: 0.0426\n",
      "Epoch 194/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4113 - acc: 0.3820 - mean_squared_error: 0.0417\n",
      "Epoch 195/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4500 - acc: 0.3724 - mean_squared_error: 0.0426\n",
      "Epoch 196/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4691 - acc: 0.3610 - mean_squared_error: 0.0432\n",
      "Epoch 197/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4859 - acc: 0.3528 - mean_squared_error: 0.0436\n",
      "Epoch 198/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4353 - acc: 0.3657 - mean_squared_error: 0.0421\n",
      "Epoch 199/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4439 - acc: 0.3628 - mean_squared_error: 0.0425\n",
      "Epoch 200/200\n",
      "60000/60000 [==============================] - 0s 7us/step - loss: 1.4389 - acc: 0.3621 - mean_squared_error: 0.0425\n",
      "(16, 1, 2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27.776924]\n",
      "Es/No: 14 SER: 0.6552166666666667 Theor_SER_PAM: 0.4143940207176103\n",
      "(65000, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16)           272         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            34          dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 2)            4           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 2)            0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 2)            0           lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 1)            0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 2)            0           lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 1)            0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 3)            0           lambda_13[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 4)            16          concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 8)            40          dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 16)           144         dense_23[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 510\n",
      "Trainable params: 506\n",
      "Non-trainable params: 4\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "65000/65000 [==============================] - 3s 54us/step - loss: 3.2168 - acc: 0.0651 - mean_squared_error: 0.0606\n",
      "Epoch 2/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.6344 - acc: 0.0902 - mean_squared_error: 0.0571\n",
      "Epoch 3/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.3515 - acc: 0.1328 - mean_squared_error: 0.0549\n",
      "Epoch 4/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.2978 - acc: 0.1349 - mean_squared_error: 0.0546\n",
      "Epoch 5/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.2718 - acc: 0.1636 - mean_squared_error: 0.0533\n",
      "Epoch 6/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.1729 - acc: 0.1820 - mean_squared_error: 0.0523\n",
      "Epoch 7/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.0458 - acc: 0.1835 - mean_squared_error: 0.0519\n",
      "Epoch 8/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.0296 - acc: 0.1807 - mean_squared_error: 0.0518\n",
      "Epoch 9/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 2.0180 - acc: 0.1861 - mean_squared_error: 0.0516\n",
      "Epoch 10/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 2.0079 - acc: 0.1943 - mean_squared_error: 0.0514\n",
      "Epoch 11/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.9901 - acc: 0.2097 - mean_squared_error: 0.0511\n",
      "Epoch 12/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.9294 - acc: 0.2146 - mean_squared_error: 0.0509\n",
      "Epoch 13/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.9272 - acc: 0.2172 - mean_squared_error: 0.0508\n",
      "Epoch 14/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.9198 - acc: 0.2178 - mean_squared_error: 0.0507\n",
      "Epoch 15/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8970 - acc: 0.2279 - mean_squared_error: 0.0501\n",
      "Epoch 16/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.9087 - acc: 0.2198 - mean_squared_error: 0.0505\n",
      "Epoch 17/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8997 - acc: 0.2217 - mean_squared_error: 0.0503\n",
      "Epoch 18/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8903 - acc: 0.2254 - mean_squared_error: 0.0501\n",
      "Epoch 19/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8997 - acc: 0.2196 - mean_squared_error: 0.0504\n",
      "Epoch 20/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8838 - acc: 0.2252 - mean_squared_error: 0.0500\n",
      "Epoch 21/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8801 - acc: 0.2259 - mean_squared_error: 0.0499\n",
      "Epoch 22/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8918 - acc: 0.2211 - mean_squared_error: 0.0502\n",
      "Epoch 23/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8785 - acc: 0.2273 - mean_squared_error: 0.0499\n",
      "Epoch 24/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8736 - acc: 0.2271 - mean_squared_error: 0.0498\n",
      "Epoch 25/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8759 - acc: 0.2260 - mean_squared_error: 0.0498\n",
      "Epoch 26/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8749 - acc: 0.2212 - mean_squared_error: 0.0499\n",
      "Epoch 27/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8694 - acc: 0.2276 - mean_squared_error: 0.0496\n",
      "Epoch 28/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.8659 - acc: 0.2279 - mean_squared_error: 0.0496\n",
      "Epoch 29/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.8746 - acc: 0.2223 - mean_squared_error: 0.0499\n",
      "Epoch 30/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8619 - acc: 0.2261 - mean_squared_error: 0.0495\n",
      "Epoch 31/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8611 - acc: 0.2287 - mean_squared_error: 0.0496\n",
      "Epoch 32/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8566 - acc: 0.2285 - mean_squared_error: 0.0494\n",
      "Epoch 33/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.8674 - acc: 0.2242 - mean_squared_error: 0.0497\n",
      "Epoch 34/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.8615 - acc: 0.2276 - mean_squared_error: 0.0496\n",
      "Epoch 35/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.8678 - acc: 0.2269 - mean_squared_error: 0.0497\n",
      "Epoch 36/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.8555 - acc: 0.2317 - mean_squared_error: 0.0494\n",
      "Epoch 37/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.8003 - acc: 0.2356 - mean_squared_error: 0.0493\n",
      "Epoch 38/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7759 - acc: 0.2350 - mean_squared_error: 0.0491\n",
      "Epoch 39/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7709 - acc: 0.2397 - mean_squared_error: 0.0491\n",
      "Epoch 40/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7990 - acc: 0.2301 - mean_squared_error: 0.0497\n",
      "Epoch 41/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7834 - acc: 0.2344 - mean_squared_error: 0.0494\n",
      "Epoch 42/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7823 - acc: 0.2332 - mean_squared_error: 0.0494\n",
      "Epoch 43/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7870 - acc: 0.2301 - mean_squared_error: 0.0495\n",
      "Epoch 44/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7670 - acc: 0.2371 - mean_squared_error: 0.0491\n",
      "Epoch 45/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7840 - acc: 0.2336 - mean_squared_error: 0.0494\n",
      "Epoch 46/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7786 - acc: 0.2385 - mean_squared_error: 0.0492\n",
      "Epoch 47/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7875 - acc: 0.2407 - mean_squared_error: 0.0494\n",
      "Epoch 48/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7794 - acc: 0.2392 - mean_squared_error: 0.0492\n",
      "Epoch 49/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7664 - acc: 0.2447 - mean_squared_error: 0.0489\n",
      "Epoch 50/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7593 - acc: 0.2475 - mean_squared_error: 0.0487\n",
      "Epoch 51/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7657 - acc: 0.2488 - mean_squared_error: 0.0489\n",
      "Epoch 52/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7736 - acc: 0.2453 - mean_squared_error: 0.0491\n",
      "Epoch 53/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7678 - acc: 0.2465 - mean_squared_error: 0.0490\n",
      "Epoch 54/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7595 - acc: 0.2474 - mean_squared_error: 0.0488\n",
      "Epoch 55/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7639 - acc: 0.2426 - mean_squared_error: 0.0489\n",
      "Epoch 56/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7817 - acc: 0.2391 - mean_squared_error: 0.0493\n",
      "Epoch 57/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7861 - acc: 0.2378 - mean_squared_error: 0.0493\n",
      "Epoch 58/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7851 - acc: 0.2388 - mean_squared_error: 0.0494\n",
      "Epoch 59/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7655 - acc: 0.2475 - mean_squared_error: 0.0488\n",
      "Epoch 60/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7571 - acc: 0.2467 - mean_squared_error: 0.0488\n",
      "Epoch 61/200\n",
      "65000/65000 [==============================] - 0s 5us/step - loss: 1.7652 - acc: 0.2423 - mean_squared_error: 0.0489\n",
      "Epoch 62/200\n",
      "65000/65000 [==============================] - 0s 8us/step - loss: 1.7581 - acc: 0.2458 - mean_squared_error: 0.0488\n",
      "Epoch 63/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7462 - acc: 0.2520 - mean_squared_error: 0.0485\n",
      "Epoch 64/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7519 - acc: 0.2516 - mean_squared_error: 0.0486\n",
      "Epoch 65/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7662 - acc: 0.2447 - mean_squared_error: 0.0490\n",
      "Epoch 66/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7506 - acc: 0.2488 - mean_squared_error: 0.0486\n",
      "Epoch 67/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7026 - acc: 0.2556 - mean_squared_error: 0.0486\n",
      "Epoch 68/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6903 - acc: 0.2558 - mean_squared_error: 0.0486\n",
      "Epoch 69/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6926 - acc: 0.2553 - mean_squared_error: 0.0486\n",
      "Epoch 70/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6901 - acc: 0.2556 - mean_squared_error: 0.0485\n",
      "Epoch 71/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6999 - acc: 0.2515 - mean_squared_error: 0.0487\n",
      "Epoch 72/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7119 - acc: 0.2537 - mean_squared_error: 0.0489\n",
      "Epoch 73/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.7013 - acc: 0.2523 - mean_squared_error: 0.0488\n",
      "Epoch 74/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6776 - acc: 0.2662 - mean_squared_error: 0.0483\n",
      "Epoch 75/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6820 - acc: 0.2627 - mean_squared_error: 0.0483\n",
      "Epoch 76/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6925 - acc: 0.2574 - mean_squared_error: 0.0486\n",
      "Epoch 77/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.7145 - acc: 0.2513 - mean_squared_error: 0.0489\n",
      "Epoch 78/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6951 - acc: 0.2601 - mean_squared_error: 0.0486\n",
      "Epoch 79/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6756 - acc: 0.2667 - mean_squared_error: 0.0481\n",
      "Epoch 80/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6829 - acc: 0.2611 - mean_squared_error: 0.0483\n",
      "Epoch 81/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6912 - acc: 0.2546 - mean_squared_error: 0.0486\n",
      "Epoch 82/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6796 - acc: 0.2623 - mean_squared_error: 0.0483\n",
      "Epoch 83/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6792 - acc: 0.2623 - mean_squared_error: 0.0482\n",
      "Epoch 84/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6772 - acc: 0.2623 - mean_squared_error: 0.0483\n",
      "Epoch 85/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6754 - acc: 0.2638 - mean_squared_error: 0.0482\n",
      "Epoch 86/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6684 - acc: 0.2645 - mean_squared_error: 0.0481\n",
      "Epoch 87/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6789 - acc: 0.2654 - mean_squared_error: 0.0482\n",
      "Epoch 88/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6695 - acc: 0.2624 - mean_squared_error: 0.0480\n",
      "Epoch 89/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6697 - acc: 0.2642 - mean_squared_error: 0.0480\n",
      "Epoch 90/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6628 - acc: 0.2653 - mean_squared_error: 0.0479\n",
      "Epoch 91/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6779 - acc: 0.2634 - mean_squared_error: 0.0482\n",
      "Epoch 92/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6706 - acc: 0.2644 - mean_squared_error: 0.0481\n",
      "Epoch 93/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6822 - acc: 0.2609 - mean_squared_error: 0.0483\n",
      "Epoch 94/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6598 - acc: 0.2666 - mean_squared_error: 0.0479\n",
      "Epoch 95/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6760 - acc: 0.2626 - mean_squared_error: 0.0482\n",
      "Epoch 96/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6732 - acc: 0.2645 - mean_squared_error: 0.0481\n",
      "Epoch 97/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6811 - acc: 0.2592 - mean_squared_error: 0.0483\n",
      "Epoch 98/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6631 - acc: 0.2661 - mean_squared_error: 0.0479\n",
      "Epoch 99/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6632 - acc: 0.2637 - mean_squared_error: 0.0480\n",
      "Epoch 100/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6789 - acc: 0.2639 - mean_squared_error: 0.0482\n",
      "Epoch 101/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6681 - acc: 0.2638 - mean_squared_error: 0.0480\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6808 - acc: 0.2603 - mean_squared_error: 0.0483\n",
      "Epoch 103/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6654 - acc: 0.2676 - mean_squared_error: 0.0480\n",
      "Epoch 104/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6668 - acc: 0.2683 - mean_squared_error: 0.0480\n",
      "Epoch 105/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6166 - acc: 0.2705 - mean_squared_error: 0.0480\n",
      "Epoch 106/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.6154 - acc: 0.2702 - mean_squared_error: 0.0480\n",
      "Epoch 107/200\n",
      "65000/65000 [==============================] - 0s 8us/step - loss: 1.6075 - acc: 0.2735 - mean_squared_error: 0.0477\n",
      "Epoch 108/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6133 - acc: 0.2725 - mean_squared_error: 0.0479\n",
      "Epoch 109/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6134 - acc: 0.2703 - mean_squared_error: 0.0479\n",
      "Epoch 110/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6131 - acc: 0.2786 - mean_squared_error: 0.0478\n",
      "Epoch 111/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6059 - acc: 0.2773 - mean_squared_error: 0.0477\n",
      "Epoch 112/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6303 - acc: 0.2691 - mean_squared_error: 0.0483\n",
      "Epoch 113/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6084 - acc: 0.2775 - mean_squared_error: 0.0477\n",
      "Epoch 114/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6042 - acc: 0.2748 - mean_squared_error: 0.0477\n",
      "Epoch 115/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.5982 - acc: 0.2804 - mean_squared_error: 0.0475\n",
      "Epoch 116/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6075 - acc: 0.2805 - mean_squared_error: 0.0477\n",
      "Epoch 117/200\n",
      "65000/65000 [==============================] - 0s 8us/step - loss: 1.6423 - acc: 0.2658 - mean_squared_error: 0.0484\n",
      "Epoch 118/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5978 - acc: 0.2810 - mean_squared_error: 0.0475\n",
      "Epoch 119/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6228 - acc: 0.2692 - mean_squared_error: 0.0481\n",
      "Epoch 120/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6265 - acc: 0.2678 - mean_squared_error: 0.0482\n",
      "Epoch 121/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6095 - acc: 0.2752 - mean_squared_error: 0.0478\n",
      "Epoch 122/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5975 - acc: 0.2821 - mean_squared_error: 0.0475\n",
      "Epoch 123/200\n",
      "65000/65000 [==============================] - 1s 9us/step - loss: 1.6074 - acc: 0.2757 - mean_squared_error: 0.0478\n",
      "Epoch 124/200\n",
      "65000/65000 [==============================] - 1s 10us/step - loss: 1.6206 - acc: 0.2725 - mean_squared_error: 0.0480\n",
      "Epoch 125/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.6038 - acc: 0.2764 - mean_squared_error: 0.0477\n",
      "Epoch 126/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5932 - acc: 0.2802 - mean_squared_error: 0.0475\n",
      "Epoch 127/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6147 - acc: 0.2723 - mean_squared_error: 0.0479\n",
      "Epoch 128/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5955 - acc: 0.2788 - mean_squared_error: 0.0475\n",
      "Epoch 129/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5905 - acc: 0.2818 - mean_squared_error: 0.0474\n",
      "Epoch 130/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5999 - acc: 0.2783 - mean_squared_error: 0.0476\n",
      "Epoch 131/200\n",
      "65000/65000 [==============================] - 1s 9us/step - loss: 1.6140 - acc: 0.2740 - mean_squared_error: 0.0480\n",
      "Epoch 132/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5971 - acc: 0.2789 - mean_squared_error: 0.0476\n",
      "Epoch 133/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5941 - acc: 0.2820 - mean_squared_error: 0.0475\n",
      "Epoch 134/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5979 - acc: 0.2792 - mean_squared_error: 0.0476\n",
      "Epoch 135/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6131 - acc: 0.2750 - mean_squared_error: 0.0478\n",
      "Epoch 136/200\n",
      "65000/65000 [==============================] - 1s 9us/step - loss: 1.6157 - acc: 0.2703 - mean_squared_error: 0.0480\n",
      "Epoch 137/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.5986 - acc: 0.2802 - mean_squared_error: 0.0475\n",
      "Epoch 138/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6063 - acc: 0.2795 - mean_squared_error: 0.0477\n",
      "Epoch 139/200\n",
      "65000/65000 [==============================] - 0s 8us/step - loss: 1.5844 - acc: 0.2835 - mean_squared_error: 0.0473\n",
      "Epoch 140/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5965 - acc: 0.2805 - mean_squared_error: 0.0476\n",
      "Epoch 141/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5948 - acc: 0.2756 - mean_squared_error: 0.0476\n",
      "Epoch 142/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.6073 - acc: 0.2789 - mean_squared_error: 0.0478\n",
      "Epoch 143/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6048 - acc: 0.2806 - mean_squared_error: 0.0478\n",
      "Epoch 144/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5938 - acc: 0.2795 - mean_squared_error: 0.0475\n",
      "Epoch 145/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5885 - acc: 0.2823 - mean_squared_error: 0.0474\n",
      "Epoch 146/200\n",
      "65000/65000 [==============================] - 1s 9us/step - loss: 1.5942 - acc: 0.2830 - mean_squared_error: 0.0475\n",
      "Epoch 147/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.6033 - acc: 0.2786 - mean_squared_error: 0.0477\n",
      "Epoch 148/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5911 - acc: 0.2803 - mean_squared_error: 0.0475\n",
      "Epoch 149/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.6020 - acc: 0.2811 - mean_squared_error: 0.0476\n",
      "Epoch 150/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.5890 - acc: 0.2842 - mean_squared_error: 0.0474\n",
      "Epoch 151/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.6104 - acc: 0.2748 - mean_squared_error: 0.0478\n",
      "Epoch 152/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5987 - acc: 0.2759 - mean_squared_error: 0.0477\n",
      "Epoch 153/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.5975 - acc: 0.2817 - mean_squared_error: 0.0476\n",
      "Epoch 154/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5953 - acc: 0.2797 - mean_squared_error: 0.0476\n",
      "Epoch 155/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5872 - acc: 0.2825 - mean_squared_error: 0.0474\n",
      "Epoch 156/200\n",
      "65000/65000 [==============================] - 1s 9us/step - loss: 1.6055 - acc: 0.2774 - mean_squared_error: 0.0478\n",
      "Epoch 157/200\n",
      "65000/65000 [==============================] - 1s 8us/step - loss: 1.6081 - acc: 0.2763 - mean_squared_error: 0.0479\n",
      "Epoch 158/200\n",
      "65000/65000 [==============================] - 0s 7us/step - loss: 1.5960 - acc: 0.2790 - mean_squared_error: 0.0476\n",
      "Epoch 159/200\n",
      "65000/65000 [==============================] - 1s 10us/step - loss: 1.6024 - acc: 0.2796 - mean_squared_error: 0.0477\n",
      "Epoch 160/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5901 - acc: 0.2811 - mean_squared_error: 0.0475\n",
      "Epoch 161/200\n",
      "65000/65000 [==============================] - 0s 6us/step - loss: 1.5918 - acc: 0.2842 - mean_squared_error: 0.0475\n",
      "Epoch 162/200\n",
      "65000/65000 [==============================] - 1s 11us/step - loss: 1.5813 - acc: 0.2872 - mean_squared_error: 0.0473\n",
      "Epoch 163/200\n",
      "54272/65000 [========================>.....] - ETA: 0s - loss: 1.6112 - acc: 0.2757 - mean_squared_error: 0.0479"
     ]
    }
   ],
   "source": [
    "EsNodB_range = [12,14,16,20,25,26]\n",
    "N_array=[75000,60000,65000,12000,10000,14000]\n",
    "ser = [None]*len(EsNodB_range)\n",
    "theor_ser_qam = [None]*len(EsNodB_range)\n",
    "theor_ser = [None]*len(EsNodB_range)\n",
    "\n",
    "noise_std = np.sqrt(1.1)\n",
    "for n in range(0,len(EsNodB_range)):\n",
    "    \n",
    "    EsNo=10.0**(EsNodB_range[n]/10.0)\n",
    "    P = EsNo*(noise_std**2)\n",
    "    \n",
    "    no_errors = 0\n",
    "    \n",
    "    N=N_array[n]\n",
    "   \n",
    "    \n",
    "    autoencoder = set_up_train_nn(P,EsNodB_range[n])\n",
    "    \n",
    "    # generating data for checking SER\n",
    "    test_label = np.random.randint(M,size=N)\n",
    "    test_data = []\n",
    "\n",
    "    for i in test_label:\n",
    "        temp = np.zeros(M)\n",
    "        temp[i] = 1\n",
    "        test_data.append(temp)\n",
    "\n",
    "    test_data = np.array(test_data)\n",
    "    \n",
    "    pred_final_signal = autoencoder.predict(test_data)\n",
    "    \n",
    "    pred_output = np.argmax(pred_final_signal,axis=1)\n",
    "    no_errors = (pred_output != test_label)\n",
    "    no_errors =  no_errors.astype(int).sum()\n",
    "    ser[n] = no_errors / N \n",
    "    \n",
    "    P_sqrtM = 0.75*special.erfc(np.sqrt(EsNo/10))\n",
    "    theor_ser_qam[n] = 1-(1-P_sqrtM)**2\n",
    "    theor_ser[n] = (15/16)*special.erfc(np.sqrt(EsNo/85))\n",
    "    \n",
    "    print ('Es/No:',EsNodB_range[n],'SER:',ser[n],'Theor_SER_PAM:',theor_ser[n])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(EsNodB_range, theor_ser, 'g--',label='16 PAM')\n",
    "plt.plot(EsNodB_range, ser, 'bo-',label='Conventional PD-both streams')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('SNR Range')\n",
    "plt.ylabel('Block Error Rate')\n",
    "plt.grid()\n",
    "plt.legend(loc='best',ncol = 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
